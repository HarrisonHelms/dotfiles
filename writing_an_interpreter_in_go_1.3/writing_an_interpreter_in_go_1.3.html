<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="generator" content="pandoc" />
          <meta name="author" content="Thorsten Ball" />
              <meta name="date" content="2016-01-01" />
              <title>Writing An Interpreter In Go</title>
      <style type="text/css">code{white-space: pre;}</style>
        <style type="text/css">
    body {
      margin: 40px auto;

      max-width:700px;

      padding: 0 10px;

      font-family: Georgia, serif;
      font-size: 18px;

      line-height: 1.45;
      color: black;
    }

    h1, h2, h3 {
      line-height:1.2;
    }

    pre {
      padding-left:15px;
    }

    .cover {
      text-align: center;
    }

    .cover img {
      max-width: 400px;
    }

    #TOC {
      margin-top: 5em;
    }

    .sourceCode {
      line-height: 1.4;
      font-size: 15px;
    }

    .figure {
      text-align:center;
    }

    .caption {
      font-style:italic;
    }
    </style>
          <style type="text/css">
    div.sourceCode { overflow-x: auto; }
    table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
      margin: 0; padding: 0; vertical-align: baseline; border: none; }
    table.sourceCode { width: 100%; line-height: 100%; }
    td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
    td.sourceCode { padding-left: 5px; }
    code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code > span.dt { color: #902000; } /* DataType */
    code > span.dv { color: #40a070; } /* DecVal */
    code > span.bn { color: #40a070; } /* BaseN */
    code > span.fl { color: #40a070; } /* Float */
    code > span.ch { color: #4070a0; } /* Char */
    code > span.st { color: #4070a0; } /* String */
    code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code > span.ot { color: #007020; } /* Other */
    code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code > span.fu { color: #06287e; } /* Function */
    code > span.er { color: #ff0000; font-weight: bold; } /* Error */
    code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    code > span.cn { color: #880000; } /* Constant */
    code > span.sc { color: #4070a0; } /* SpecialChar */
    code > span.vs { color: #4070a0; } /* VerbatimString */
    code > span.ss { color: #bb6688; } /* SpecialString */
    code > span.im { } /* Import */
    code > span.va { color: #19177c; } /* Variable */
    code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code > span.op { color: #666666; } /* Operator */
    code > span.bu { } /* BuiltIn */
    code > span.ex { } /* Extension */
    code > span.pp { color: #bc7a00; } /* Preprocessor */
    code > span.at { color: #7d9029; } /* Attribute */
    code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
      </style>
                  </head>
  <body>
            <div id="header">
    <div class="cover">
      <img src="./images/html_cover.png">
    </div>
    <h1 class="title">Writing An Interpreter In Go</h1>
            <h2 class="author">Thorsten Ball</h2>
        </div>
            <div id="TOC">
    <h3>Contents</h3>
    <ul>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
    <li><a href="#introduction">Introduction</a><ul>
    <li><a href="#the-monkey-programming-language-interpreter">The Monkey Programming Language &amp; Interpreter</a></li>
    <li><a href="#why-go">Why Go?</a></li>
    <li><a href="#how-to-use-this-book">How to Use this Book</a></li>
    </ul></li>
    <li><a href="#lexing">Lexing</a><ul>
    <li><a href="#lexical-analysis">1.1 - Lexical Analysis</a></li>
    <li><a href="#defining-our-tokens">1.2 - Defining Our Tokens</a></li>
    <li><a href="#the-lexer">1.3 - The Lexer</a></li>
    <li><a href="#extending-our-token-set-and-lexer">1.4 - Extending our Token Set and Lexer</a></li>
    <li><a href="#start-of-a-repl">1.5 - Start of a REPL</a></li>
    </ul></li>
    <li><a href="#parsing">Parsing</a><ul>
    <li><a href="#parsers">2.1 - Parsers</a></li>
    <li><a href="#why-not-a-parser-generator">2.2 - Why not a parser generator?</a></li>
    <li><a href="#writing-a-parser-for-the-monkey-programming-language">2.3 - Writing a Parser for the Monkey Programming Language</a></li>
    <li><a href="#parsers-first-steps-parsing-let-statements">2.4 - Parser's first steps: parsing let statements</a></li>
    <li><a href="#parsing-return-statements">2.5 - Parsing Return Statements</a></li>
    <li><a href="#parsing-expressions">2.6 - Parsing Expressions</a><ul>
    <li><a href="#expressions-in-monkey">Expressions in Monkey</a></li>
    <li><a href="#top-down-operator-precedence-or-pratt-parsing">Top Down Operator Precedence (or: Pratt Parsing)</a></li>
    <li><a href="#terminology">Terminology</a></li>
    <li><a href="#preparing-the-ast">Preparing the AST</a></li>
    <li><a href="#implementing-the-pratt-parser">Implementing the Pratt Parser</a></li>
    <li><a href="#identifiers">Identifiers</a></li>
    <li><a href="#integer-literals">Integer Literals</a></li>
    <li><a href="#prefix-operators">Prefix Operators</a></li>
    <li><a href="#infix-operators">Infix Operators</a></li>
    </ul></li>
    <li><a href="#how-pratt-parsing-works">2.7 - How Pratt Parsing Works</a></li>
    <li><a href="#extending-the-parser">2.8 - Extending the Parser</a><ul>
    <li><a href="#boolean-literals">Boolean Literals</a></li>
    <li><a href="#grouped-expressions">Grouped Expressions</a></li>
    <li><a href="#if-expressions">If Expressions</a></li>
    <li><a href="#function-literals">Function Literals</a></li>
    <li><a href="#call-expressions">Call Expressions</a></li>
    <li><a href="#removing-todos">Removing TODOs</a></li>
    </ul></li>
    <li><a href="#read-parse-print-loop">2.9 - Read-Parse-Print-Loop</a></li>
    </ul></li>
    <li><a href="#evaluation">Evaluation</a><ul>
    <li><a href="#giving-meaning-to-symbols">3.1 - Giving Meaning to Symbols</a></li>
    <li><a href="#strategies-of-evaluation">3.2 - Strategies of Evaluation</a></li>
    <li><a href="#a-tree-walking-interpreter">3.3 - A Tree-Walking Interpreter</a></li>
    <li><a href="#representing-objects">3.4 - Representing Objects</a><ul>
    <li><a href="#foundation-of-our-object-system">Foundation of our Object System</a></li>
    <li><a href="#integers">Integers</a></li>
    <li><a href="#booleans">Booleans</a></li>
    <li><a href="#null">Null</a></li>
    </ul></li>
    <li><a href="#evaluating-expressions">3.5 - Evaluating Expressions</a><ul>
    <li><a href="#integer-literals-1">Integer Literals</a></li>
    <li><a href="#completing-the-repl">Completing the REPL</a></li>
    <li><a href="#boolean-literals-1">Boolean Literals</a></li>
    <li><a href="#null-1">Null</a></li>
    <li><a href="#prefix-expressions">Prefix Expressions</a></li>
    <li><a href="#infix-expressions">Infix Expressions</a></li>
    </ul></li>
    <li><a href="#conditionals">3.6 - Conditionals</a></li>
    <li><a href="#return-statements">3.7 - Return Statements</a></li>
    <li><a href="#abort-abort-theres-been-a-mistake-or-error-handling">3.8 - Abort! Abort! There's been a mistake!, or: Error Handling</a></li>
    <li><a href="#bindings-the-environment">3.9 - Bindings &amp; The Environment</a></li>
    <li><a href="#functions-function-calls">3.10 - Functions &amp; Function Calls</a></li>
    <li><a href="#whos-taking-the-trash-out">3.11 - Who's taking the trash out?</a></li>
    </ul></li>
    <li><a href="#extending-the-interpreter">Extending the Interpreter</a><ul>
    <li><a href="#data-types-functions">4.1 - Data Types &amp; Functions</a></li>
    <li><a href="#strings">4.2 - Strings</a><ul>
    <li><a href="#supporting-strings-in-our-lexer">Supporting Strings in our Lexer</a></li>
    <li><a href="#parsing-strings">Parsing Strings</a></li>
    <li><a href="#evaluating-strings">Evaluating Strings</a></li>
    <li><a href="#string-concatenation">String Concatenation</a></li>
    </ul></li>
    <li><a href="#built-in-functions">4.3 - Built-in Functions</a><ul>
    <li><a href="#len">len</a></li>
    </ul></li>
    <li><a href="#array">4.4 - Array</a><ul>
    <li><a href="#supporting-arrays-in-our-lexer">Supporting Arrays in our Lexer</a></li>
    <li><a href="#parsing-array-literals">Parsing Array Literals</a></li>
    <li><a href="#parsing-index-operator-expressions">Parsing Index Operator Expressions</a></li>
    <li><a href="#evaluating-array-literals">Evaluating Array Literals</a></li>
    <li><a href="#evaluating-index-operator-expressions">Evaluating Index Operator Expressions</a></li>
    <li><a href="#adding-built-in-functions-for-arrays">Adding Built-in Functions for Arrays</a></li>
    <li><a href="#test-driving-arrays">Test-Driving Arrays</a></li>
    </ul></li>
    <li><a href="#hashes">4.5 - Hashes</a><ul>
    <li><a href="#lexing-hash-literals">Lexing Hash Literals</a></li>
    <li><a href="#parsing-hash-literals">Parsing Hash Literals</a></li>
    <li><a href="#hashing-objects">Hashing Objects</a></li>
    <li><a href="#evaluating-hash-literals">Evaluating Hash Literals</a></li>
    <li><a href="#evaluating-index-expressions-with-hashes">Evaluating Index Expressions With Hashes</a></li>
    </ul></li>
    <li><a href="#the-grand-finale">4.6 - The Grand Finale</a></li>
    </ul></li>
    <li><a href="#resources">Resources</a></li>
    <li><a href="#feedback">Feedback</a></li>
    <li><a href="#changelog">Changelog</a></li>
    </ul>
    </div>
        <h1 id="acknowledgments" class="unnumbered">Acknowledgments</h1>
<p>I want to use these lines to express my gratitude to my wife for supporting me. She's the reason you're reading this. This book wouldn't exist without her encouragement, faith in me, assistance and her willingness to listen to my mechanical keyboard clacking away at 6am.</p>
<p>Thanks to my friends Christian, Felix and Robin for reviewing early versions of this book and providing me with invaluable feedback, advice and cheers. You improved this book more than you can imagine.</p>
<h1 id="introduction" class="unnumbered">Introduction</h1>
<p>The first sentence of this introduction was supposed to be this one: &quot;Interpreters are magical&quot;. But one of the earliest reviewers, who wishes to remain anonymous, said that &quot;sounds super stupid&quot;. Well, Christian, I don't think so! I still think that interpreters <em>are</em> magical! Let me tell you why.</p>
<p>On the surface they look deceptively simple: text goes in and something comes out. They are programs that take other programs as their input and produce something. Simple, right? But the more you think about it, the more fascinating it becomes. Seemingly random characters - letters, numbers and special characters - are fed into the interpreter and suddenly become <strong>meaningful</strong>. The interpreter gives them meaning! It makes sense out of nonsense. And the computer, a machine that's built on understanding ones and zeroes, now understands and acts upon this weird language we feed into it - thanks to an interpreter that translates this language while reading it.</p>
<p>I kept asking myself: <em>how does this work?</em> And the first time this question began forming in my mind, I already knew that I'll only be satisfied with an answer if I get to it by writing my own interpreter. So I set out to do so.</p>
<p>A lot of books, articles, blog posts and tutorials on interpreters exist. Most of the time, though, they fall into one of two categories. Either they are huge, incredibly heavy on theory and more targeted towards people who already have a vast understanding of the topic, or they are really short, provide just a small introduction to the topic, use external tools as black boxes and only concern themselves with &quot;toy interpreters&quot;.</p>
<p>One of the main sources of frustration was this latter category of resources, because the interpreters they explain only interpret languages with a really simple syntax. I didn't want to take a shortcut! I truly wanted to understand how interpreters work and that included understanding how lexers and parsers work. Especially with a C-like language and its curly braces and semicolons, where I didn't even know how to start parsing them. The academic textbooks had the answers I was looking for, of course. But rather inaccessible to me, behind their lengthy, theoretical explanations and mathematical notation.</p>
<p>What I wanted was something between the 900 page book on compilers and the blog post that explains how to write a Lisp interpreter in 50 lines of Ruby code.</p>
<p>So I wrote this book, for you and me. This is the book I wish I had. This is a book for people who love to look under the hood. For people that love to learn by understanding how something really works.</p>
<p>In this book we're going to write our own interpreter for our own programming language - from scratch. We won't be using any 3rd party tools and libraries. The result won't be production-ready, it won't have the performance of a fully-fledged interpreter and, of course, the language it's built to interpret will be missing features. But we're going to learn a lot.</p>
<p>It's difficult to make generic statements about interpreters since the variety is so high and none are alike. What can be said is that the one fundamental attribute they all share is that they take source code and evaluate it without producing some visible, intermediate result that can later be executed. That's in contrast to compilers, which take source code and produce output in another language that the underlying system can understand.</p>
<p>Some interpreters are really small, tiny, and do not even bother with a parsing step. They just interpret the input right away. Look at one of the many Brainfuck interpreters out there to see what I mean.</p>
<p>On the other end of the spectrum are much more elaborate types of interpreters. Highly optimized and using advanced parsing and evaluation techniques. Some of them don't just evaluate their input, but compile it into an internal representation called bytecode and then evaluate this. Even more advanced are JIT interpreters that compile the input just-in-time into native machine code that gets then executed.</p>
<p>But then, in between those two categories, there are interpreters that parse the source code, build an abstract syntax tree (AST) out of it and then evaluate this tree. This type of interpreter is sometimes called &quot;tree-walking&quot; interpreter, because it &quot;walks&quot; the AST and interprets it.</p>
<p>What we will be building in this book is such a tree-walking interpreter.</p>
<p>We're going to build our own lexer, our own parser, our own tree representation and our own evaluator. We'll see what &quot;tokens&quot; are, what an abstract syntax tree is, how to build such a tree, how to evaluate it and how to extend our language with new data structures and built-in functions.</p>
<h2 id="the-monkey-programming-language-interpreter">The Monkey Programming Language &amp; Interpreter</h2>
<p>Every interpreter is built to interpret a specific programming language. That's how you &quot;implement&quot; a programming language. Without a compiler or an interpreter a programming language is nothing more than an idea or a specification.</p>
<p>We're going to parse and evaluate our own language called Monkey. It's a language specifically designed for this book. Its only implementation is the one we're going to build in this book - our interpreter.</p>
<p>Expressed as a list of features, Monkey has the following:</p>
<ul>
<li>C-like syntax</li>
<li>variable bindings</li>
<li>integers and booleans</li>
<li>arithmetic expressions</li>
<li>built-in functions</li>
<li>first-class and higher-order functions</li>
<li>closures</li>
<li>a string data structure</li>
<li>an array data structure</li>
<li>a hash data structure</li>
</ul>
<p>We're going to take a detailed look at and implement each of these features in the rest of this book. But for now, let's see what Monkey looks like.</p>
<p>Here is how we bind values to names in Monkey:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> age <span class="op">=</span> <span class="dv">1</span><span class="op">;</span>
<span class="kw">let</span> name <span class="op">=</span> <span class="st">&quot;Monkey&quot;</span><span class="op">;</span>
<span class="kw">let</span> result <span class="op">=</span> <span class="dv">10</span> <span class="op">*</span> (<span class="dv">20</span> / <span class="dv">2</span>)<span class="op">;</span></code></pre></div>
<p>Besides integers, booleans and strings, the Monkey interpreter we're going to build will also support arrays and hashes. Here's what binding an array of integers to a name looks like:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> myArray <span class="op">=</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">5</span>]<span class="op">;</span></code></pre></div>
<p>And here is a hash, where values are associated with keys:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> thorsten <span class="op">=</span> <span class="op">{</span><span class="st">&quot;name&quot;</span><span class="op">:</span> <span class="st">&quot;Thorsten&quot;</span><span class="op">,</span> <span class="st">&quot;age&quot;</span><span class="op">:</span> <span class="dv">28</span><span class="op">};</span></code></pre></div>
<p>Accessing the elements in arrays and hashes is done with index expressions:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">myArray[<span class="dv">0</span>]       <span class="co">// =&gt; 1</span>
thorsten[<span class="st">&quot;name&quot;</span>] <span class="co">// =&gt; &quot;Thorsten&quot;</span></code></pre></div>
<p>The <code>let</code> statements can also be used to bind functions to names. Here's a small function that adds two numbers:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(a<span class="op">,</span> b) <span class="op">{</span> <span class="cf">return</span> a <span class="op">+</span> b<span class="op">;</span> <span class="op">};</span></code></pre></div>
<p>But Monkey not only supports <code>return</code> statements. Implicit return values are also possible, which means we can leave out the <code>return</code> if we want to:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(a<span class="op">,</span> b) <span class="op">{</span> a <span class="op">+</span> b<span class="op">;</span> <span class="op">};</span></code></pre></div>
<p>And calling a function is as easy as you'd expect:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span>)<span class="op">;</span></code></pre></div>
<p>A more complex function, such as a <code>fibonacci</code> function that returns the Nth Fibonacci number, might look like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> fibonacci <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span>
  <span class="cf">if</span> (x <span class="op">==</span> <span class="dv">0</span>) <span class="op">{</span>
    <span class="dv">0</span>
  <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
    <span class="cf">if</span> (x <span class="op">==</span> <span class="dv">1</span>) <span class="op">{</span>
      <span class="dv">1</span>
    <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
      <span class="at">fibonacci</span>(x <span class="op">-</span> <span class="dv">1</span>) <span class="op">+</span> <span class="at">fibonacci</span>(x <span class="op">-</span> <span class="dv">2</span>)<span class="op">;</span>
    <span class="op">}</span>
  <span class="op">}</span>
<span class="op">};</span></code></pre></div>
<p>Note the recursive calls to <code>fibonacci</code> itself!</p>
<p>Monkey also supports a special type of functions, called higher order functions. These are functions that take other functions as arguments. Here is an example:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> twice <span class="op">=</span> <span class="at">fn</span>(f<span class="op">,</span> x) <span class="op">{</span>
  <span class="cf">return</span> <span class="at">f</span>(<span class="at">f</span>(x))<span class="op">;</span>
<span class="op">};</span>

<span class="kw">let</span> addTwo <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span>
  <span class="cf">return</span> x <span class="op">+</span> <span class="dv">2</span><span class="op">;</span>
<span class="op">};</span>

<span class="at">twice</span>(addTwo<span class="op">,</span> <span class="dv">2</span>)<span class="op">;</span> <span class="co">// =&gt; 6</span></code></pre></div>
<p>Here <code>twice</code> takes two arguments: another function called <code>addTwo</code> and the integer <code>2</code>. It calls <code>addTwo</code> two times with first <code>2</code> as argument and then with the return value of the first call. The last line produces <code>6</code>.</p>
<p>Yes, we can use functions as arguments in function calls. Functions in Monkey are just values, like integers or strings. That feature is called &quot;first class functions&quot;.</p>
<p>The interpreter we're going to build in this book will implement all these features. It will tokenize and parse Monkey source code in a REPL, building up an internal representation of the code called abstract syntax tree and then evaluate this tree. It will have a few major parts:</p>
<ul>
<li>the lexer</li>
<li>the parser</li>
<li>the Abstract Syntax Tree (AST)</li>
<li>the internal object system</li>
<li>the evaluator</li>
</ul>
<p>We're going to build these parts in exactly this order, from the bottom up. Or better put: starting with the source code and ending with the output. The drawback of this approach is that it won't produce a simple &quot;Hello World&quot; after the first chapter. The advantage is that it's easier to understand how all the pieces fit together and how the data flows through the program.</p>
<p>But why the name? Why is it called &quot;Monkey&quot;? Well, because monkeys are magnificent, elegant, fascinating and funny creatures. Exactly like our interpreter.</p>
<p>And why the name of the book?</p>
<h2 id="why-go">Why Go?</h2>
<p>If you read this far without noticing the title and the words &quot;in Go&quot; in it, first of all: congratulations, that's pretty remarkable. And second: we will write our interpreter in Go. Why Go?</p>
<p>I like writing code in Go. I enjoy using the language, its standard library and the tools it provides. But other than that I think that Go is in possession of a few attributes that make it a great fit for this particular book.</p>
<p>Go is really easy to read and subsequently understand. You won't need to decipher the Go code I present to you in this book. Even if you are not an experienced Go programmer. I'd bet that you can follow this book along even if you've never written a single line of Go in your life.</p>
<p>Another reason is the great tooling Go provides. The focus of this book is the interpreter we are writing - the ideas and concepts behind it and its implementation. With Go's universal formatting style thanks to <code>gofmt</code> and a testing framework built-in, we can concentrate on our interpreter and not worry about 3rd party libraries, tools and dependencies. We won't be using any other tools in this book other than the ones provided by the Go programming language.</p>
<p>But I think much more important is that the Go code presented in this book maps closely to other and possibly more low-level languages, like C, C++ and Rust. Maybe the reason for this is Go itself, with its focus on simplicity, its stripped-down charm and lack of programming language constructs that are absent in other languages and hard to translate. Or maybe it's because of the way I chose to write Go for this book. Either way, there won't be any meta-programming tricks to take a shortcut that nobody understands anymore after two weeks and no grandiose object-oriented designs and patterns that need pen, paper and the sentence &quot;actually, it's pretty easy&quot; to explain.</p>
<p>All of these reasons make the code presented here easy to understand (on a conceptual as well as a technical level) and reusable for you. And if you, after reading this book, choose to write your own interpreter in another language this should come in handy. With this book I want to provide a starting point in your understanding and construction of interpreters and I think the code reflects that.</p>
<h2 id="how-to-use-this-book">How to Use this Book</h2>
<p>This book is neither a reference, nor is it a theory-laden paper describing concepts of interpreter implementation with code in the appendix. This book is meant to be read from start to finish and I recommend that you follow along by reading, typing out and modifying the presented code.</p>
<p>Each chapter builds upon its predecessor - in code and in prose. And in each chapter we build another part of our interpreter, piece by piece. To make it easier to follow along, the book comes with a folder called <code>code</code>, that contains, well, code. If your copy of the book came without the folder, you can download it here:</p>
<p><a href="https://interpreterbook.com/waiig_code_1.3.zip" class="uri">https://interpreterbook.com/waiig_code_1.3.zip</a></p>
<p>The <code>code</code> folder is divided into several subfolders, with one for each chapter, containing the final result of the corresponding chapter.</p>
<p>Sometimes I'll only allude to something being in the code, without showing the code itself (because either it would take up too much space, as is the case with the test files, or it is just some detail) - you can find this code in the folder accompanying the chapter, too.</p>
<p>Which tools do you need to follow along? Not much: a text editor and the Go programming language. Any Go version above 1.0 should work, but just as a disclaimer and for future generations: at the time of writing I'm using Go 1.7.</p>
<p>I also recommend using <a href="http://direnv.net/">direnv</a>, which can change the environment of your shell according to an <code>.envrc</code> file. Each sub-folder in the code folder accompanying this book contains such an <code>.envrc</code> file that sets the <code>GOPATH</code> correctly for this sub-folder. That allows us to easily work with the code of different chapters.</p>
<p>And with that out of the way, let's get started!</p>
<h1 id="lexing">Lexing</h1>
<h2 id="lexical-analysis">1.1 - Lexical Analysis</h2>
<p>In order for us to work with source code we need to turn it into a more accessible form. As easy as plain text is to work with in our editor, it becomes cumbersome pretty fast when trying to interpret it in a programming language as another programming language.</p>
<p>So, what we need to do is represent our source code in other forms that <strong>are</strong> easier to work with. We're going to change the representation of our source code two times before we evaluate it:</p>
<div class="figure">
<img src="./images/source_code_tokens_ast.png" width="400" />

</div>
<p>The first transformation, from source code to tokens, is called &quot;lexical analysis&quot;, or &quot;lexing&quot; for short. It's done by a lexer (also called tokenizer or scanner -- some use one word or the other to denote subtle differences in behaviour, which we can ignore in this book).</p>
<p>Tokens itself are small, easily categorizable data structures that are then fed to the parser, which does the second transformation and turns the tokens into an &quot;Abstract Syntax Tree&quot;.</p>
<p>Here's an example. This is the input one gives to a lexer:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="st">&quot;let x = 5 + 5;&quot;</span></code></pre></div>
<p>And what comes out of the lexer looks kinda like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">[
  LET<span class="op">,</span>
  <span class="at">IDENTIFIER</span>(<span class="st">&quot;x&quot;</span>)<span class="op">,</span>
  EQUAL_SIGN<span class="op">,</span>
  <span class="at">INTEGER</span>(<span class="dv">5</span>)<span class="op">,</span>
  PLUS_SIGN<span class="op">,</span>
  <span class="at">INTEGER</span>(<span class="dv">5</span>)<span class="op">,</span>
  SEMICOLON
]</code></pre></div>
<p>All of these tokens have the original source code representation attached. <code>&quot;let&quot;</code> in the case of <code>LET</code>, <code>&quot;+&quot;</code> in the case of <code>PLUS_SIGN</code>, and so on. Some, like <code>IDENTIFIER</code> and <code>INTEGER</code> in our example, also have the concrete values they represent attached: <code>5</code> (not <code>&quot;5&quot;</code>!) in the case of <code>INTEGER</code> and <code>&quot;x&quot;</code> in the case of <code>IDENTIFIER</code>. But what exactly constitutes a &quot;token&quot; varies between different lexer implementations. As an example, some lexers only convert the <code>&quot;5&quot;</code> to an integer in the parsing stage, or even later, and not when constructing tokens.</p>
<p>A thing to note about this example: whitespace characters don't show up as tokens. In our case that's okay, because whitespace length is not significant in the Monkey language. Whitespace merely acts as a separator for other tokens. It doesn't matter if we type this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>Or if we type this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span>   x   <span class="op">=</span>   <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>In other languages, like Python, the length of whitespace <em>is</em> significant. That means the lexer can't just &quot;eat up&quot; the whitespace and newline characters. It has to output the whitespace characters as tokens so the parser can later on make sense of them (or output an error, of course, if there are not enough or too many).</p>
<p>A production-ready lexer might also attach the line number, column number and filename to a token. Why? For example, to later output more useful error messages in the parsing stage. Instead of <code>&quot;error: expected semicolon token&quot;</code> it can output:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&quot;error: expected semicolon token. line 42, column 23, program.monkey&quot;</code></pre></div>
<p>We're not going to bother with that. Not because it's too complex, but because it would take away from the essential simpleness of the tokens and the lexer, making it harder to understand.</p>
<h2 id="defining-our-tokens">1.2 - Defining Our Tokens</h2>
<p>The first thing we have to do is to define the tokens our lexer is going to output. We're going to start with just a few token definitions and then add more when extending the lexer.</p>
<p>The subset of the Monkey language we're going to lex in our first step looks like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> five <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="kw">let</span> ten <span class="op">=</span> <span class="dv">10</span><span class="op">;</span>

<span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span>
  x <span class="op">+</span> y<span class="op">;</span>
<span class="op">};</span>

<span class="kw">let</span> result <span class="op">=</span> <span class="at">add</span>(five<span class="op">,</span> ten)<span class="op">;</span></code></pre></div>
<p>Let's break this down: which types of tokens does this example contain? First of all, there are the numbers like <code>5</code> and <code>10</code>. These are pretty obvious. Then we have the variable names <code>x</code>, <code>y</code>, <code>add</code> and <code>result</code>. And then there are also these parts of the language that are not numbers, just words, but no variable names either, like <code>let</code> and <code>fn</code>. Of course, there are also a lot of special characters: <code>(</code>, <code>)</code>, <code>{</code>, <code>}</code>, <code>=</code>, <code>,</code>, <code>;</code>.</p>
<p>The numbers are just integers and we're going to treat them as such and give them a separate type. In the lexer or parser we don't care if the number is <code>5</code> or <code>10</code>, we just want to know if it's a number. The same goes for &quot;variable names&quot;: we'll call them &quot;identifiers&quot; and treat them the same. Now, the other words, the ones that look like identifiers, but aren't really identifiers, since they're part of the language, are called &quot;keywords&quot;. We won't group these together since it <strong>should</strong> make a difference in the parsing stage whether we encounter a <code>let</code> or a <code>fn</code>. The same goes for the last category we identified: the special characters. We'll treat each of them separately, since it is a big difference whether or not we have a <code>(</code> or a <code>)</code> in the source code.</p>
<p>Let's define our <code>Token</code> data structure. Which fields does it need? As we just saw, we definitely need a &quot;type&quot; attribute, so we can distinguish between &quot;integers&quot; and &quot;right bracket&quot; for example. And it also needs a field that holds the literal value of the token, so we can reuse it later and the information whether a &quot;number&quot; token is a <code>5</code> or a <code>10</code> doesn't get lost.</p>
<p>In a new <code>token</code> package we define our <code>Token</code> struct and our <code>TokenType</code> type:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">package</span> token

<span class="kw">type</span> TokenType <span class="dt">string</span>

<span class="kw">type</span> Token <span class="kw">struct</span> {
    Type    TokenType
    Literal <span class="dt">string</span>
}</code></pre></div>
<p>We defined the <code>TokenType</code> type to be a <code>string</code>. That allows us to use many different values as <code>TokenType</code>s, which in turn allows us to distinguish between different types of tokens. Using <code>string</code> also has the advantage of being easy to debug without a lot of boilerplate and helper functions: we can just print a <code>string</code>. Of course, using a <code>string</code> might not lead to the same performance as using an <code>int</code> or a <code>byte</code> would, but for this book a <code>string</code> is perfect.</p>
<p>As we just saw, there is a limited number of different token types in the Monkey language. That means we can define the possible <code>TokenType</code>s as constants. In the same file we add this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
    ILLEGAL = <span class="st">&quot;ILLEGAL&quot;</span>
    EOF     = <span class="st">&quot;EOF&quot;</span>

    <span class="co">// Identifiers + literals</span>
    IDENT = <span class="st">&quot;IDENT&quot;</span> <span class="co">// add, foobar, x, y, ...</span>
    INT   = <span class="st">&quot;INT&quot;</span>   <span class="co">// 1343456</span>

    <span class="co">// Operators</span>
    ASSIGN   = <span class="st">&quot;=&quot;</span>
    PLUS     = <span class="st">&quot;+&quot;</span>

    <span class="co">// Delimiters</span>
    COMMA     = <span class="st">&quot;,&quot;</span>
    SEMICOLON = <span class="st">&quot;;&quot;</span>

    LPAREN = <span class="st">&quot;(&quot;</span>
    RPAREN = <span class="st">&quot;)&quot;</span>
    LBRACE = <span class="st">&quot;{&quot;</span>
    RBRACE = <span class="st">&quot;}&quot;</span>

    <span class="co">// Keywords</span>
    FUNCTION = <span class="st">&quot;FUNCTION&quot;</span>
    LET      = <span class="st">&quot;LET&quot;</span>
)</code></pre></div>
<p>As you can see there are two special types: <code>ILLEGAL</code> and <code>EOF</code>. We didn't see them in the example above, but we'll need them. <code>ILLEGAL</code> signifies a token/character we don't know about and <code>EOF</code> stands for &quot;end of file&quot;, which tells our parser later on that it can stop.</p>
<p>So far so good! We are ready to start writing our lexer.</p>
<h2 id="the-lexer">1.3 - The Lexer</h2>
<p>Before we start to write code, let's be clear about the goal of this section. We're going to write our own lexer. It will take source code as input and output the tokens that represent the source code. It will go through its input and output the next token it recognizes. It doesn't need to buffer or save tokens, since there will only be one method called <code>NextToken()</code>, which will output the next token.</p>
<p>That means, we'll initialize the lexer with our source code and then repeatedly call <code>NextToken()</code> on it to go through the source code, token by token, character by character. We'll also make life simpler here by using <code>string</code> as the type for our source code. Again: in a production environment it makes sense to attach filenames and line numbers to tokens, to better track down lexing and parsing errors. So it would be better to initialize the lexer with an <code>io.Reader</code> and the filename. But since that would add more complexity we're not here to handle, we'll start small and just use a <code>string</code> and ignore filenames and line numbers.</p>
<p>Having thought this through, we now realize that what our lexer needs to do is pretty clear. So let's create a new package and add a first test that we can continuously run to get feedback about the working state of the lexer. We're starting small here and will extend the test case as we add more capabilities to the lexer:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">package</span> lexer

<span class="kw">import</span> (
    <span class="st">&quot;testing&quot;</span>

    <span class="st">&quot;monkey/token&quot;</span>
)

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`=+(){},;`</span>

    tests := []<span class="kw">struct</span> {
        expectedType    token.TokenType
        expectedLiteral <span class="dt">string</span>
    }{
        {token.ASSIGN, <span class="st">&quot;=&quot;</span>},
        {token.PLUS, <span class="st">&quot;+&quot;</span>},
        {token.LPAREN, <span class="st">&quot;(&quot;</span>},
        {token.RPAREN, <span class="st">&quot;)&quot;</span>},
        {token.LBRACE, <span class="st">&quot;{&quot;</span>},
        {token.RBRACE, <span class="st">&quot;}&quot;</span>},
        {token.COMMA, <span class="st">&quot;,&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.EOF, <span class="st">&quot;&quot;</span>},
    }

    l := New(input)

    <span class="kw">for</span> i, tt := <span class="kw">range</span> tests {
        tok := l.NextToken()

        <span class="kw">if</span> tok.Type != tt.expectedType {
            t.Fatalf(<span class="st">&quot;tests[%d] - tokentype wrong. expected=%q, got=%q&quot;</span>,
                i, tt.expectedType, tok.Type)
        }

        <span class="kw">if</span> tok.Literal != tt.expectedLiteral {
            t.Fatalf(<span class="st">&quot;tests[%d] - literal wrong. expected=%q, got=%q&quot;</span>,
                i, tt.expectedLiteral, tok.Literal)
        }
    }
}</code></pre></div>
<p>Of the course, the tests fail -- we haven't written any code yet:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
# monkey/lexer
lexer/lexer_test.go:27: undefined: New
FAIL    monkey/lexer [build failed]</code></pre></div>
<p>So let's start by defining the <code>New()</code> function that returns <code>*Lexer</code>.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>
<span class="kw">package</span> lexer

<span class="kw">type</span> Lexer <span class="kw">struct</span> {
    input        <span class="dt">string</span>
    position     <span class="dt">int</span>  <span class="co">// current position in input (points to current char)</span>
    readPosition <span class="dt">int</span>  <span class="co">// current reading position in input (after current char)</span>
    ch           <span class="dt">byte</span> <span class="co">// current char under examination</span>
}

<span class="kw">func</span> New(input <span class="dt">string</span>) *Lexer {
    l := &amp;Lexer{input: input}
    <span class="kw">return</span> l
}</code></pre></div>
<p>Most of the fields in <code>Lexer</code> are pretty self-explanatory. The ones that might cause some confusion right now are <code>position</code> and <code>readPosition</code>. Both will be used to access characters in <code>input</code> by using them as an index, e.g.: <code>l.input[l.readPosition]</code>. The reason for these two &quot;pointers&quot; pointing into our input string is the fact that we will need to be able to &quot;peek&quot; further into the input and look after the current character to see what comes up next. <code>readPosition</code> always points to the &quot;next&quot; character in the input. <code>position</code> points to the character in the input that corresponds to the <code>ch</code> byte.</p>
<p>A first helper method called <code>readChar()</code> should make the usage of these fields easier to understand:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) readChar() {
    <span class="kw">if</span> l.readPosition &gt;= <span class="bu">len</span>(l.input) {
        l.ch = <span class="dv">0</span>
    } <span class="kw">else</span> {
        l.ch = l.input[l.readPosition]
    }
    l.position = l.readPosition
    l.readPosition += <span class="dv">1</span>
}</code></pre></div>
<p>The purpose of <code>readChar</code> is to give us the next character and advance our position in the <code>input</code> string. The first thing it does is to check whether we have reached the end of <code>input</code>. If that's the case it sets <code>l.ch</code> to <code>0</code>, which is the ASCII code for the <code>&quot;NUL&quot;</code> character and signifies either &quot;we haven't read anything yet&quot; or &quot;end of file&quot; for us. But if we haven't reached the end of <code>input</code> yet it sets <code>l.ch</code> to the next character by accessing <code>l.input[l.readPosition]</code>.</p>
<p>After that <code>l.position</code> is updated to the just used <code>l.readPosition</code> and <code>l.readPosition</code> is incremented by one. That way, <code>l.readPosition</code> always points to the next position where we're going to read from next and <code>l.position</code> always points to the position where we last read. This will come in handy soon enough.</p>
<p>While talking about <code>readChar</code> it's worth pointing out that the lexer only supports ASCII characters instead of the full Unicode range. Why? Because this lets us keep things simple and concentrate on the essential parts of our interpreter. In order to fully support Unicode and UTF-8 we would need to change <code>l.ch</code> from a <code>byte</code> to <code>rune</code> and change the way we read the next characters, since they could be multiple bytes wide now. Using <code>l.input[l.readPosition]</code> wouldn't work anymore. And then we'd also need to change a few other methods and functions we'll see later on. So it's left as an exercise to the reader to fully support Unicode (and emojis!) in Monkey.</p>
<p>Let's use <code>readChar</code> in our <code>New()</code> function so our <code>*Lexer</code> is in a fully working state before anyone calls <code>NextToken()</code>, with <code>l.ch</code>, <code>l.position</code> and <code>l.readPosition</code> already initialized:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> New(input <span class="dt">string</span>) *Lexer {
    l := &amp;Lexer{input: input}
    l.readChar()
    <span class="kw">return</span> l
}</code></pre></div>
<p>Our tests now tell us that calling <code>New(input)</code> doesn't result in problems anymore, but the <code>NextToken()</code> method is still missing. Let's fix that by adding a first version:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">import</span> <span class="st">&quot;monkey/token&quot;</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
    <span class="kw">var</span> tok token.Token

    <span class="kw">switch</span> l.ch {
    <span class="kw">case</span> &#39;=&#39;:
        tok = newToken(token.ASSIGN, l.ch)
    <span class="kw">case</span> &#39;;&#39;:
        tok = newToken(token.SEMICOLON, l.ch)
    <span class="kw">case</span> &#39;(&#39;:
        tok = newToken(token.LPAREN, l.ch)
    <span class="kw">case</span> &#39;)&#39;:
        tok = newToken(token.RPAREN, l.ch)
    <span class="kw">case</span> &#39;,&#39;:
        tok = newToken(token.COMMA, l.ch)
    <span class="kw">case</span> &#39;+&#39;:
        tok = newToken(token.PLUS, l.ch)
    <span class="kw">case</span> &#39;{&#39;:
        tok = newToken(token.LBRACE, l.ch)
    <span class="kw">case</span> &#39;}&#39;:
        tok = newToken(token.RBRACE, l.ch)
    <span class="kw">case</span> <span class="dv">0</span>:
        tok.Literal = <span class="st">&quot;&quot;</span>
        tok.Type = token.EOF
    }

    l.readChar()
    <span class="kw">return</span> tok
}

<span class="kw">func</span> newToken(tokenType token.TokenType, ch <span class="dt">byte</span>) token.Token {
    <span class="kw">return</span> token.Token{Type: tokenType, Literal: <span class="dt">string</span>(ch)}
}</code></pre></div>
<p>That's the basic structure of the <code>NextToken()</code> method. We look at the current character under examination (<code>l.ch</code>) and return a token depending on which character it is. Before returning the token we advance our pointers into the input so when we call <code>NextToken()</code> again the <code>l.ch</code> field is already updated. A small function called <code>newToken</code> helps us with initializing these tokens.</p>
<p>Running the tests we can see that they pass:</p>
<pre><code>$ go test ./lexer
ok      monkey/lexer 0.007s</code></pre>
<p>Great! Let's now extend the test case so it starts to resemble Monkey source code.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">`</span>

    tests := []<span class="kw">struct</span> {
        expectedType    token.TokenType
        expectedLiteral <span class="dt">string</span>
    }{
        {token.LET, <span class="st">&quot;let&quot;</span>},
        {token.IDENT, <span class="st">&quot;five&quot;</span>},
        {token.ASSIGN, <span class="st">&quot;=&quot;</span>},
        {token.INT, <span class="st">&quot;5&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.LET, <span class="st">&quot;let&quot;</span>},
        {token.IDENT, <span class="st">&quot;ten&quot;</span>},
        {token.ASSIGN, <span class="st">&quot;=&quot;</span>},
        {token.INT, <span class="st">&quot;10&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.LET, <span class="st">&quot;let&quot;</span>},
        {token.IDENT, <span class="st">&quot;add&quot;</span>},
        {token.ASSIGN, <span class="st">&quot;=&quot;</span>},
        {token.FUNCTION, <span class="st">&quot;fn&quot;</span>},
        {token.LPAREN, <span class="st">&quot;(&quot;</span>},
        {token.IDENT, <span class="st">&quot;x&quot;</span>},
        {token.COMMA, <span class="st">&quot;,&quot;</span>},
        {token.IDENT, <span class="st">&quot;y&quot;</span>},
        {token.RPAREN, <span class="st">&quot;)&quot;</span>},
        {token.LBRACE, <span class="st">&quot;{&quot;</span>},
        {token.IDENT, <span class="st">&quot;x&quot;</span>},
        {token.PLUS, <span class="st">&quot;+&quot;</span>},
        {token.IDENT, <span class="st">&quot;y&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.RBRACE, <span class="st">&quot;}&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.LET, <span class="st">&quot;let&quot;</span>},
        {token.IDENT, <span class="st">&quot;result&quot;</span>},
        {token.ASSIGN, <span class="st">&quot;=&quot;</span>},
        {token.IDENT, <span class="st">&quot;add&quot;</span>},
        {token.LPAREN, <span class="st">&quot;(&quot;</span>},
        {token.IDENT, <span class="st">&quot;five&quot;</span>},
        {token.COMMA, <span class="st">&quot;,&quot;</span>},
        {token.IDENT, <span class="st">&quot;ten&quot;</span>},
        {token.RPAREN, <span class="st">&quot;)&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.EOF, <span class="st">&quot;&quot;</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Most notably the <code>input</code> in this test case has changed. It looks like a subset of the Monkey language. It contains all the symbols we already successfully turned into tokens, but also new things that are now causing our tests to fail: identifiers, keywords and numbers.</p>
<p>Let's start with the identifiers and keywords. What our lexer needs to do is recognize whether the current character is a letter and if so, it needs to read the rest of the identifier/keyword until it encounters a non-letter-character. Having read that identifier/keyword, we then need to find out if it is a identifier or a keyword, so we can use the correct <code>token.TokenType</code>. The first step is extending our switch statement:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">import</span> <span class="st">&quot;monkey/token&quot;</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
    <span class="kw">var</span> tok token.Token

    <span class="kw">switch</span> l.ch {
<span class="co">// [...]</span>
    <span class="kw">default</span>:
        <span class="kw">if</span> isLetter(l.ch) {
            tok.Literal = l.readIdentifier()
            <span class="kw">return</span> tok
        } <span class="kw">else</span> {
            tok = newToken(token.ILLEGAL, l.ch)
        }
    }
<span class="co">// [...]</span>
}

<span class="kw">func</span> (l *Lexer) readIdentifier() <span class="dt">string</span> {
    position := l.position
    <span class="kw">for</span> isLetter(l.ch) {
        l.readChar()
    }
    <span class="kw">return</span> l.input[position:l.position]
}

<span class="kw">func</span> isLetter(ch <span class="dt">byte</span>) <span class="dt">bool</span> {
    <span class="kw">return</span> &#39;a&#39; &lt;= ch &amp;&amp; ch &lt;= &#39;z&#39; || &#39;A&#39; &lt;= ch &amp;&amp; ch &lt;= &#39;Z&#39; || ch == &#39;_&#39;
}</code></pre></div>
<p>We added a <code>default</code> branch to our switch statement, so we can check for identifiers whenever the <code>l.ch</code> is not one of the recognized characters. We also added the generation of <code>token.ILLEGAL</code> tokens. If we end up there, we truly don't know how to handle the current character and declare it as <code>token.ILLEGAL</code>.</p>
<p>The <code>isLetter</code> helper function just checks whether the given argument is a letter. That sounds easy enough, but what's noteworthy about <code>isLetter</code> is that changing this function has a larger impact on the language our interpreter will be able to parse than one would expect from such a small function. As you can see, in our case it contains the check <code>ch == '_'</code>, which means that we'll treat <code>_</code> as a letter and allow it in identifiers and keywords. That means we can use variable names like <code>foo_bar</code>. Other programming languages even allow <code>!</code> and <code>?</code> in identifiers. If you want to allow that too, this is the place to sneak it in.</p>
<p><code>readIdentifier()</code> does exactly what its name suggests: it reads in an identifier and advances our lexer's positions until it encounters a non-letter-character.</p>
<p>In the <code>default:</code> branch of the switch statement we use <code>readIdentifier()</code> to set the <code>Literal</code> field of our current token. But what about its <code>Type</code>? Now that we have read identifiers like <code>let</code>, <code>fn</code> or <code>foobar</code>, we need to be able to tell user-defined identifiers apart from language keywords. We need a function that returns the correct <code>TokenType</code> for the token literal we have. What better place than the <code>token</code> package to add such a function?</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">var</span> keywords = <span class="kw">map</span>[<span class="dt">string</span>]TokenType{
    <span class="st">&quot;fn&quot;</span>:  FUNCTION,
    <span class="st">&quot;let&quot;</span>: LET,
}

<span class="kw">func</span> LookupIdent(ident <span class="dt">string</span>) TokenType {
    <span class="kw">if</span> tok, ok := keywords[ident]; ok {
        <span class="kw">return</span> tok
    }
    <span class="kw">return</span> IDENT
}</code></pre></div>
<p><code>LookupIdent</code> checks the <code>keywords</code> table to see whether the given identifier is in fact a keyword. If it is, it returns the keyword's <code>TokenType</code> constant. If it isn't, we just get back <code>token.IDENT</code>, which is the <code>TokenType</code> for all user-defined identifiers.</p>
<p>With this in hand we can now complete the lexing of identifiers and keywords:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
    <span class="kw">var</span> tok token.Token

    <span class="kw">switch</span> l.ch {
<span class="co">// [...]</span>
    <span class="kw">default</span>:
        <span class="kw">if</span> isLetter(l.ch) {
            tok.Literal = l.readIdentifier()
            tok.Type = token.LookupIdent(tok.Literal)
            <span class="kw">return</span> tok
        } <span class="kw">else</span> {
            tok = newToken(token.ILLEGAL, l.ch)
        }
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>The early exit here, our <code>return tok</code> statement, is necessary because when calling <code>readIdentifier()</code>, we call <code>readChar()</code> repeatedly and advance our <code>readPosition</code> and <code>position</code> fields past the last character of the current identifier. So we don't need the call to <code>readChar()</code> after the switch statement again.</p>
<p>Running our tests now, we can see that <code>let</code> is identified correctly but the tests still fail:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
--- FAIL: TestNextToken (0.00s)
  lexer_test.go:70: tests[1] - tokentype wrong. expected=&quot;IDENT&quot;, got=&quot;ILLEGAL&quot;
FAIL
FAIL    monkey/lexer 0.008s</code></pre></div>
<p>The problem is the next token we want: a <code>IDENT</code> token with <code>&quot;five&quot;</code> in its <code>Literal</code> field. Instead we get an <code>ILLEGAL</code> token. Why is that? Because of the whitespace character between &quot;let&quot; and &quot;five&quot;. But in Monkey whitespace only acts as a separator of tokens and doesn't have meaning, so we need to skip over it entirely:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
    <span class="kw">var</span> tok token.Token

    l.skipWhitespace()

    <span class="kw">switch</span> l.ch {
<span class="co">// [...]</span>
}

<span class="kw">func</span> (l *Lexer) skipWhitespace() {
    <span class="kw">for</span> l.ch == &#39; &#39; || l.ch == <span class="ch">&#39;\t&#39;</span> || l.ch == <span class="ch">&#39;\n&#39;</span> || l.ch == <span class="ch">&#39;\r&#39;</span> {
        l.readChar()
    }
}</code></pre></div>
<p>This little helper function is found in a lot of parsers. Sometimes it's called <code>eatWhitespace</code> and sometimes <code>consumeWhitespace</code> and sometimes something entirely different. Which characters these functions actually skip depends on the language being lexed. Some language implementations do create tokens for newline characters for example and throw parsing errors if they are not at the correct place in the stream of tokens. We skip over newline characters to make the parsing step later on a little easier.</p>
<p>With <code>skipWhitespace()</code> in place, the lexer trips over the <code>5</code> in the <code>let five = 5;</code> part of our test input. And that's right, it doesn't know yet how to turn numbers into tokens. It's time to add this.</p>
<p>As we did previously for identifiers, we now need to add more functionality to the <code>default</code> branch of our switch statement.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
    <span class="kw">var</span> tok token.Token

    l.skipWhitespace()

    <span class="kw">switch</span> l.ch {
<span class="co">// [...]</span>
    <span class="kw">default</span>:
        <span class="kw">if</span> isLetter(l.ch) {
            tok.Literal = l.readIdentifier()
            tok.Type = token.LookupIdent(tok.Literal)
            <span class="kw">return</span> tok
        } <span class="kw">else</span> <span class="kw">if</span> isDigit(l.ch) {
            tok.Type = token.INT
            tok.Literal = l.readNumber()
            <span class="kw">return</span> tok
        } <span class="kw">else</span> {
            tok = newToken(token.ILLEGAL, l.ch)
        }
    }
<span class="co">// [...]</span>
}

<span class="kw">func</span> (l *Lexer) readNumber() <span class="dt">string</span> {
    position := l.position
    <span class="kw">for</span> isDigit(l.ch) {
        l.readChar()
    }
    <span class="kw">return</span> l.input[position:l.position]
}

<span class="kw">func</span> isDigit(ch <span class="dt">byte</span>) <span class="dt">bool</span> {
    <span class="kw">return</span> &#39;<span class="dv">0</span>&#39; &lt;= ch &amp;&amp; ch &lt;= &#39;<span class="dv">9</span>&#39;
}</code></pre></div>
<p>As you can see, the added code closely mirrors the part concerned with reading identifiers and keywords. The <code>readNumber</code> method is exactly the same as <code>readIdentifier</code> except for its usage of <code>isDigit</code> instead of <code>isLetter</code>. We could probably generalize this by passing in the character-identifying functions as arguments, but won't, for simplicity's sake and ease of understanding.</p>
<p>The <code>isDigit</code> function is as simple as <code>isLetter</code>. It just returns whether the passed in byte is a Latin digit between <code>0</code> and <code>9</code>.</p>
<p>With this added, our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer 0.008s</code></pre></div>
<p>I don't know if you noticed, but we simplified things a lot in <code>readNumber</code>. We only read in <em>integers</em>. What about floats? Or numbers in hex notation? Octal notation? We ignore them and just say that Monkey doesn't support this. Of course, the reason for this is again the educational aim and limited scope of this book.</p>
<p>It's time to pop the champagne and celebrate: we successfully turned the small subset of the Monkey language we used in the our test case into tokens!</p>
<p>With this victory under our belt, it's easy to extend the lexer so it can tokenize a lot more of Monkey source code.</p>
<h2 id="extending-our-token-set-and-lexer">1.4 - Extending our Token Set and Lexer</h2>
<p>In order to eliminate the need to jump between packages when later writing our parser, we need to extend our lexer so it can recognize more of the Monkey language and output more tokens. So in this section we will add support for <code>==</code>, <code>!</code>, <code>!=</code>, <code>-</code>, <code>/</code>, <code>*</code>, <code>&lt;</code>, <code>&gt;</code> and the keywords <code>true</code>, <code>false</code>, <code>if</code>, <code>else</code> and <code>return</code>.</p>
<p>The new tokens we will need to add, build and output can be classified as one of these three: one-character token (e.g. <code>-</code>), two-character token (e.g. <code>==</code>) and keyword token (e.g. <code>return</code>). We already know how to handle one-character and keyword tokens, so we add support for these first, before extending the lexer for two-character tokens.</p>
<p>Adding support for <code>-</code>, <code>/</code>, <code>*</code>, <code>&lt;</code> and <code>&gt;</code> is trivial. The first thing we need to do, of course, is modify the input of our test case in <code>lexer/lexer_test.go</code> to include these characters. Just like we did before. In the code accompanying this chapter you can also find the extended <code>tests</code> table, which I won't show in the remainder of this chapter, in order to save space and to keep you from getting bored.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>
<span class="st">`</span>

<span class="co">// [...]</span>
}</code></pre></div>
<p>Note that although the input looks like an actual piece of Monkey source code, some lines don't really make sense, with gibberish like <code>!-/*5</code>. That's okay. The lexer's job is not to tell us whether code makes sense, works or contains errors. That comes in a later stage. The lexer should only turn this input into tokens. For that reason the test cases I write for lexers cover all tokens and also try to provoke off-by-one errors, edge cases at end-of-file, newline handling, multi-digit number parsing and so on. That's why the &quot;code&quot; looks like gibberish.</p>
<p>Running the test we get <code>undefined:</code> errors, because the tests contain references to undefined <code>TokenType</code>s. To fix them we add the following constants to <code>token/token.go</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>

    <span class="co">// Operators</span>
    ASSIGN   = <span class="st">&quot;=&quot;</span>
    PLUS     = <span class="st">&quot;+&quot;</span>
    MINUS    = <span class="st">&quot;-&quot;</span>
    BANG     = <span class="st">&quot;!&quot;</span>
    ASTERISK = <span class="st">&quot;*&quot;</span>
    SLASH    = <span class="st">&quot;/&quot;</span>

    LT = <span class="st">&quot;&lt;&quot;</span>
    GT = <span class="st">&quot;&gt;&quot;</span>

<span class="co">// [...]</span>
)</code></pre></div>
<p>With the new constants added, the tests still fail, because we don't return the tokens with the expected <code>TokenType</code>s.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
--- FAIL: TestNextToken (0.00s)
  lexer_test.go:84: tests[36] - tokentype wrong. expected=&quot;!&quot;, got=&quot;ILLEGAL&quot;
FAIL
FAIL    monkey/lexer 0.007s</code></pre></div>
<p>Turning these tests from failing to passing requires us to extend our switch statement in the <code>NextToken()</code> method of <code>Lexer</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
<span class="co">// [...]</span>
    <span class="kw">switch</span> l.ch {
    <span class="kw">case</span> &#39;=&#39;:
        tok = newToken(token.ASSIGN, l.ch)
    <span class="kw">case</span> &#39;+&#39;:
        tok = newToken(token.PLUS, l.ch)
    <span class="kw">case</span> &#39;-&#39;:
        tok = newToken(token.MINUS, l.ch)
    <span class="kw">case</span> &#39;!&#39;:
        tok = newToken(token.BANG, l.ch)
    <span class="kw">case</span> &#39;/&#39;:
        tok = newToken(token.SLASH, l.ch)
    <span class="kw">case</span> &#39;*&#39;:
        tok = newToken(token.ASTERISK, l.ch)
    <span class="kw">case</span> &#39;&lt;&#39;:
        tok = newToken(token.LT, l.ch)
    <span class="kw">case</span> &#39;&gt;&#39;:
        tok = newToken(token.GT, l.ch)
    <span class="kw">case</span> &#39;;&#39;:
        tok = newToken(token.SEMICOLON, l.ch)
    <span class="kw">case</span> &#39;,&#39;:
        tok = newToken(token.COMMA, l.ch)
<span class="co">// [...]</span>
}</code></pre></div>
<p>The tokens are now added and the cases of the switch statement have been reordered to reflect the structure of the constants in <code>token/token.go</code>. This small change makes our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer 0.007s</code></pre></div>
<p>The new one-character tokens have been successfully added. Next step: add the new keywords <code>true</code>, <code>false</code>, <code>if</code>, <code>else</code> and <code>return</code>.</p>
<p>Again, the first step is to extend the input in our test to include these new keywords. Here is what the <code>input</code> in <code>TestNextToken</code> looks like now:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>

<span class="st">if (5 &lt; 10) {</span>
<span class="st">    return true;</span>
<span class="st">} else {</span>
<span class="st">    return false;</span>
<span class="st">}`</span>
<span class="co">// [...]</span>
}</code></pre></div>
<p>The tests do not even compile since the references in the test expectations to the new keywords are undefined. Fixing that, again, means just adding new constants and in this case, adding the keywords to the lookup table for <code>LookupIdent()</code>.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>

    <span class="co">// Keywords</span>
    FUNCTION = <span class="st">&quot;FUNCTION&quot;</span>
    LET      = <span class="st">&quot;LET&quot;</span>
    TRUE     = <span class="st">&quot;TRUE&quot;</span>
    FALSE    = <span class="st">&quot;FALSE&quot;</span>
    IF       = <span class="st">&quot;IF&quot;</span>
    ELSE     = <span class="st">&quot;ELSE&quot;</span>
    RETURN   = <span class="st">&quot;RETURN&quot;</span>
)

<span class="kw">var</span> keywords = <span class="kw">map</span>[<span class="dt">string</span>]TokenType{
    <span class="st">&quot;fn&quot;</span>:     FUNCTION,
    <span class="st">&quot;let&quot;</span>:    LET,
    <span class="st">&quot;true&quot;</span>:   TRUE,
    <span class="st">&quot;false&quot;</span>:  FALSE,
    <span class="st">&quot;if&quot;</span>:     IF,
    <span class="st">&quot;else&quot;</span>:   ELSE,
    <span class="st">&quot;return&quot;</span>: RETURN,
}</code></pre></div>
<p>And it turns out that we not only fixed the compilation error by fixing references to undefined variables, we even made the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer 0.007s</code></pre></div>
<p>The lexer now recognizes the new keywords and the necessary changes were trivial, easy to predict and easy to make. I'd say a pat on the back is in order. We did a great job!</p>
<p>But before we can move onto the next chapter and start with our parser, we still need to extend the lexer so it recognizes tokens that are composed of two characters. The tokens we want to support look like this in the source code: <code>==</code> and <code>!=</code>.</p>
<p>At first glance you may be thinking: &quot;why not add a new case to our switch statement and be done with it?&quot; Since our switch statement takes the current character <code>l.ch</code> as the expression to compare against the cases, we can't just add new cases like <code>case &quot;==&quot;</code> - the compiler won't let us. We can't compare our <code>l.ch</code> byte with strings like <code>&quot;==&quot;</code>.</p>
<p>What we can do instead is to reuse the existing branches for <code>'='</code> and <code>'!'</code> and extend them. So what we're going to do is to look ahead in the input and then determine whether to return a token for <code>=</code> or <code>==</code>. After extending <code>input</code> in <code>lexer/lexer_test.go</code> again, it now looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>

<span class="st">if (5 &lt; 10) {</span>
<span class="st">    return true;</span>
<span class="st">} else {</span>
<span class="st">    return false;</span>
<span class="st">}</span>

<span class="st">10 == 10;</span>
<span class="st">10 != 9;</span>
<span class="st">`</span>
<span class="co">// [...]</span>
}</code></pre></div>
<p>Before we start working on the switch statement in <code>NextToken()</code>, we need to add a new helper method defined on <code>*Lexer</code> called <code>peekChar()</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) peekChar() <span class="dt">byte</span> {
    <span class="kw">if</span> l.readPosition &gt;= <span class="bu">len</span>(l.input) {
        <span class="kw">return</span> <span class="dv">0</span>
    } <span class="kw">else</span> {
        <span class="kw">return</span> l.input[l.readPosition]
    }
}</code></pre></div>
<p><code>peekChar()</code> is really similar to <code>readChar()</code>, except that it doesn't increment <code>l.position</code> and <code>l.readPosition</code>. We only want to &quot;peek&quot; ahead in the input and not move around in it, so we know what a call to <code>readChar()</code> would return. Most lexers and parser have such a &quot;peek&quot; function that looks ahead and most of the time it only returns the immediately next character. The difficulty of parsing different languages often comes down to how far you have to peek ahead (or look backwards!) in the source code to make sense of it.</p>
<p>With <code>peekChar()</code> added, the code with the updated test input doesn't compile. Of course, since we're referencing undefined token constants in the tests. Fixing that, again, is easy:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>

    EQ     = <span class="st">&quot;==&quot;</span>
    NOT_EQ = <span class="st">&quot;!=&quot;</span>

<span class="co">// [...]</span>
)</code></pre></div>
<p>With the references to <code>token.EQ</code> and <code>token.NOT_EQ</code> in the tests for the lexer fixed, running <code>go test</code> now returns the correct failure message:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
--- FAIL: TestNextToken (0.00s)
  lexer_test.go:118: tests[66] - tokentype wrong. expected=&quot;==&quot;, got=&quot;=&quot;
FAIL
FAIL    monkey/lexer 0.007s</code></pre></div>
<p>When the lexer comes upon a <code>==</code> in the input it creates two <code>token.ASSIGN</code> tokens instead of one <code>token.EQ</code> token. The solution is to use our new <code>peekChar()</code> method. In the branches of the switch statement for <code>'='</code> and <code>'!'</code> we &quot;peek&quot; ahead. If the next token is also a <code>=</code> we create either a <code>token.EQ</code> or a <code>token.NOT_EQ</code> token:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
<span class="co">// [...]</span>
    <span class="kw">switch</span> l.ch {
    <span class="kw">case</span> &#39;=&#39;:
        <span class="kw">if</span> l.peekChar() == &#39;=&#39; {
            ch := l.ch
            l.readChar()
            tok = token.Token{Type: token.EQ, Literal: <span class="dt">string</span>(ch) + <span class="dt">string</span>(l.ch)}
        } <span class="kw">else</span> {
            tok = newToken(token.ASSIGN, l.ch)
        }
<span class="co">// [...]</span>
    <span class="kw">case</span> &#39;!&#39;:
        <span class="kw">if</span> l.peekChar() == &#39;=&#39; {
            ch := l.ch
            l.readChar()
            tok = token.Token{Type: token.NOT_EQ, Literal: <span class="dt">string</span>(ch) + <span class="dt">string</span>(l.ch)}
        } <span class="kw">else</span> {
            tok = newToken(token.BANG, l.ch)
        }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Note that we save <code>l.ch</code> in a local variable before calling <code>l.readChar()</code> again. This way we don't lose the current character and can safely advance the lexer so it leaves the <code>NextToken()</code> with <code>l.position</code> and <code>l.readPosition</code> in the correct state. If we were to start supporting more two-character tokens in Monkey, we should probably abstract the behaviour away in a method called <code>makeTwoCharToken</code> that peeks and advances if it found the right token. Because those two branches look awfully similar. For now though <code>==</code> and <code>!=</code> are the only two-character tokens in Monkey, so let's leave it as it is and run our tests again to make sure it works:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer 0.006s</code></pre></div>
<p>They pass! We did it! The lexer can now produce the extended set of tokens and we're ready to write our parser. But before we do that, let's lay another ground stone we can build upon in the coming chapters...</p>
<h2 id="start-of-a-repl">1.5 - Start of a REPL</h2>
<p>The Monkey language needs a REPL. REPL stands for &quot;Read Eval Print Loop&quot; and you probably know what it is from other interpreted languages: Python has a REPL, Ruby has one, every JavaScript runtime has one, most Lisps have one and a lot of other languages too. Sometimes the REPL is called &quot;console&quot;, sometimes &quot;interactive mode&quot;. The concept is the same: the REPL reads input, sends it to the interpreter for evaluation, prints the result/output of the interpreter and starts again. Read, Eval, Print, Loop.</p>
<p>We don't know how to fully &quot;Eval&quot; Monkey source code yet. We only have one part of the process that hides behind &quot;Eval&quot;: we can tokenize Monkey source code. But we also know how to read and print something, and I don't think looping poses a problem.</p>
<p>Here is a REPL that tokenizes Monkey source code and prints the tokens. Later on, we will expand on this and add parsing and evaluation to it.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// repl/repl.go</span>

<span class="kw">package</span> repl

<span class="kw">import</span> (
    <span class="st">&quot;bufio&quot;</span>
    <span class="st">&quot;fmt&quot;</span>
    <span class="st">&quot;io&quot;</span>
    <span class="st">&quot;monkey/lexer&quot;</span>
    <span class="st">&quot;monkey/token&quot;</span>
)

<span class="kw">const</span> PROMPT = <span class="st">&quot;&gt;&gt; &quot;</span>

<span class="kw">func</span> Start(in io.Reader, out io.Writer) {
    scanner := bufio.NewScanner(in)

    <span class="kw">for</span> {
        fmt.Printf(PROMPT)
        scanned := scanner.Scan()
        <span class="kw">if</span> !scanned {
            <span class="kw">return</span>
        }

        line := scanner.Text()
        l := lexer.New(line)

        <span class="kw">for</span> tok := l.NextToken(); tok.Type != token.EOF; tok = l.NextToken() {
            fmt.Printf(<span class="st">&quot;%+v</span><span class="ch">\n</span><span class="st">&quot;</span>, tok)
        }
    }
}</code></pre></div>
<p>This is all pretty straightforward: read from the input source until encountering a newline, take the just read line and pass it to an instance of our lexer and finally print all the tokens the lexer gives us until we encounter EOF.</p>
<p>In a <code>main.go</code> file (which we've been missing until now!) we welcome the user of the REPL and start it:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// main.go</span>

<span class="kw">package</span> main

<span class="kw">import</span> (
    <span class="st">&quot;fmt&quot;</span>
    <span class="st">&quot;os&quot;</span>
    <span class="st">&quot;os/user&quot;</span>
    <span class="st">&quot;monkey/repl&quot;</span>
)

<span class="kw">func</span> main() {
    user, err := user.Current()
    <span class="kw">if</span> err != <span class="ot">nil</span> {
        <span class="bu">panic</span>(err)
    }
    fmt.Printf(<span class="st">&quot;Hello %s! This is the Monkey programming language!</span><span class="ch">\n</span><span class="st">&quot;</span>,
        user.Username)
    fmt.Printf(<span class="st">&quot;Feel free to type in commands</span><span class="ch">\n</span><span class="st">&quot;</span>)
    repl.Start(os.Stdin, os.Stdout)
}</code></pre></div>
<p>And with that we can now interactively produce tokens:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let add = fn(x, y) { x + y; };
{Type:let Literal:let}
{Type:IDENT Literal:add}
{Type:= Literal:=}
{Type:fn Literal:fn}
{Type:( Literal:(}
{Type:IDENT Literal:x}
{Type:, Literal:,}
{Type:IDENT Literal:y}
{Type:) Literal:)}
{Type:{ Literal:{}
{Type:IDENT Literal:x}
{Type:+ Literal:+}
{Type:IDENT Literal:y}
{Type:; Literal:;}
{Type:} Literal:}}
{Type:; Literal:;}
&gt;&gt;</code></pre></div>
<p>Perfect! And <strong>now</strong> it's time to start parsing these tokens.</p>
<h1 id="parsing">Parsing</h1>
<h2 id="parsers">2.1 - Parsers</h2>
<p>Everyone who has ever programmed has probably heard about parsers, mostly by encountering a &quot;parser error&quot;. Or maybe heard or even said something like &quot;we need to parse this&quot;, &quot;after it's parsed&quot;, &quot;the parser blows up with this input&quot;. The word &quot;parser&quot; is as common as &quot;compiler&quot;, &quot;interpreter&quot; and &quot;programming language&quot;. Everyone knows that parsers <em>exist</em>. They have to, right? Because who else would be responsible for &quot;parser errors&quot;?</p>
<p>But what is a parser exactly? What is its job and how does it do it? This is what <a href="https://en.wikipedia.org/wiki/Parsing#Parser">Wikipedia has to say</a>:</p>
<blockquote>
<p>A parser is a software component that takes input data (frequently text) and builds a data structure  often some kind of parse tree, abstract syntax tree or other hierarchical structure  giving a structural representation of the input, checking for correct syntax in the process. [...] The parser is often preceded by a separate lexical analyser, which creates tokens from the sequence of input characters;</p>
</blockquote>
<p>For a Wikipedia article about a computer science topic this excerpt is remarkably easy to understand. We can even recognize our lexer in there!</p>
<p>A parser turns its input into a data structure that represents the input. That sounds pretty abstract, so let me illustrate this with an example. Here is a little bit of JavaScript:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;</span> <span class="kw">var</span> input <span class="op">=</span> <span class="st">&#39;{&quot;name&quot;: &quot;Thorsten&quot;, &quot;age&quot;: 28}&#39;</span><span class="op">;</span>
<span class="op">&gt;</span> <span class="kw">var</span> output <span class="op">=</span> <span class="va">JSON</span>.<span class="at">parse</span>(input)<span class="op">;</span>
<span class="op">&gt;</span> output
<span class="op">{</span> <span class="dt">name</span><span class="op">:</span> <span class="st">&#39;Thorsten&#39;</span><span class="op">,</span> <span class="dt">age</span><span class="op">:</span> <span class="dv">28</span> <span class="op">}</span>
<span class="op">&gt;</span> <span class="va">output</span>.<span class="at">name</span>
<span class="st">&#39;Thorsten&#39;</span>
<span class="op">&gt;</span> <span class="va">output</span>.<span class="at">age</span>
<span class="dv">28</span>
<span class="op">&gt;</span></code></pre></div>
<p>Our <code>input</code> is just some text, a string. We then pass it to a parser hidden behind the <code>JSON.parse</code> function and receive an output value. This output is the data structure that represents the input: a JavaScript object with two fields named <code>name</code> and <code>age</code>, their values also corresponding to the input. We can now easily work with this data structure as demonstrated by accessing the <code>name</code> and <code>age</code> fields.</p>
<p>&quot;But&quot;, I hear you say, &quot;a JSON parser isn't the same as a parser for a programming language! They're different!&quot; I can see where you're coming from with this, but no, they are not different. At least not on a conceptual level. A JSON parser takes text as input and builds a data structure that represents the input. That's exactly what the parser of a programming language does. The difference is that in the case of a JSON parser you can <em>see</em> the data structure when looking at the input. Whereas if you look at this</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> ((<span class="dv">5</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> <span class="dv">3</span>) <span class="op">==</span> <span class="dv">91</span>) <span class="op">{</span> <span class="cf">return</span> <span class="at">computeStuff</span>(input1<span class="op">,</span> input2)<span class="op">;</span> <span class="op">}</span></code></pre></div>
<p>it's not immediately obvious how this could be represented with a data structure. This is why, at least for me, they seemed different on a deeper, conceptional level. My guess is that this perception of conceptional difference is mainly due to a lack of familiarity with programming language parsers and the data structures they produce. I have a lot more experience with writing JSON, parsing it with a parser and inspecting the output of the parser than with parsing programming languages. As users of programming languages we seldom get to see or interact with the parsed source code, with its internal representation. Lisp programmers are the exception to the rule -- in Lisp the data structures used to represent the source code are the ones used by a Lisp user. The parsed source code is easily accessible as data in the program. &quot;Code is data, data is code&quot; is something you hear a lot from Lisp programmers.</p>
<p>So, in order to bring our conceptual understanding of programming language parsers up to the level of our familiarity and intuitiveness with parsers of serialization languages (like JSON, YAML, TOML, INI, and so on) we need to understand the data structures they produce.</p>
<p>In most interpreters and compilers the data structure used for the internal representation of the source code is called a &quot;syntax tree&quot; or an &quot;abstract syntax tree&quot; (AST for short). The &quot;abstract&quot; is based on the fact that certain details visible in the source code are omitted in the AST. Semicolons, newlines, whitespace, comments, braces, bracket and parentheses -- depending on the language and the parser these details are not represented in the AST, but merely guide the parser when constructing it.</p>
<p>A fact to note is that there is not one true, universal AST format that's used by every parser. Their implementations are all pretty similar, the concept is the same, but they differ in details. The concrete implementation depends on the programming language being parsed.</p>
<p>A small example should make things clearer. Let's say that we have the following source code:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (<span class="dv">3</span> <span class="op">*</span> <span class="dv">5</span> <span class="op">&gt;</span> <span class="dv">10</span>) <span class="op">{</span>
  <span class="cf">return</span> <span class="st">&quot;hello&quot;</span><span class="op">;</span>
<span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
  <span class="cf">return</span>  <span class="st">&quot;goodbye&quot;</span><span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>And let's say we are using JavaScript, have a <code>MagicLexer</code>, a <code>MagicParser</code> and the AST is built out of JavaScript objects, then the parsing step might produce something like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;</span> <span class="kw">var</span> input <span class="op">=</span> <span class="st">&#39;if (3 * 5 &gt; 10) { return &quot;hello&quot;; } else { return &quot;goodbye&quot;; }&#39;</span><span class="op">;</span>
<span class="op">&gt;</span> <span class="kw">var</span> tokens <span class="op">=</span> <span class="va">MagicLexer</span>.<span class="at">parse</span>(input)<span class="op">;</span>
<span class="op">&gt;</span> <span class="va">MagicParser</span>.<span class="at">parse</span>(tokens)<span class="op">;</span>
<span class="op">{</span>
  <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;if-statement&quot;</span><span class="op">,</span>
  <span class="dt">condition</span><span class="op">:</span> <span class="op">{</span>
    <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;operator-expression&quot;</span><span class="op">,</span>
    <span class="dt">operator</span><span class="op">:</span> <span class="st">&quot;&gt;&quot;</span><span class="op">,</span>
    <span class="dt">left</span><span class="op">:</span> <span class="op">{</span>
      <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;operator-expression&quot;</span><span class="op">,</span>
      <span class="dt">operator</span><span class="op">:</span> <span class="st">&quot;*&quot;</span><span class="op">,</span>
      <span class="dt">left</span><span class="op">:</span> <span class="op">{</span> <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;integer-literal&quot;</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="dv">3</span> <span class="op">},</span>
      <span class="dt">right</span><span class="op">:</span> <span class="op">{</span> <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;integer-literal&quot;</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="dv">5</span> <span class="op">}</span>
    <span class="op">},</span>
    <span class="dt">right</span><span class="op">:</span> <span class="op">{</span> <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;integer-literal&quot;</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="dv">10</span> <span class="op">}</span>
  <span class="op">},</span>
  <span class="dt">consequence</span><span class="op">:</span> <span class="op">{</span>
    <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;return-statement&quot;</span><span class="op">,</span>
    <span class="dt">returnValue</span><span class="op">:</span> <span class="op">{</span> <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;string-literal&quot;</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="st">&quot;hello&quot;</span> <span class="op">}</span>
  <span class="op">},</span>
  <span class="dt">alternative</span><span class="op">:</span> <span class="op">{</span>
    <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;return-statement&quot;</span><span class="op">,</span>
    <span class="dt">returnValue</span><span class="op">:</span> <span class="op">{</span> <span class="dt">type</span><span class="op">:</span> <span class="st">&quot;string-literal&quot;</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="st">&quot;goodbye&quot;</span> <span class="op">}</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>As you can see, the output of the parser, the AST, <em>is</em> pretty abstract: there are no parentheses, no semicolons and no braces. But it does represent the source code pretty accurately, don't you think? I bet that you can now &quot;see&quot; the AST structure when looking back at the source code!</p>
<p>So, this is what parsers do. They take source code as input (either as text or tokens) and produce a data structure which represents this source code. While building up the data structure, they unavoidably analyse the input, checking that it conforms to the expected structure. Thus the process of parsing is also called syntactic analysis.</p>
<p>In this chapter, we're going to write our parser for the Monkey programming language. Its input will be the tokens we defined in the previous chapter, produced by the lexer we already wrote. We will define our own AST, suited to our needs as interpreters of the Monkey programming language, and construct instances of this AST while recursively parsing tokens.</p>
<h2 id="why-not-a-parser-generator">2.2 - Why not a parser generator?</h2>
<p>Maybe you've already heard about parser generators, like the tools yacc, bison or ANTLR. Parser generators are tools that, when fed with a formal description of a language, produce parsers as their output. This output is code that can then be compiled/interpreted and itself fed with source code as input to produce a syntax tree.</p>
<p>There are a lot of parser generators, differing in the format of the input they accept and the language of the output they produce. The majority of them use a <em>context-free grammar</em> (CFG) as their input. A CFG is a set of rules that describe how to form correct (valid according to the syntax) sentences in a language. The most common notational formats of CFGs are the Backus-Naur Form (BNF) or the Extended Backus-Naur Form (EBNF).</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">PrimaryExpression ::= &quot;this&quot;
                    | ObjectLiteral
                    | ( &quot;(&quot; Expression &quot;)&quot; )
                    | Identifier
                    | ArrayLiteral
                    | Literal
Literal ::= ( &lt;DECIMAL_LITERAL&gt;
            | &lt;HEX_INTEGER_LITERAL&gt;
            | &lt;STRING_LITERAL&gt;
            | &lt;BOOLEAN_LITERAL&gt;
            | &lt;NULL_LITERAL&gt;
            | &lt;REGULAR_EXPRESSION_LITERAL&gt; )
Identifier ::= &lt;IDENTIFIER_NAME&gt;
ArrayLiteral ::= &quot;[&quot; ( ( Elision )? &quot;]&quot;
                 | ElementList Elision &quot;]&quot;
                 | ( ElementList )? &quot;]&quot; )
ElementList ::= ( Elision )? AssignmentExpression
                ( Elision AssignmentExpression )*
Elision ::= ( &quot;,&quot; )+
ObjectLiteral ::= &quot;{&quot; ( PropertyNameAndValueList )? &quot;}&quot;
PropertyNameAndValueList ::= PropertyNameAndValue ( &quot;,&quot; PropertyNameAndValue
                                                  | &quot;,&quot; )*
PropertyNameAndValue ::= PropertyName &quot;:&quot; AssignmentExpression
PropertyName ::= Identifier
              | &lt;STRING_LITERAL&gt;
              | &lt;DECIMAL_LITERAL&gt;</code></pre></div>
<p>This is part of <a href="http://tomcopeland.blogs.com/EcmaScript.html">a full description</a> of the EcmaScript syntax, in BNF. A parser generator would take something like this and turn it into compilable C code, for example.</p>
<p>Maybe you've also heard that you should use a parser generator instead of writing a parser by hand. &quot;Just skip this part&quot;, they say, &quot;it's a solved problem.&quot; The reason for this recommendation is that parsers are exceptionally well suited to being automatically generated. Parsing is one of the most well-understood branches of computer science and really smart people have already invested a lot of time into the problems of parsing. The results of their work are CFG, BNF, EBNF, parser generators and advanced parsing techniques used in them. Why shouldn't you take advantage of that?</p>
<p>I don't think that learning to write your own parser is a waste of time. I actually think it's immensely valuable. Only after having written your own parser, or at least attempted to, will you see the benefits parser generators provide, the drawbacks they have and the problems they solve. For me the concept of a parser generator only &quot;clicked&quot; after I wrote my first parser. I looked at it and only then really and truly understood how it's possible to generate this code automatically.</p>
<p>Most people, that recommend using a parser generator, when others want to get started with interpreters and compilers only do so because they've written a parser themselves before. They've seen the problems and solutions available and decided it's better to use an existing tool for the job. And they're correct - when you want to get something done and are in a production environment, where correctness and robustness are priorities. Of course you shouldn't try to write your own parser then, especially not if you've never written one before.</p>
<p>But we are here to learn, we want to understand how parsers work. And it's my opinion that the best way to do that is by getting our hands dirty and writing a parser ourselves. Also, I think it's immense fun.</p>
<h2 id="writing-a-parser-for-the-monkey-programming-language">2.3 - Writing a Parser for the Monkey Programming Language</h2>
<p>There are two main strategies when parsing a programming language: top-down parsing or bottom-up parsing. A lot of slightly different forms of each strategy exist. For example, &quot;recursive descent parsing&quot;, &quot;Early parsing&quot; or &quot;predictive parsing&quot; are all variations of top down parsing.</p>
<p>The parser we are going to write is a recursive descent parser. And in particular, it's a &quot;top down operator precedence&quot; parser, sometimes called &quot;Pratt parser&quot;, after its inventor Vaughan Pratt.</p>
<p>I won't go into the details of different parsing strategies here, because this is neither the place nor am I qualified enough to accurately describe them. Instead, let me just say, that the difference between top down and bottom up parsers is that the former starts with constructing root node of the AST and then descends while the latter does it the other way around. A recursive descent parser, which works from the top down, is often recommended for newcomers to parsing, since it closely mirrors the way we think about ASTs and their construction. I personally found the recursive approach starting at the root node really nice, even though it took writing some code before the concept really clicked. Which is another reason to get started with the code instead of delving into parsing strategies.</p>
<p>Now, when writing a parser ourselves, we have to make some trade-offs, yes. Our parser won't be the fastest of all time, we won't have formal proof of its correctness and its error-recovery process and detection of erroneous syntax won't be bullet proof. The last one is especially hard to get right without extensive study of the theory surrounding parsing. But what we're going to have is a fully working parser for the Monkey programming language that's open for extensions and improvements, easy to understand and a great start to further dive into the topic of parsing, if one were so inclined.</p>
<p>We're going to start by parsing statements: let and return statements. When we can parse statements and the basic structure of our parser stands, we will look at expressions and how to parse these (this is were Vaughan Pratt will come into play). Afterwards we extend the parser to make it capable of parsing a large subset of the Monkey programming language. As we go along we build up the necessary structures for our AST.</p>
<h2 id="parsers-first-steps-parsing-let-statements">2.4 - Parser's first steps: parsing let statements</h2>
<p>In Monkey, variable bindings are statements of the following form:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="kw">let</span> y <span class="op">=</span> <span class="dv">10</span><span class="op">;</span>
<span class="kw">let</span> foobar <span class="op">=</span> <span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">5</span>)<span class="op">;</span>
<span class="kw">let</span> barfoo <span class="op">=</span> <span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span> / <span class="dv">10</span> <span class="op">+</span> <span class="dv">18</span> <span class="op">-</span> <span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">5</span>) <span class="op">+</span> <span class="at">multiply</span>(<span class="dv">124</span>)<span class="op">;</span>
<span class="kw">let</span> anotherName <span class="op">=</span> barfoo<span class="op">;</span></code></pre></div>
<p>These statements are called &quot;let statements&quot; and bind a value to the given name. <code>let x = 5;</code> binds the value <code>5</code> to the name <code>x</code>. Our job in this section is to parse let statements correctly. For now we're going to skip parsing the expressions that produce the value of a given variable binding and come back to this later - as soon as we know how to parse expressions on their own.</p>
<p>What does it mean to parse let statements correctly? It means that the parser produces an AST that accurately represents the information contained in the original let statement. That sounds reasonable, but we don't have an AST yet, nor do we know what it should look like. So our first task is to take a close look at Monkey source code and see how it's structured, so that we can define the necessary parts of an AST that's able to accurately represent let statements.</p>
<p>Here is a fully valid program written in Monkey:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">10</span><span class="op">;</span>
<span class="kw">let</span> y <span class="op">=</span> <span class="dv">15</span><span class="op">;</span>

<span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(a<span class="op">,</span> b) <span class="op">{</span>
  <span class="cf">return</span> a <span class="op">+</span> b<span class="op">;</span>
<span class="op">};</span></code></pre></div>
<p>Programs in Monkey are a series of statements. In this example we can see three statements, three variable bindings - let statements - of the following form:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">let &lt;identifier&gt; = &lt;expression&gt;;</code></pre></div>
<p>A let statement in Monkey consists of two changing parts: an identifier and an expression. In the example above <code>x</code>, <code>y</code> and <code>add</code> are identifiers. <code>10</code>, <code>15</code> and the function literal are expressions.</p>
<p>Before we go on, a few words about the difference between statements and expressions are needed. Expressions produce values, statements don't. <code>let x = 5</code> doesn't produce a value, whereas <code>5</code> does (the value it produces is <code>5</code>). A <code>return 5;</code> statement doesn't produce a value, but <code>add(5, 5)</code> does. This distinction - expressions produce values, statements don't - changes depending on who you ask, but it's good enough for our needs.</p>
<p>What exactly an expression is or a statement, what produces values and what doesn't, depends on the programming language. In some languages function literals (e.g.: <code>fn(x, y) { return x + y; }</code>) are expressions and can be used in any place where any other expression is allowed. In other programming languages though function literals can only be part of a function declaration statement, in the top level of the program. Some languages also have &quot;if expressions&quot;, where conditionals are expressions and produce a value. This is entirely dependent on the choices the language designers made. As you'll see, a lot of things in Monkey are expressions, including function literals.</p>
<p>Back to our AST. Looking at the example above, we can see that it needs two different types of nodes: expressions and statements. Take a look at the start of our AST:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">package</span> ast

<span class="kw">type</span> Node <span class="kw">interface</span> {
    TokenLiteral() <span class="dt">string</span>
}

<span class="kw">type</span> Statement <span class="kw">interface</span> {
    Node
    statementNode()
}

<span class="kw">type</span> Expression <span class="kw">interface</span> {
    Node
    expressionNode()
}</code></pre></div>
<p>Here we have three interfaces called <code>Node</code>, <code>Statement</code> and <code>Expression</code>. Every node in our AST has to implement the <code>Node</code> interface, meaning it has to provide a <code>TokenLiteral()</code> method that returns the literal value of the token it's associated with. <code>TokenLiteral()</code> will be used only for debugging and testing. The AST we are going to construct consists solely of <code>Node</code>s that are connected to each other - it's a tree after all. Some of these nodes implement the <code>Statement</code> and some the <code>Expression</code> interface. These interfaces only contain dummy methods called <code>statementNode</code> and <code>expressionNode</code> respectively. They are not strictly necessary but help us by guiding the Go compiler and possibly causing it to throw errors when we use a <code>Statement</code> where an <code>Expression</code> should've been used, and vice versa.</p>
<p>And here is our first implementation of <code>Node</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> Program <span class="kw">struct</span> {
    Statements []Statement
}

<span class="kw">func</span> (p *Program) TokenLiteral() <span class="dt">string</span> {
    <span class="kw">if</span> <span class="bu">len</span>(p.Statements) &gt; <span class="dv">0</span> {
        <span class="kw">return</span> p.Statements[<span class="dv">0</span>].TokenLiteral()
    } <span class="kw">else</span> {
        <span class="kw">return</span> <span class="st">&quot;&quot;</span>
    }
}</code></pre></div>
<p>This <code>Program</code> node is going to be the root node of every AST our parser produces. Every valid Monkey program is a series of statements. These statements are contained in the <code>Program.Statements</code>, which is just a slice of AST nodes that implement the <code>Statement</code> interface.</p>
<p>With these basic building blocks for our AST construction defined, let's think about what a node for a variable binding in the form of <code>let x = 5;</code> might look like. Which fields should it have? Definitely one for the name of the variable. And it also needs a field that points to the expression on the right side of the equal sign. It needs to be able to point to any expression. It can't just point to a literal value (the integer literal <code>5</code> in this case), since every expression is valid after the equal sign: <code>let x = 5 * 5</code> is as valid as <code>let y = add(2, 2) * 5 / 10;</code>. And then the node also needs to keep track of the token the AST node is associated with, so we can implement the <code>TokenLiteral()</code> method. That makes three fields: one for the identifier, one for the expression that produces the value in the let statement and one for the token.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">import</span> <span class="st">&quot;monkey/token&quot;</span>

<span class="co">// [...]</span>

<span class="kw">type</span> LetStatement <span class="kw">struct</span> {
    Token token.Token <span class="co">// the token.LET token</span>
    Name  *Identifier
    Value Expression
}

<span class="kw">func</span> (ls *LetStatement) statementNode()       {}
<span class="kw">func</span> (ls *LetStatement) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> ls.Token.Literal }

<span class="kw">type</span> Identifier <span class="kw">struct</span> {
    Token token.Token <span class="co">// the token.IDENT token</span>
    Value <span class="dt">string</span>
}

<span class="kw">func</span> (i *Identifier) expressionNode()      {}
<span class="kw">func</span> (i *Identifier) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> i.Token.Literal }</code></pre></div>
<p><code>LetStatement</code> has the fields we need: <code>Name</code> to hold the identifier of the binding and <code>Value</code> for the expression that produces the value. The two methods <code>statementNode</code> and <code>TokenLiteral</code> satisfy the <code>Statement</code> and <code>Node</code> interfaces respectively.</p>
<p>To hold the identifier of the binding, the <code>x</code> in <code>let x = 5;</code>, we have the <code>Identifier</code> struct type, which implements the <code>Expression</code> interface. But the identifier in a let statement doesn't produce a value, right? So why is it an <code>Expression</code>? It's to keep things simple. Identifiers in other parts of a Monkey program <strong>do</strong> produce values, e.g.: <code>let x = valueProducingIdentifier;</code>. And to keep the number of different node types small, we'll use <code>Identifier</code> here to represent the name in a variable binding and later reuse it, to represent an identifier as part of or as a complete expression.</p>
<p>With <code>Program</code>, <code>LetStatement</code> and <code>Identifier</code> defined this piece of Monkey source code</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>could be represented by an AST looking like this:</p>
<div class="figure">
<img src="./images/let_statement.png" width="400" />

</div>
<p>Now that we know what it's supposed to look like, the next task is to construct such an AST. So, without further ado here is the beginning of our parser:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">package</span> parser

<span class="kw">import</span> (
    <span class="st">&quot;monkey/ast&quot;</span>
    <span class="st">&quot;monkey/lexer&quot;</span>
    <span class="st">&quot;monkey/token&quot;</span>
)

<span class="kw">type</span> Parser <span class="kw">struct</span> {
    l *lexer.Lexer

    curToken  token.Token
    peekToken token.Token
}

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
    p := &amp;Parser{l: l}

    <span class="co">// Read two tokens, so curToken and peekToken are both set</span>
    p.nextToken()
    p.nextToken()

    <span class="kw">return</span> p
}

<span class="kw">func</span> (p *Parser) nextToken() {
    p.curToken = p.peekToken
    p.peekToken = p.l.NextToken()
}

<span class="kw">func</span> (p *Parser) ParseProgram() *ast.Program {
    <span class="kw">return</span> <span class="ot">nil</span>
}</code></pre></div>
<p>The <code>Parser</code> has three fields: <code>l</code>, <code>curToken</code> and <code>peekToken</code>. <code>l</code> is a pointer to an instance of the lexer, on which we repeatedly call <code>NextToken()</code> to get the next token in the input. <code>curToken</code> and <code>peekToken</code> act exactly like the two &quot;pointers&quot; our lexer has: <code>position</code> and <code>peekPosition</code>. But instead of pointing to a character in the input, they point to the current and the next token. Both are important: we need to look at the <code>curToken</code>, which is the current token under examination, to decide what to do next, and we also need <code>peekToken</code> for this decision if <code>curToken</code> doesn't give us enough information. Think of a single line only containing <code>5;</code>. Then <code>curToken</code> is a <code>token.INT</code> and we need <code>peekToken</code> to decide whether we are at the end of the line or if we are at just the start of an arithmetic expression.</p>
<p>The <code>New</code> function is pretty self-explanatory and the <code>nextToken</code> method is a small helper that advances both <code>curToken</code> and <code>peekToken</code>. But <code>ParseProgram</code> is empty, for now.</p>
<p>Now before we start writing tests and filling out the <code>ParseProgram</code> method I want to show you the basic idea and structure behind a recursive descent parser. That makes it a lot easier to understand our own parser later on. What follows are the major parts of such a parser in pseudocode. Read this carefully and try to understand what happens in the <code>parseProgram</code> function:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">function</span> <span class="at">parseProgram</span>() <span class="op">{</span>
  program <span class="op">=</span> <span class="at">newProgramASTNode</span>()

  <span class="at">advanceTokens</span>()

  <span class="cf">for</span> (<span class="at">currentToken</span>() <span class="op">!=</span> EOF_TOKEN) <span class="op">{</span>
    statement <span class="op">=</span> <span class="kw">null</span>

    <span class="cf">if</span> (<span class="at">currentToken</span>() <span class="op">==</span> LET_TOKEN) <span class="op">{</span>
      statement <span class="op">=</span> <span class="at">parseLetStatement</span>()
    <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (<span class="at">currentToken</span>() <span class="op">==</span> RETURN_TOKEN) <span class="op">{</span>
      statement <span class="op">=</span> <span class="at">parseReturnStatement</span>()
    <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (<span class="at">currentToken</span>() <span class="op">==</span> IF_TOKEN) <span class="op">{</span>
      statement <span class="op">=</span> <span class="at">parseIfStatement</span>()
    <span class="op">}</span>

    <span class="cf">if</span> (statement <span class="op">!=</span> <span class="kw">null</span>) <span class="op">{</span>
      <span class="va">program</span>.<span class="va">Statements</span>.<span class="at">push</span>(statement)
    <span class="op">}</span>

    <span class="at">advanceTokens</span>()
  <span class="op">}</span>

  <span class="cf">return</span> program
<span class="op">}</span>

<span class="kw">function</span> <span class="at">parseLetStatement</span>() <span class="op">{</span>
  <span class="at">advanceTokens</span>()

  identifier <span class="op">=</span> <span class="at">parseIdentifier</span>()

  <span class="at">advanceTokens</span>()

  <span class="cf">if</span> <span class="at">currentToken</span>() <span class="op">!=</span> EQUAL_TOKEN <span class="op">{</span>
    <span class="at">parseError</span>(<span class="st">&quot;no equal sign!&quot;</span>)
    <span class="cf">return</span> <span class="kw">null</span>
  <span class="op">}</span>

  <span class="at">advanceTokens</span>()

  value <span class="op">=</span> <span class="at">parseExpression</span>()

  variableStatement <span class="op">=</span> <span class="at">newVariableStatementASTNode</span>()
  <span class="va">variableStatement</span>.<span class="at">identifier</span> <span class="op">=</span> identifier
  <span class="va">variableStatement</span>.<span class="at">value</span> <span class="op">=</span> value
  <span class="cf">return</span> variableStatement
<span class="op">}</span>

<span class="kw">function</span> <span class="at">parseIdentifier</span>() <span class="op">{</span>
  identifier <span class="op">=</span> <span class="at">newIdentifierASTNode</span>()
  <span class="va">identifier</span>.<span class="at">token</span> <span class="op">=</span> <span class="at">currentToken</span>()
  <span class="cf">return</span> identifier
<span class="op">}</span>

<span class="kw">function</span> <span class="at">parseExpression</span>() <span class="op">{</span>
  <span class="cf">if</span> (<span class="at">currentToken</span>() <span class="op">==</span> INTEGER_TOKEN) <span class="op">{</span>
    <span class="cf">if</span> (<span class="at">nextToken</span>() <span class="op">==</span> PLUS_TOKEN)  <span class="op">{</span>
      <span class="cf">return</span> <span class="at">parseOperatorExpression</span>()
    <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (<span class="at">nextToken</span>() <span class="op">==</span> SEMICOLON_TOKEN) <span class="op">{</span>
      <span class="cf">return</span> <span class="at">parseIntegerLiteral</span>()
    <span class="op">}</span>
  <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (<span class="at">currentToken</span>() <span class="op">==</span> LEFT_PAREN) <span class="op">{</span>
    <span class="cf">return</span> <span class="at">parseGroupedExpression</span>()
  <span class="op">}</span>
<span class="co">// [...]</span>
<span class="op">}</span>

<span class="kw">function</span> <span class="at">parseOperatorExpression</span>() <span class="op">{</span>
  operatorExpression <span class="op">=</span> <span class="at">newOperatorExpression</span>()

  <span class="va">operatorExpression</span>.<span class="at">left</span> <span class="op">=</span> <span class="at">parseIntegerLiteral</span>()
  <span class="va">operatorExpression</span>.<span class="at">operator</span> <span class="op">=</span> <span class="at">currentToken</span>()
  <span class="va">operatorExpression</span>.<span class="at">right</span> <span class="op">=</span> <span class="at">parseExpression</span>()

  <span class="cf">return</span> <span class="at">operatorExpression</span>()
<span class="op">}</span>
<span class="co">// [...]</span></code></pre></div>
<p>Since this is pseudocode there are a lot of omissions, of course. But the basic idea behind recursive-descent parsing is there. The entry point is <code>parseProgram</code> and it constructs the root node of the AST (<code>newProgramASTNode()</code>). It then builds the child nodes, the statements, by calling other functions that know which AST node to construct based on the current token. These other functions call each other again, recursively.</p>
<p>The most recursive part of this is in <code>parseExpression</code> and is only hinted at. But we can already see that in order to parse an expression like <code>5 + 5</code>, we need to first parse <code>5 +</code> and then call <code>parseExpression()</code> again to parse the rest, since after the <code>+</code> might be another operator expression, like this: <code>5 + 5 * 10</code>. We will get to this later and look at expression parsing in detail, since it's probably the most complicated but also the most beautiful part of the parser, making heavy use of &quot;Pratt parsing&quot;.</p>
<p>But for now, we can already see what the parser has to do. It repeatedly advances the tokens and checks the current token to decide what to do next: either call another parsing function or throw an error. Each function then does its job and possibly constructs an AST node so that the &quot;main loop&quot; in <code>parseProgram()</code> can advance the tokens and decide what to do again.</p>
<p>If you looked at that pseudocode and thought &quot;Well, that's actually pretty easy to understand&quot; I have great news for you: our <code>ParseProgram</code> method and the parser will look pretty similar! Let's get to work!</p>
<p>Again, we're starting with a test before we flesh out <code>ParseProgram</code>. Here is a test case to make sure that the parsing of let statements works:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">package</span> parser

<span class="kw">import</span> (
    <span class="st">&quot;testing&quot;</span>
    <span class="st">&quot;monkey/ast&quot;</span>
    <span class="st">&quot;monkey/lexer&quot;</span>
)

<span class="kw">func</span> TestLetStatements(t *testing.T) {
    input := <span class="st">`</span>
<span class="st">let x = 5;</span>
<span class="st">let y = 10;</span>
<span class="st">let foobar = 838383;</span>
<span class="st">`</span>
    l := lexer.New(input)
    p := New(l)

    program := p.ParseProgram()
    <span class="kw">if</span> program == <span class="ot">nil</span> {
        t.Fatalf(<span class="st">&quot;ParseProgram() returned nil&quot;</span>)
    }
    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">3</span> {
        t.Fatalf(<span class="st">&quot;program.Statements does not contain 3 statements. got=%d&quot;</span>,
            <span class="bu">len</span>(program.Statements))
    }

    tests := []<span class="kw">struct</span> {
        expectedIdentifier <span class="dt">string</span>
    }{
        {<span class="st">&quot;x&quot;</span>},
        {<span class="st">&quot;y&quot;</span>},
        {<span class="st">&quot;foobar&quot;</span>},
    }

    <span class="kw">for</span> i, tt := <span class="kw">range</span> tests {
        stmt := program.Statements[i]
        <span class="kw">if</span> !testLetStatement(t, stmt, tt.expectedIdentifier) {
            <span class="kw">return</span>
        }
    }
}

<span class="kw">func</span> testLetStatement(t *testing.T, s ast.Statement, name <span class="dt">string</span>) <span class="dt">bool</span> {
    <span class="kw">if</span> s.TokenLiteral() != <span class="st">&quot;let&quot;</span> {
        t.Errorf(<span class="st">&quot;s.TokenLiteral not &#39;let&#39;. got=%q&quot;</span>, s.TokenLiteral())
        <span class="kw">return</span> <span class="ot">false</span>
    }

    letStmt, ok := s.(*ast.LetStatement)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;s not *ast.LetStatement. got=%T&quot;</span>, s)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> letStmt.Name.Value != name {
        t.Errorf(<span class="st">&quot;letStmt.Name.Value not &#39;%s&#39;. got=%s&quot;</span>, name, letStmt.Name.Value)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> letStmt.Name.TokenLiteral() != name {
        t.Errorf(<span class="st">&quot;s.Name not &#39;%s&#39;. got=%s&quot;</span>, name, letStmt.Name)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>The test case follows the same principle as the test for our lexer and pretty much every other unit test we're going to write: we provide Monkey source code as input and then set expectations on what we want the AST - that's produced by the parser - to look like. We do this by checking as many fields of the AST nodes as possible to make sure that nothing is missing. I found that a parser is a breeding ground for off-by-one bugs and the more tests and assertions it has the better.</p>
<p>I choose not to mock or stub out the lexer and provide source code as input instead of tokens, since that makes the tests much more readable and understandable. Of course there's the problem of bugs in the lexer blowing up tests for the parser and generating unneeded noise, but I deem the risk too minimal, especially judged against the advantages of using readable source code as input.</p>
<p>There are two noteworthy things about this test case. The first one is that we ignore the <code>Value</code> field of the <code>*ast.LetStatement</code>. Why don't we check if the integer literals (<code>5</code>, <code>10</code>, ...) are parsed correctly? Answer: we're going to! But first we need to make sure that the parsing of let statements works and ignore the <code>Value</code>.</p>
<p>The second one is the helper function <code>testLetStatement</code>. It might seem like over-engineering to use a separate function, but we're going to need this function soon enough. And then it's going to make our test cases a lot more readable than lines and lines of type conversions strewn about.</p>
<p>As an aside: we won't look at all of the parser tests in this chapter, since they are just too long. But the code provided with the book contains all of them.</p>
<p>That being said, the tests fail as expected:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestLetStatements (0.00s)
  parser_test.go:20: ParseProgram() returned nil
FAIL
FAIL    monkey/parser    0.007s</code></pre></div>
<p>It's time to flesh out the <code>ParseProgram()</code> method of the <code>Parser</code>.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) ParseProgram() *ast.Program {
    program := &amp;ast.Program{}
    program.Statements = []ast.Statement{}

    <span class="kw">for</span> p.curToken.Type != token.EOF {
        stmt := p.parseStatement()
        <span class="kw">if</span> stmt != <span class="ot">nil</span> {
            program.Statements = <span class="bu">append</span>(program.Statements, stmt)
        }
        p.nextToken()
    }

    <span class="kw">return</span> program
}</code></pre></div>
<p>Doesn't this look really similar to the <code>parseProgram()</code> pseudocode function we saw earlier? See! I told you! And what it does is the same too.</p>
<p>The first thing <code>ParseProgram</code> does is construct the root node of the AST, an <code>*ast.Program</code>. It then iterates over every token in the input until it encounters an <code>token.EOF</code> token. It does this by repeatedly calling <code>nextToken</code>, which advances both <code>p.curToken</code> and <code>p.peekToken</code>. In every iteration it calls <code>parseStatement</code>, whose job it is to parse a statement. If <code>parseStatement</code> returned something other than <code>nil</code>, a <code>ast.Statement</code>, its return value is added to <code>Statements</code> slice of the AST root node. When nothing is left to parse the <code>*ast.Program</code> root node is returned.</p>
<p>The <code>parseStatement</code> method looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseStatement() ast.Statement {
    <span class="kw">switch</span> p.curToken.Type {
    <span class="kw">case</span> token.LET:
        <span class="kw">return</span> p.parseLetStatement()
    <span class="kw">default</span>:
        <span class="kw">return</span> <span class="ot">nil</span>
    }
}</code></pre></div>
<p>Don't worry, the switch statement will get more branches. But for now, it only calls <code>parseLetStatement</code> when it encounters a <code>token.LET</code> token. And <code>parseLetStatement</code> is the method where we turn our tests from red to green:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseLetStatement() *ast.LetStatement {
    stmt := &amp;ast.LetStatement{Token: p.curToken}

    <span class="kw">if</span> !p.expectPeek(token.IDENT) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    stmt.Name = &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

    <span class="kw">if</span> !p.expectPeek(token.ASSIGN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="co">// TODO: We&#39;re skipping the expressions until we</span>
    <span class="co">// encounter a semicolon</span>
    <span class="kw">for</span> !p.curTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}

<span class="kw">func</span> (p *Parser) curTokenIs(t token.TokenType) <span class="dt">bool</span> {
    <span class="kw">return</span> p.curToken.Type == t
}

<span class="kw">func</span> (p *Parser) peekTokenIs(t token.TokenType) <span class="dt">bool</span> {
    <span class="kw">return</span> p.peekToken.Type == t
}

<span class="kw">func</span> (p *Parser) expectPeek(t token.TokenType) <span class="dt">bool</span> {
    <span class="kw">if</span> p.peekTokenIs(t) {
        p.nextToken()
        <span class="kw">return</span> <span class="ot">true</span>
    } <span class="kw">else</span> {
        <span class="kw">return</span> <span class="ot">false</span>
    }
}</code></pre></div>
<p>It works! The tests are green:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>We can parse let statements! That's amazing! But, wait, how?</p>
<p>Let's start with <code>parseLetStatement</code>. It constructs an <code>*ast.LetStatement</code> node with the token it's currently sitting on (a <code>token.LET</code> token) and then advances the tokens while making assertions about the next token with calls to <code>expectPeek</code>. First it expects a <code>token.IDENT</code> token, which it then uses to construct an <code>*ast.Identifier</code> node. Then it expects an equal sign and finally it jumps over the expression following the equal sign until it encounters a semicolon. The skipping of expressions will be replaced, of course, as soon as we know how to parse them.</p>
<p>The <code>curTokenIs</code> and <code>peekTokenIs</code> methods do not need much of an explanation. They are useful methods that we will see again and again when fleshing out the parser. Already, we can replace the <code>p.curToken.Type != token.EOF</code> condition of the for-loop in <code>ParseProgram</code> with <code>!p.curTokenIs(token.EOF)</code>.</p>
<p>Instead of dissecting these tiny methods, let's talk about <code>expectPeek</code>. The <code>expectPeek</code> method is one of the &quot;assertion functions&quot; nearly all parsers share. Their primary purpose is to enforce the correctness of the order of tokens by checking the type of the next token. Our <code>expectPeek</code> here checks the type of the <code>peekToken</code> and only if the type is correct does it advance the tokens by calling <code>nextToken</code>. As you'll see, this is something a parser does a lot.</p>
<p>But what happens if we encounter a token in <code>expectPeek</code> that's not of the expected type? At the moment, we just return <code>nil</code>, which gets ignored in <code>ParseProgram</code>, which results in entire statements being ignored because of an error in the input. Silently. You can probably imagine that this makes debugging really tough. And since nobody likes tough debugging we need to add error handling to our parser.</p>
<p>Thankfully, the changes we need to make are minimal:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">type</span> Parser <span class="kw">struct</span> {
<span class="co">// [...]</span>
    errors []<span class="dt">string</span>
<span class="co">// [...]</span>
}

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
    p := &amp;Parser{
        l:      l,
        errors: []<span class="dt">string</span>{},
    }
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) Errors() []<span class="dt">string</span> {
    <span class="kw">return</span> p.errors
}

<span class="kw">func</span> (p *Parser) peekError(t token.TokenType) {
    msg := fmt.Sprintf(<span class="st">&quot;expected next token to be %s, got %s instead&quot;</span>,
        t, p.peekToken.Type)
    p.errors = <span class="bu">append</span>(p.errors, msg)
}</code></pre></div>
<p>The <code>Parser</code> now has an <code>errors</code> field, which is just a slice of strings. This field gets initialized in <code>New</code> and the helper function <code>peekError</code> can now be used to add an error to <code>errors</code> when the type of <code>peekToken</code> doesn't match the expectation. With the <code>Errors</code> method we can check if the parser encountered any errors.</p>
<p>Extending the test suite to make use of this is as easy as you'd expect:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestLetStatements(t *testing.T) {
<span class="co">// [...]</span>

    program := p.ParseProgram()
    checkParserErrors(t, p)

<span class="co">// [...]</span>
}

<span class="kw">func</span> checkParserErrors(t *testing.T, p *Parser) {
    errors := p.Errors()
    <span class="kw">if</span> <span class="bu">len</span>(errors) == <span class="dv">0</span> {
        <span class="kw">return</span>
    }

    t.Errorf(<span class="st">&quot;parser has %d errors&quot;</span>, <span class="bu">len</span>(errors))
    <span class="kw">for</span> _, msg := <span class="kw">range</span> errors {
        t.Errorf(<span class="st">&quot;parser error: %q&quot;</span>, msg)
    }
    t.FailNow()
}</code></pre></div>
<p>The new <code>checkParserErrors</code> helper function does nothing more than check the parser for errors and if it has any it prints them as test errors and stops the execution of the current test. Pretty straightforward.</p>
<p>But nothing in our parser creates errors yet. By changing <code>expectPeek</code> we can automatically add an error every time one of our expectations about the next token was wrong:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) expectPeek(t token.TokenType) <span class="dt">bool</span> {
    <span class="kw">if</span> p.peekTokenIs(t) {
        p.nextToken()
        <span class="kw">return</span> <span class="ot">true</span>
    } <span class="kw">else</span> {
        p.peekError(t)
        <span class="kw">return</span> <span class="ot">false</span>
    }
}</code></pre></div>
<p>If we now change our test case input from this</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">input := <span class="st">`</span>
<span class="st">let x = 5;</span>
<span class="st">let y = 10;</span>
<span class="st">let foobar = 838383;</span>
<span class="st">`</span></code></pre></div>
<p>to this invalid input where tokens are missing</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">    input := <span class="st">`</span>
<span class="st">let x 5;</span>
<span class="st">let = 10;</span>
<span class="st">let 838383;</span>
<span class="st">`</span></code></pre></div>
<p>we can run our tests to see our new parser errors:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestLetStatements (0.00s)
  parser_test.go:20: parser has 3 errors
  parser_test.go:22: parser error: &quot;expected next token to be =,\
    got INT instead&quot;
  parser_test.go:22: parser error: &quot;expected next token to be IDENT,\
    got = instead&quot;
  parser_test.go:22: parser error: &quot;expected next token to be IDENT,\
    got INT instead&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>As you can see, our parser showcases a neat little feature here: it gives us errors for each erroneous statement it encounters. It doesn't exit on the first one, potentially saving us the grunt work of rerunning the parsing process again and again to catch all of the syntax errors. That's pretty helpful - even with line and column numbers missing.</p>
<h2 id="parsing-return-statements">2.5 - Parsing Return Statements</h2>
<p>I said earlier that we're going to flesh out our sparse looking <code>ParseProgram</code> method. Now's the time. We're going to parse return statements. And the first step, as with let statements before them, is to define the necessary structures in the <code>ast</code> package with which we can represent return statements in our AST.</p>
<p>Here is what return statements look like in Monkey:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">return</span> <span class="dv">5</span><span class="op">;</span>
<span class="cf">return</span> <span class="dv">10</span><span class="op">;</span>
<span class="cf">return</span> <span class="at">add</span>(<span class="dv">15</span>)<span class="op">;</span></code></pre></div>
<p>Experienced with let statements, we can easily spot the structure behind these statements:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">return &lt;expression&gt;;</code></pre></div>
<p>Return statements consist solely of the keyword <code>return</code> and an expression. That makes the definition of <code>ast.ReturnStatement</code> really simple:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> ReturnStatement <span class="kw">struct</span> {
    Token       token.Token <span class="co">// the &#39;return&#39; token</span>
    ReturnValue Expression
}

<span class="kw">func</span> (rs *ReturnStatement) statementNode()       {}
<span class="kw">func</span> (rs *ReturnStatement) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> rs.Token.Literal }</code></pre></div>
<p>There is nothing about this node that you haven't seen before: it has a field for the initial token and a <code>ReturnValue</code> field that will contain the expression that's to be returned. We will again skip the parsing of the expressions and the semicolon handling for now, but will come back to this later. The <code>statementNode</code> and <code>TokenLiteral</code> methods are there to fulfill the <code>Node</code> and <code>Statement</code> interfaces and look identical to the methods defined on <code>*ast.LetStatement</code>.</p>
<p>The test we write next also looks pretty similar to the one for let statements:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestReturnStatements(t *testing.T) {
    input := <span class="st">`</span>
<span class="st">return 5;</span>
<span class="st">return 10;</span>
<span class="st">return 993322;</span>
<span class="st">`</span>
    l := lexer.New(input)
    p := New(l)

    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">3</span> {
        t.Fatalf(<span class="st">&quot;program.Statements does not contain 3 statements. got=%d&quot;</span>,
            <span class="bu">len</span>(program.Statements))
    }

    <span class="kw">for</span> _, stmt := <span class="kw">range</span> program.Statements {
        returnStmt, ok := stmt.(*ast.ReturnStatement)
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;stmt not *ast.returnStatement. got=%T&quot;</span>, stmt)
            <span class="kw">continue</span>
        }
        <span class="kw">if</span> returnStmt.TokenLiteral() != <span class="st">&quot;return&quot;</span> {
            t.Errorf(<span class="st">&quot;returnStmt.TokenLiteral not &#39;return&#39;, got %q&quot;</span>,
                returnStmt.TokenLiteral())
        }
    }
}</code></pre></div>
<p>Of course these test cases will also have to be extended as soon as expression parsing is in place. But that's okay, tests are not immutable. But they are, in fact, failing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestReturnStatements (0.00s)
  parser_test.go:77: program.Statements does not contain 3 statements. got=0
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>So let's make them pass by changing our <code>ParseProgram</code> method to also take <code>token.RETURN</code> tokens into account:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseStatement() ast.Statement {
    <span class="kw">switch</span> p.curToken.Type {
    <span class="kw">case</span> token.LET:
        <span class="kw">return</span> p.parseLetStatement()
    <span class="kw">case</span> token.RETURN:
        <span class="kw">return</span> p.parseReturnStatement()
    <span class="kw">default</span>:
        <span class="kw">return</span> <span class="ot">nil</span>
    }
}</code></pre></div>
<p>I could make a lot of fuzz about the <code>parseReturnStatement</code> method before showing it to you, but, well, I won't. Because it's tiny. There is nothing to fuzz about.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseReturnStatement() *ast.ReturnStatement {
    stmt := &amp;ast.ReturnStatement{Token: p.curToken}

    p.nextToken()

    <span class="co">// TODO: We&#39;re skipping the expressions until we</span>
    <span class="co">// encounter a semicolon</span>
    <span class="kw">for</span> !p.curTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}</code></pre></div>
<p>I told you: it's tiny. The only thing it does is construct a <code>ast.ReturnStatement</code>, with the current token it's sitting on as <code>Token</code>. It then brings the parser in place for the expression that comes next by calling <code>nextToken()</code> and finally, there's the cop-out. It skips over every expression until it encounters a semicolon. That's it. Our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.009s</code></pre></div>
<p>It's time to celebrate again! We can now parse all of the statements in the Monkey programming language! That's right: there are only two of them. Let statements and return statements. The rest of the language consists solely of expressions. And that's what we're going to parse next.</p>
<h2 id="parsing-expressions">2.6 - Parsing Expressions</h2>
<p>Personally, I think that parsing expressions is the most interesting part of writing a parser. As we just saw, parsing statements is relatively straightforward. We process tokens from &quot;left to right&quot;, expect or reject the next tokens and if everything fits we return an AST node.</p>
<p>Parsing expressions, on the other hand, contains a few more challenges. Operator precedence is probably the first one that comes to mind and is best illustrated with an example. Let's say we want to parse the following arithmetic expression:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span> <span class="op">+</span> <span class="dv">10</span></code></pre></div>
<p>What we want here is an AST that represents the expression like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">((<span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span>) <span class="op">+</span> <span class="dv">10</span>)</code></pre></div>
<p>That is to say, <code>5 * 5</code> needs to be &quot;deeper&quot; in the AST and evaluated earlier than the addition. In order to produce an AST that looks like this, the parser has to know about operator precedences where the precedence of <code>*</code> is higher than <code>+</code>. That's the most common example for operator precedence, but there are a lot more cases where it's important. Consider this expression:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> (<span class="dv">5</span> <span class="op">+</span> <span class="dv">10</span>)</code></pre></div>
<p>Here the parenthesis group together the <code>5 + 10</code> expression and give them a &quot;precedence bump&quot;: the addition now has to be evaluated before the multiplication. That's because parentheses have a higher precedence than the <code>*</code> operator. As we will soon see, there are a few more cases where precedence is playing a crucial role.</p>
<p>The other big challenge is that in expressions tokens of the same type can appear in multiple positions. In contrast to this, the <code>let</code> token can only appear once at the beginning of a let statement, which makes it easy to determine what the rest of the statement is supposed to be. Now look at this expression:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">-</span><span class="dv">5</span> <span class="op">-</span> <span class="dv">10</span></code></pre></div>
<p>Here the <code>-</code> operator appears at the beginning of the expression, as a prefix operator, and then as an infix operator in the middle. A variation of the same challenge appears here:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> (<span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>) <span class="op">+</span> <span class="dv">10</span>)</code></pre></div>
<p>Even though you might not recognize the parentheses as operators yet, they pose the same problem to us as the <code>-</code> in the previous example. The outer pair of parentheses in this example denotes a grouped expression. The inner pair denotes a &quot;call expression&quot;. The validity of a token's position now depends on the context, the tokens that come before and after, and their precedence.</p>
<h3 id="expressions-in-monkey">Expressions in Monkey</h3>
<p>In the Monkey programming language everything besides let and return statements is an expression. These expressions come in different varieties.</p>
<p>Monkey has expressions involving prefix operators:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">-</span><span class="dv">5</span>
<span class="op">!</span><span class="kw">true</span>
<span class="op">!</span><span class="kw">false</span></code></pre></div>
<p>And of course it has infix operators (or &quot;binary operators&quot;):</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span>
<span class="dv">5</span> <span class="op">-</span> <span class="dv">5</span>
<span class="dv">5</span> / <span class="dv">5</span>
<span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span></code></pre></div>
<p>Besides these basic arithmetic operators, there are also the following comparison operators:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">foo <span class="op">==</span> bar
foo <span class="op">!=</span> bar
foo <span class="op">&lt;</span> bar
foo <span class="op">&gt;</span> bar</code></pre></div>
<p>And of course, as we previously saw, we can use parentheses to group expressions and influence the order of evaluation:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> (<span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span>)
((<span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span>) <span class="op">*</span> <span class="dv">5</span>) <span class="op">*</span> <span class="dv">5</span></code></pre></div>
<p>Then there are call expressions:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>)
<span class="at">add</span>(<span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>)<span class="op">,</span> <span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">10</span>))
<span class="at">max</span>(<span class="dv">5</span><span class="op">,</span> <span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> (<span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span>)))</code></pre></div>
<p>Identifiers are expressions too:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">foo <span class="op">*</span> bar / foobar
<span class="at">add</span>(foo<span class="op">,</span> bar)</code></pre></div>
<p>Functions in Monkey are first-class citizens and, yes, function literals are expressions too. We can use a let statement to bind a function to a name. The function literal is just the expression in the statement:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> <span class="cf">return</span> x <span class="op">+</span> y <span class="op">};</span></code></pre></div>
<p>And here we use a function literal in place of an identifier:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> <span class="cf">return</span> x <span class="op">+</span> y <span class="op">}</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">5</span>)
(<span class="at">fn</span>(x) <span class="op">{</span> <span class="cf">return</span> x <span class="op">}</span>(<span class="dv">5</span>) <span class="op">+</span> <span class="dv">10</span> ) <span class="op">*</span> <span class="dv">10</span></code></pre></div>
<p>In contrast to a lot of widely used programming languages we also have &quot;if expressions&quot; in Monkey:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> result <span class="op">=</span> <span class="cf">if</span> (<span class="dv">10</span> <span class="op">&gt;</span> <span class="dv">5</span>) <span class="op">{</span> <span class="kw">true</span> <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span> <span class="kw">false</span> <span class="op">};</span>
result <span class="co">// =&gt; true</span></code></pre></div>
<p>Looking at all these different forms of expressions it becomes clear that we need a really good approach to parse them correctly and in an understandable and extendable way. Our old approach of deciding what to do based on the current token won't get us very far - at least not without wanting to tear our hair out. And that is where Vaughan Pratt comes in.</p>
<h3 id="top-down-operator-precedence-or-pratt-parsing">Top Down Operator Precedence (or: Pratt Parsing)</h3>
<p>In his paper &quot;Top Down Operator Precedence&quot; Vaughan Pratt presents an approach to parsing expressions that, in his own words:</p>
<blockquote>
<p>[...] is very simple to understand, trivial to implement, easy to use, extremely efficient in practice if not in theory, yet flexible enough to meet most reasonable syntactic needs of users [...]</p>
</blockquote>
<p>The paper was published in 1973 but in the many years since then the ideas presented by Pratt didn't gain a huge following. Only in recent years, other programmers rediscovered Pratt's paper, wrote about it and caused Pratt's approach to parsing to rise in popularity. There's Douglas Crockford's (of &quot;JavaScript: The Good Parts&quot; fame) article called <a href="http://javascript.crockford.com/tdop/tdop.html">&quot;Top Down Operator Precedence&quot;</a> that shows how to translate Pratt's ideas to JavaScript (which Crockford did when building JSLint). And then there's <a href="http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/">the highly recommended article by Bob Nystrom</a>, author of the excellent &quot;Game Programming Patterns&quot; book, that makes Pratt's approach really easy to understand and to follow by providing clean example code in Java.</p>
<p>The parsing approach described by all three, which is called Top Down Operator Precedence Parsing, or Pratt parsing, was invented as an alternative to parsers based on context-free grammars and the Backus-Naur-Form.</p>
<p>And that is also the main difference: instead of associating parsing functions (think of our <code>parseLetStatement</code> method here) with grammar rules (defined in BNF or EBNF), Pratt associates these functions (which he calls &quot;semantic code&quot;) with single token types. A crucial part of this idea is that each token type can have two parsing functions associated with it, depending on the token's position - infix or prefix.</p>
<p>I guess that doesn't make a lot of sense yet. We never saw how to associate parsing functions with grammar rules, so the idea of using token types instead of these rules doesn't register as anything really novel or revelatory. To be completely honest: I was facing a chicken-and-egg problem when writing this section. Is it better to explain this algorithm in abstract terms and then show the implementation, possibly causing you to jump back and forth between pages, or to show the implementation with the explanation following, causing you to probably skip over the implementation and not getting a lot out of the explanation?</p>
<p>The answer, I decided, is neither of these two options. What we're going to do instead is start implementing the expression parsing part of our parser. Then we're going to take a closer look at it and its algorithm. Afterwards we will extend and complete it so it's able to parse all possible expressions in Monkey.</p>
<p>And before we start writing any code, let's just be clear on the terminology.</p>
<h3 id="terminology">Terminology</h3>
<p>A <strong>prefix operator</strong> is an operator &quot;in front of&quot; its operand. Example:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">--</span><span class="dv">5</span></code></pre></div>
<p>Here the operator is <code>--</code> (decrement), the operand is the integer literal <code>5</code> and the operator is in the prefix position.</p>
<p>A <strong>postfix operator</strong> is an operator &quot;after&quot; its operand. Example:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">foobar<span class="op">++</span></code></pre></div>
<p>Here the operator is <code>++</code> (increment), the operand is the identifier <code>foobar</code> and the operator is in the postfix position. The Monkey interpreter we'll build won't have postfix operators. Not because of some technical limitations, but purely in order to keep the scope of the book limited.</p>
<p>Now, <strong>infix operators</strong> are something we've all seen before. An infix operator sits between its operands, like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> <span class="dv">8</span></code></pre></div>
<p>The <code>*</code> operator sits in the infix position between the two integer literals <code>5</code> and <code>8</code>. Infix operators appear in <strong>binary expressions</strong> - where the operator has two operands.</p>
<p>The other term we already stumbled upon and will find again later is <strong>operator precedence</strong>. And alternative term for this is <strong>order of operations</strong>, which should make clearer what operator precedence describes: which priority do different operators have. The canonical example is this one, which we saw earlier:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span> <span class="op">*</span> <span class="dv">10</span></code></pre></div>
<p>The result of this expression is <code>55</code> and not <code>100</code>. And that's because the <code>*</code> operator has a higher precedence, a &quot;higher rank&quot;. It's &quot;more important&quot; than the <code>+</code> operator. It gets evaluated before the other operator. I sometimes think of operator precedence as &quot;operator stickiness&quot;: how much do the operands next to the operator &quot;stick&quot; to it.</p>
<p>These are all basic terms: prefix, postfix, infix operator and precedence. But it's important that we keep these simple definitions in mind later on, where we'll use these terms in other places.</p>
<p>But for now: let's get typing and write some code!</p>
<h3 id="preparing-the-ast">Preparing the AST</h3>
<p>The first thing we need to do for expression parsing is to prepare our AST. As we saw before, a program in Monkey is a series of statements. Some are let statements, others return statements. We need to add a third type of statement to our AST: expression statements.</p>
<p>This may sound confusing, after I told you that let and return statements are the only type of statements in Monkey. But an expression statement is not really a distinct statement; it's a statement that consists solely of one expression. It's only a wrapper. We need it because it's totally legal in Monkey to write the following code:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
x <span class="op">+</span> <span class="dv">10</span><span class="op">;</span></code></pre></div>
<p>The first line is a let statement, the second line is an expression statement. Other languages don't have these expression statements, but most scripting languages do. They make it possible to have one line consisting only of an expression. So let's add this node type to our AST:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> ExpressionStatement <span class="kw">struct</span> {
    Token      token.Token <span class="co">// the first token of the expression</span>
    Expression Expression
}

<span class="kw">func</span> (es *ExpressionStatement) statementNode()       {}
<span class="kw">func</span> (es *ExpressionStatement) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> es.Token.Literal }</code></pre></div>
<p>The <code>ast.ExpressionStatement</code> type has two fields: the <code>Token</code> field, which every node has, and the <code>Expression</code> field, which holds the expression. <code>ast.ExpressionStatement</code> fulfills the <code>ast.Statement</code> interface, which means we can add it to the <code>Statements</code> slice of <code>ast.Program</code>. And that's the whole reason why we're adding <code>ast.ExpressionStatement</code>.</p>
<p>With <code>ast.ExpressionStatement</code> defined we could resume work on the parser. But instead, let's make our lives much easier by adding a <code>String()</code> method to our AST nodes. This will allow us to print AST nodes for debugging and to compare them with other AST nodes. This is going to be really handy in tests!</p>
<p>We're going to make this <code>String()</code> method part of the <code>ast.Node</code> interface:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> Node <span class="kw">interface</span> {
    TokenLiteral() <span class="dt">string</span>
    String() <span class="dt">string</span>
}</code></pre></div>
<p>Now every node type in our <code>ast</code> package has to implement this method. With that change made, our code won't compile because the compiler complains about our AST nodes not fully implementing the updated <code>Node</code> interface. Let's start with <code>*ast.Program</code> and add its <code>String()</code> method first:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">import</span> (
<span class="co">// [...]</span>
    <span class="st">&quot;bytes&quot;</span>
)

<span class="kw">func</span> (p *Program) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    <span class="kw">for</span> _, s := <span class="kw">range</span> p.Statements {
        out.WriteString(s.String())
    }

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>This method doesn't do much. It only creates a buffer and writes the return value of each statements <code>String()</code> method to it. And then it returns the buffer as a string. It delegates most of its work to the <code>Statements</code> of <code>*ast.Program</code>.</p>
<p>The &quot;real work&quot; happens in the <code>String()</code> methods of our three statement types <code>ast.LetStatement</code>, <code>ast.ReturnStatement</code> and <code>ast.ExpressionStatement</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">func</span> (ls *LetStatement) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(ls.TokenLiteral() + <span class="st">&quot; &quot;</span>)
    out.WriteString(ls.Name.String())
    out.WriteString(<span class="st">&quot; = &quot;</span>)

    <span class="kw">if</span> ls.Value != <span class="ot">nil</span> {
        out.WriteString(ls.Value.String())
    }

    out.WriteString(<span class="st">&quot;;&quot;</span>)

    <span class="kw">return</span> out.String()
}

<span class="kw">func</span> (rs *ReturnStatement) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(rs.TokenLiteral() + <span class="st">&quot; &quot;</span>)

    <span class="kw">if</span> rs.ReturnValue != <span class="ot">nil</span> {
        out.WriteString(rs.ReturnValue.String())
    }

    out.WriteString(<span class="st">&quot;;&quot;</span>)

    <span class="kw">return</span> out.String()
}

<span class="kw">func</span> (es *ExpressionStatement) String() <span class="dt">string</span> {
    <span class="kw">if</span> es.Expression != <span class="ot">nil</span> {
        <span class="kw">return</span> es.Expression.String()
    }
    <span class="kw">return</span> <span class="st">&quot;&quot;</span>
}</code></pre></div>
<p>The nil-checks will be taken out, later on, when we can fully build expressions.</p>
<p>Now we only need to add a last <code>String()</code> method to <code>ast.Identifier</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">func</span> (i *Identifier) String() <span class="dt">string</span> { <span class="kw">return</span> i.Value }</code></pre></div>
<p>With these methods in place, we can now just call <code>String()</code> on <code>*ast.Program</code> and get our whole program back as a string. That makes the structure of <code>*ast.Program</code> easily testable. Let's use the following line of Monkey source code as an example:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> myVar <span class="op">=</span> anotherVar<span class="op">;</span></code></pre></div>
<p>If we construct an AST out of this, we can make an assertion about the return value of <code>String()</code> like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast_test.go</span>

<span class="kw">package</span> ast

<span class="kw">import</span> (
    <span class="st">&quot;monkey/token&quot;</span>
    <span class="st">&quot;testing&quot;</span>
)

<span class="kw">func</span> TestString(t *testing.T) {
    program := &amp;Program{
        Statements: []Statement{
            &amp;LetStatement{
                Token: token.Token{Type: token.LET, Literal: <span class="st">&quot;let&quot;</span>},
                Name: &amp;Identifier{
                    Token: token.Token{Type: token.IDENT, Literal: <span class="st">&quot;myVar&quot;</span>},
                    Value: <span class="st">&quot;myVar&quot;</span>,
                },
                Value: &amp;Identifier{
                    Token: token.Token{Type: token.IDENT, Literal: <span class="st">&quot;anotherVar&quot;</span>},
                    Value: <span class="st">&quot;anotherVar&quot;</span>,
                },
            },
        },
    }

    <span class="kw">if</span> program.String() != <span class="st">&quot;let myVar = anotherVar;&quot;</span> {
        t.Errorf(<span class="st">&quot;program.String() wrong. got=%q&quot;</span>, program.String())
    }
}</code></pre></div>
<p>In this test we construct the AST by hand. When writing tests for the parser we don't, of course, but make assertions about the AST the parser produces. For demonstration purposes, this test shows us how we can add another easily readable layer of tests for our parser by just comparing the parser output with strings. That's going to be especially handy when parsing expressions.</p>
<p>So, good news: preparation is done! It's time to write a Pratt parser.</p>
<h3 id="implementing-the-pratt-parser">Implementing the Pratt Parser</h3>
<p>A Pratt parser's main idea is the association of parsing functions (which Pratt calls &quot;semantic code&quot;) with token types. Whenever this token type is encountered, the parsing functions are called to parse the appropriate expression and return an AST node that represents it. Each token type can have up to two parsing functions associated with it, depending on whether the token is found in a prefix or an infix position.</p>
<p>The first thing we need to do is to setup these associations. We define two types of functions: a prefix parsing functions and an infix parsing function.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">type</span> (
    prefixParseFn <span class="kw">func</span>() ast.Expression
    infixParseFn  <span class="kw">func</span>(ast.Expression) ast.Expression
)</code></pre></div>
<p>Both function types return an <code>ast.Expression</code>, since that's what we're here to parse. But only the <code>infixParseFn</code> takes an argument: another <code>ast.Expression</code>. This argument is &quot;left side&quot; of the infix operator that's being parsed. A prefix operator doesn't have a &quot;left side&quot;, per definition. I know that this doesn't make a lot of sense yet, but bear with me here, you'll see how this works. For now, just remember that <code>prefixParseFn</code>s gets called when we encounter the associated token type in prefix position and <code>infixParseFn</code> gets called when we encounter the token type in infix position.</p>
<p>In order for our parser to get the correct <code>prefixParseFn</code> or <code>infixParseFn</code> for the current token type, we add two maps to the <code>Parser</code> structure:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">type</span> Parser <span class="kw">struct</span> {
    l      *lexer.Lexer
    errors []<span class="dt">string</span>

    curToken  token.Token
    peekToken token.Token

    prefixParseFns <span class="kw">map</span>[token.TokenType]prefixParseFn
    infixParseFns  <span class="kw">map</span>[token.TokenType]infixParseFn
}</code></pre></div>
<p>With these maps in place, we can just check if the appropriate map (infix or prefix) has a parsing function associated with <code>curToken.Type</code>.</p>
<p>We also give the <code>Parser</code> two helper methods that add entries to these maps:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
    p.prefixParseFns[tokenType] = fn
}

<span class="kw">func</span> (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
    p.infixParseFns[tokenType] = fn
}</code></pre></div>
<p>Now we are ready to get to the heart of the algorithm.</p>
<h3 id="identifiers">Identifiers</h3>
<p>We're going to start with possibly the simplest expression type in the Monkey programming language: identifiers. Used in an expression statement an identifier looks like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">foobar<span class="op">;</span></code></pre></div>
<p>Of course, the <code>foobar</code> is arbitrary and identifiers are expressions in other contexts too, not just in an expression statements:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(foobar<span class="op">,</span> barfoo)<span class="op">;</span>
foobar <span class="op">+</span> barfoo<span class="op">;</span>
<span class="cf">if</span> (foobar) <span class="op">{</span>
  <span class="co">// [...]</span>
<span class="op">}</span></code></pre></div>
<p>Here we have identifiers as arguments in a function call, as operands in an infix expression and as a standalone expression as part of a conditional. They can be used in all of these contexts, because identifiers are expressions just like <code>1 + 2</code>. And just like any other expression identifiers produce a value: they evaluate to the value they are bound to.</p>
<p>We start with a test:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestIdentifierExpression(t *testing.T) {
    input := <span class="st">&quot;foobar;&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;program has not enough statements. got=%d&quot;</span>,
            <span class="bu">len</span>(program.Statements))
    }
    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
            program.Statements[<span class="dv">0</span>])
    }

    ident, ok := stmt.Expression.(*ast.Identifier)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp not *ast.Identifier. got=%T&quot;</span>, stmt.Expression)
    }
    <span class="kw">if</span> ident.Value != <span class="st">&quot;foobar&quot;</span> {
        t.Errorf(<span class="st">&quot;ident.Value not %s. got=%s&quot;</span>, <span class="st">&quot;foobar&quot;</span>, ident.Value)
    }
    <span class="kw">if</span> ident.TokenLiteral() != <span class="st">&quot;foobar&quot;</span> {
        t.Errorf(<span class="st">&quot;ident.TokenLiteral not %s. got=%s&quot;</span>, <span class="st">&quot;foobar&quot;</span>,
            ident.TokenLiteral())
    }
}</code></pre></div>
<p>That's a lot of lines, but it's mostly just grunt work. We parse our input <code>foobar;</code>, check the parser for errors, make an assertion about the number of statements in the <code>*ast.Program</code> node and then check that the only statement in <code>program.Statements</code> is an <code>*ast.ExpressionStatement</code>. Then we check that the <code>*ast.ExpressionStatement.Expression</code> is an <code>*ast.Identifier</code>. Finally we check that our identifier has the correct value of <code>&quot;foobar&quot;</code>.</p>
<p>Of course, the parser tests fail:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestIdentifierExpression (0.00s)
  parser_test.go:110: program has not enough statements. got=0
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>The parser doesn't know anything about expressions yet. We need to write a <code>parseExpression</code> method.</p>
<p>The first thing we need to do is to extend the <code>parseStatement()</code> method of the parser, so that it parses expression statements. Since the only two real statement types in Monkey are let and return statements, we try to parse expression statements if we don't encounter one of the other two:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseStatement() ast.Statement {
    <span class="kw">switch</span> p.curToken.Type {
    <span class="kw">case</span> token.LET:
        <span class="kw">return</span> p.parseLetStatement()
    <span class="kw">case</span> token.RETURN:
        <span class="kw">return</span> p.parseReturnStatement()
    <span class="kw">default</span>:
        <span class="kw">return</span> p.parseExpressionStatement()
    }
}</code></pre></div>
<p>The <code>parseExpressionStatement</code> method looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
    stmt := &amp;ast.ExpressionStatement{Token: p.curToken}

    stmt.Expression = p.parseExpression(LOWEST)

    <span class="kw">if</span> p.peekTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}</code></pre></div>
<p>We already know the drill: we build our AST node and then try to fill its field by calling other parsing functions. In this case there are a few differences though: we call <code>parseExpression()</code>, which doesn't exist yet, with the constant <code>LOWEST</code>, that doesn't exist yet, and then we check for an optional semicolon. Yes, it's optional. If the <code>peekToken</code> is a <code>token.SEMICOLON</code>, we advance so it's the <code>curToken</code>. If it's not there, that's okay too, we don't add an error to the parser if it's not there. That's because we want expression statements to have optional semicolons (which makes it easier to type something like <code>5 + 5</code> into the REPL later on).</p>
<p>If we now run the tests we can see that compilation fails, because <code>LOWEST</code> is undefined. That's alright, let's add it now, by defining the precedences of the Monkey programming language:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">const</span> (
    _ <span class="dt">int</span> = <span class="ot">iota</span>
    LOWEST
    EQUALS      <span class="co">// ==</span>
    LESSGREATER <span class="co">// &gt; or &lt;</span>
    SUM         <span class="co">// +</span>
    PRODUCT     <span class="co">// *</span>
    PREFIX      <span class="co">// -X or !X</span>
    CALL        <span class="co">// myFunction(X)</span>
)</code></pre></div>
<p>Here we use <code>iota</code> to give the following constants incrementing numbers as values. The blank identifier <code>_</code> takes the zero value and the following constants get assigned the values <code>1</code> to <code>7</code>. Which numbers we use doesn't matter, but the <strong>order</strong> and the relation to each other do. What we want out of these constants is to later be able to answer: &quot;does the <code>*</code> operator have a higher precedence than the <code>==</code> operator? Does a prefix operator have a higher preference than a call expression?&quot;</p>
<p>In <code>parseExpressionStatement</code> we pass the lowest possible precedence to <code>parseExpression</code>, since we didn't parse anything yet and we can't compare precedences. That's going to make more sense in a short while, I promise. Let's write <code>parseExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseExpression(precedence <span class="dt">int</span>) ast.Expression {
    prefix := p.prefixParseFns[p.curToken.Type]
    <span class="kw">if</span> prefix == <span class="ot">nil</span> {
        <span class="kw">return</span> <span class="ot">nil</span>
    }
    leftExp := prefix()

    <span class="kw">return</span> leftExp
}</code></pre></div>
<p>That's the first version. All it does is checking whether we have a parsing function associated with <code>p.curToken.Type</code> in the prefix position. If we do, it calls this parsing function, if not, it returns nil. Which it does at the moment, since we haven't associated any tokens with any parsing functions yet. That's our next step:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>

    p.prefixParseFns = <span class="bu">make</span>(<span class="kw">map</span>[token.TokenType]prefixParseFn)
    p.registerPrefix(token.IDENT, p.parseIdentifier)

<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseIdentifier() ast.Expression {
    <span class="kw">return</span> &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
}</code></pre></div>
<p>We modified the <code>New()</code> function to initialize the <code>prefixParseFns</code> map on <code>Parser</code> and register a parsing function: if we encounter a token of type <code>token.IDENT</code> the parsing function to call is <code>parseIdentifier</code>, a method we defined on <code>*Parser</code>.</p>
<p>The <code>parseIdentifier</code> method doesn't do a lot. It only returns a <code>*ast.Identifier</code> with the current token in the <code>Token</code> field and the literal value of the token in <code>Value</code>. It doesn't advance the tokens, it doesn't call <code>nextToken</code>. That's important. All of our parsing functions, <code>prefixParseFn</code> or <code>infixParseFn</code>, are going to follow this protocol: start with <code>curToken</code> being the type of token you're associated with and return with <code>curToken</code> being the last token that's part of your expression type. Never advance the tokens too far.</p>
<p>Believe it or not, our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>We successfully parsed an identifier expression! Alright! But, before we get off the computer, find someone and proudly tell them, let's keep our breath a little longer and write some more parsing functions.</p>
<h3 id="integer-literals">Integer Literals</h3>
<p>Nearly as easy to parse as identifiers are integer literals, which look like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>Yes, that's it. Integer literals are expressions. The value they produce is the integer itself. Again, imagine in which places integer literals can occur to understand why they are expressions:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">10</span>)<span class="op">;</span>
<span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>We can use any other expression instead of integer literals here and it would still be valid: identifiers, call expressions, grouped expressions, function literals and so on. All the expression types are interchangeable and integer literals are one of them.</p>
<p>The test case for integer literals looks really similar to the one for identifiers:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestIntegerLiteralExpression(t *testing.T) {
    input := <span class="st">&quot;5;&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;program has not enough statements. got=%d&quot;</span>,
            <span class="bu">len</span>(program.Statements))
    }
    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
            program.Statements[<span class="dv">0</span>])
    }

    literal, ok := stmt.Expression.(*ast.IntegerLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp not *ast.IntegerLiteral. got=%T&quot;</span>, stmt.Expression)
    }
    <span class="kw">if</span> literal.Value != <span class="dv">5</span> {
        t.Errorf(<span class="st">&quot;literal.Value not %d. got=%d&quot;</span>, <span class="dv">5</span>, literal.Value)
    }
    <span class="kw">if</span> literal.TokenLiteral() != <span class="st">&quot;5&quot;</span> {
        t.Errorf(<span class="st">&quot;literal.TokenLiteral not %s. got=%s&quot;</span>, <span class="st">&quot;5&quot;</span>,
            literal.TokenLiteral())
    }
}</code></pre></div>
<p>And as in the test case for identifiers we use a simple input, feed it to the parser and then check that the parser didn't encounter any errors and produced the correct number of statements in <code>*ast.Program.Statements</code>. Then we add an assertion that the first statement is an <code>*ast.ExpressionStatement</code>. And finally we expect a well-formed <code>*ast.IntegerLiteral</code>.</p>
<p>The tests do not compile, since <code>*ast.IntegerLiteral</code> doesn't exist yet. Defining it is easy though:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> IntegerLiteral <span class="kw">struct</span> {
    Token token.Token
    Value <span class="dt">int64</span>
}

<span class="kw">func</span> (il *IntegerLiteral) expressionNode()      {}
<span class="kw">func</span> (il *IntegerLiteral) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> il.Token.Literal }
<span class="kw">func</span> (il *IntegerLiteral) String() <span class="dt">string</span>       { <span class="kw">return</span> il.Token.Literal }</code></pre></div>
<p><code>*ast.IntegerLiteral</code> fulfills the <code>ast.Expression</code> interface, just like <code>*ast.Identifier</code> does, but there's a notable difference to <code>ast.Identifier</code> in the structure itself: <code>Value</code> is an <code>int64</code> and not a <code>string</code>. This is the field that's going to contain the actual value the integer literal represents in the source code. When we build an <code>*ast.IntegerLiteral</code> we have to convert the string in <code>*ast.IntegerLiteral.Token.Literal</code> (which is something like <code>&quot;5&quot;</code>) to an <code>int64</code>.</p>
<p>The best place to do this is in the parsing function associated with <code>token.INT</code>, called <code>parseIntegerLiteral</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">import</span> (
<span class="co">// [...]</span>
    <span class="st">&quot;strconv&quot;</span>
)

<span class="kw">func</span> (p *Parser) parseIntegerLiteral() ast.Expression {
    lit := &amp;ast.IntegerLiteral{Token: p.curToken}

    value, err := strconv.ParseInt(p.curToken.Literal, <span class="dv">0</span>, <span class="dv">64</span>)
    <span class="kw">if</span> err != <span class="ot">nil</span> {
        msg := fmt.Sprintf(<span class="st">&quot;could not parse %q as integer&quot;</span>, p.curToken.Literal)
        p.errors = <span class="bu">append</span>(p.errors, msg)
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    lit.Value = value

    <span class="kw">return</span> lit
}</code></pre></div>
<p>Like <code>parseIdentifier</code> the method is strikingly simple. The only thing that's really different is a call to <code>strconv.ParseInt</code>, which converts the string in <code>p.curToken.Literal</code> into an <code>int64</code>. The <code>int64</code> then gets saved to the <code>Value</code> field and we return the newly constructed <code>*ast.IntegerLiteral</code> node. If that doesn't work, we add a new error to the parser's <code>errors</code> field.</p>
<p>But the tests don't pass yet:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestIntegerLiteralExpression (0.00s)
  parser_test.go:162: exp not *ast.IntegerLiteral. got=&lt;nil&gt;
FAIL
FAIL    monkey/parser   0.008s</code></pre></div>
<p>We have a <code>nil</code> instead of an <code>*ast.IntegerLiteral</code> in our AST. The reason is that <code>parseExpression</code> can't find a <code>prefixParseFn</code> for a token of type <code>token.INT</code>. All we have to do to make the tests pass is to register our <code>parseIntegerLiteral</code> method:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.prefixParseFns = <span class="bu">make</span>(<span class="kw">map</span>[token.TokenType]prefixParseFn)
    p.registerPrefix(token.IDENT, p.parseIdentifier)
    p.registerPrefix(token.INT, p.parseIntegerLiteral)

<span class="co">// [...]</span>
}</code></pre></div>
<p>With <code>parseIntegerLiteral</code> registered, <code>parseExpression</code> now knows what to do with a <code>token.INT</code> token, calls <code>parseIntegerLiteral</code> and returns its return value, an <code>*ast.IntegerLiteral</code>. The tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>I think it's time to say: we are on a roll here! Identifiers and integer literals are in the bag, let's step it up a notch and parse prefix operators.</p>
<h3 id="prefix-operators">Prefix Operators</h3>
<p>There are two prefix operators in the Monkey programming language: <code>!</code> and <code>-</code>. Their usage is pretty much what you'd expect from other languages:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">-</span><span class="dv">5</span><span class="op">;</span>
<span class="op">!</span>foobar<span class="op">;</span>
<span class="dv">5</span> <span class="op">+</span> <span class="op">-</span><span class="dv">10</span><span class="op">;</span></code></pre></div>
<p>The structure of their usage is the following:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&lt;prefix operator&gt;&lt;expression&gt;;</code></pre></div>
<p>Yes, that's right. Any expression can follow a prefix operator as operand. These are valid:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">!</span><span class="at">isGreaterThanZero</span>(<span class="dv">2</span>)<span class="op">;</span>
<span class="dv">5</span> <span class="op">+</span> <span class="op">-</span><span class="at">add</span>(<span class="dv">5</span><span class="op">,</span> <span class="dv">5</span>)<span class="op">;</span></code></pre></div>
<p>That means that an AST node for a prefix operator expression has to be flexible enough to point to any expression as its operand.</p>
<p>But first things first, here is the test case for prefix operators, or &quot;prefix expressions&quot;:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingPrefixExpressions(t *testing.T) {
    prefixTests := []<span class="kw">struct</span> {
        input        <span class="dt">string</span>
        operator     <span class="dt">string</span>
        integerValue <span class="dt">int64</span>
    }{
        {<span class="st">&quot;!5;&quot;</span>, <span class="st">&quot;!&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;-15;&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="dv">15</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> prefixTests {
        l := lexer.New(tt.input)
        p := New(l)
        program := p.ParseProgram()
        checkParserErrors(t, p)

        <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
            t.Fatalf(<span class="st">&quot;program.Statements does not contain %d statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
                <span class="dv">1</span>, <span class="bu">len</span>(program.Statements))
        }

        stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
        <span class="kw">if</span> !ok {
            t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
                program.Statements[<span class="dv">0</span>])
        }

        exp, ok := stmt.Expression.(*ast.PrefixExpression)
        <span class="kw">if</span> !ok {
            t.Fatalf(<span class="st">&quot;stmt is not ast.PrefixExpression. got=%T&quot;</span>, stmt.Expression)
        }
        <span class="kw">if</span> exp.Operator != tt.operator {
            t.Fatalf(<span class="st">&quot;exp.Operator is not &#39;%s&#39;. got=%s&quot;</span>,
                tt.operator, exp.Operator)
        }
        <span class="kw">if</span> !testIntegerLiteral(t, exp.Right, tt.integerValue) {
            <span class="kw">return</span>
        }
    }
}</code></pre></div>
<p>This test function, again, has a lot of lines. For two reasons: manually creating error messages with <code>t.Errorf</code> takes up some space and we're using a table-driven testing approach. The reason for this approach is that it saves us a lot of test code. Yes, it's only two test cases, but duplicating the complete test setup for each case would mean a lot more lines. And since the logic behind the test assertions is the same, we share the test setup. Both test cases (<code>!5</code> and <code>-15</code> as input) differ only in the expected operators and integer values (which we define here in <code>prefixTests</code>).</p>
<p>In the test function we iterate through our slice of test inputs and make assertions about the produced AST based on the values defined in the <code>prefixTests</code> slice of structs. As you can see, at the end we use a new helper function called <code>testIntegerLiteral</code> to test that the <code>Right</code> value of <code>*ast.PrefixExpression</code> is the correct integer literal. We introduce this helper function here, so the focus of the test case is on <code>*ast.PrefixExpression</code> and its fields and we will soon enough need it again. It looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> testIntegerLiteral(t *testing.T, il ast.Expression, value <span class="dt">int64</span>) <span class="dt">bool</span> {
    integ, ok := il.(*ast.IntegerLiteral)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;il not *ast.IntegerLiteral. got=%T&quot;</span>, il)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> integ.Value != value {
        t.Errorf(<span class="st">&quot;integ.Value not %d. got=%d&quot;</span>, value, integ.Value)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> integ.TokenLiteral() != fmt.Sprintf(<span class="st">&quot;%d&quot;</span>, value) {
        t.Errorf(<span class="st">&quot;integ.TokenLiteral not %d. got=%s&quot;</span>, value,
            integ.TokenLiteral())
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>There is nothing new here, we've seen this before in <code>TestIntegerLiteralExpression</code>. But now it's hidden behind a small helper function that makes these new tests more readable.</p>
<p>As expected the tests don't even compile:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
# monkey/parser
parser/parser_test.go:210: undefined: ast.PrefixExpression
FAIL    monkey/parser [build failed]</code></pre></div>
<p>We need to define the <code>ast.PrefixExpression</code> node:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> PrefixExpression <span class="kw">struct</span> {
    Token    token.Token <span class="co">// The prefix token, e.g. !</span>
    Operator <span class="dt">string</span>
    Right    Expression
}

<span class="kw">func</span> (pe *PrefixExpression) expressionNode()      {}
<span class="kw">func</span> (pe *PrefixExpression) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> pe.Token.Literal }
<span class="kw">func</span> (pe *PrefixExpression) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(pe.Operator)
    out.WriteString(pe.Right.String())
    out.WriteString(<span class="st">&quot;)&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>This doesn't contain any surprises. The <code>*ast.PrefixExpression</code> node has two noteworthy fields: <code>Operator</code> and <code>Right</code>. <code>Operator</code> is a string that's going to contain either <code>&quot;-&quot;</code> or <code>&quot;!&quot;</code>. The <code>Right</code> field contains the expression to the right of the operator.</p>
<p>In the <code>String()</code> method we deliberately add parentheses around the operator and its operand, the expression in <code>Right</code>. That allows us to see which operands belong to which operator.</p>
<p>With <code>*ast.PrefixExpression</code> defined, the tests now fail with a strange error message:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestParsingPrefixExpressions (0.00s)
  parser_test.go:198: program.Statements does not contain 1 statements. got=2
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>Why does <code>program.Statements</code> contain one statement instead of the expected two? The reason is that <code>parseExpression</code> doesn't recognize our prefix operators yet and simply returns <code>nil</code>. <code>program.Statements</code> does not contain one statement but simply one <code>nil</code>.</p>
<p>We can do better than this, we can extend our parser and the <code>parseExpression</code> method to give us better error messages when this happens:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) noPrefixParseFnError(t token.TokenType) {
    msg := fmt.Sprintf(<span class="st">&quot;no prefix parse function for %s found&quot;</span>, t)
    p.errors = <span class="bu">append</span>(p.errors, msg)
}

<span class="kw">func</span> (p *Parser) parseExpression(precedence <span class="dt">int</span>) ast.Expression {
    prefix := p.prefixParseFns[p.curToken.Type]
    <span class="kw">if</span> prefix == <span class="ot">nil</span> {
        p.noPrefixParseFnError(p.curToken.Type)
        <span class="kw">return</span> <span class="ot">nil</span>
    }
    leftExp := prefix()

    <span class="kw">return</span> leftExp
}</code></pre></div>
<p>The small helper method <code>noPrefixParseFnError</code> just adds a formatted error message to our parser's <code>errors</code> field. But that's enough to get better error messages in our failing test:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestParsingPrefixExpressions (0.00s)
  parser_test.go:227: parser has 1 errors
  parser_test.go:229: parser error: &quot;no prefix parse function for ! found&quot;
FAIL
FAIL    monkey/parser   0.010s</code></pre></div>
<p>Now it's clear what we have to do: write a parsing function for prefix expressions and register it in our parser.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.BANG, p.parsePrefixExpression)
    p.registerPrefix(token.MINUS, p.parsePrefixExpression)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parsePrefixExpression() ast.Expression {
    expression := &amp;ast.PrefixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
    }

    p.nextToken()

    expression.Right = p.parseExpression(PREFIX)

    <span class="kw">return</span> expression
}</code></pre></div>
<p>For <code>token.BANG</code> and <code>token.MINUS</code> we register the same method as <code>prefixParseFn</code>: the newly created <code>parsePrefixExpression</code>. This method builds an AST node, in this case <code>*ast.PrefixExpression</code>, just like the parsing functions we saw before. But then it does something different: it actually advances our tokens by calling <code>p.nextToken()</code>!</p>
<p>When <code>parsePrefixExpression</code> is called, <code>p.curToken</code> is either of type <code>token.BANG</code> or <code>token.MINUS</code>, because otherwise it wouldn't have been called. But in order to correctly parse a prefix expression like <code>-5</code> more than one token has to be &quot;consumed&quot;. So after using <code>p.curToken</code> to build a <code>*ast.PrefixExpression</code> node, the method advances the tokens and calls <code>parseExpression</code> again. This time with the precedence of prefix operators as argument. It's still unused, but we'll shortly see what it's good for and how to make use of it.</p>
<p>Now, when <code>parseExpression</code> is called by <code>parsePrefixExpression</code> the tokens have been advanced and the current token is the one after the prefix operator. In the case of <code>-5</code>, when <code>parseExpression</code> is called the <code>p.curToken.Type</code> is <code>token.INT</code>. <code>parseExpression</code> then checks the registered prefix parsing functions and finds <code>parseIntegerLiteral</code>, which builds an <code>*ast.IntegerLiteral</code> node and returns it. <code>parseExpression</code> returns this newly constructed node and <code>parsePrefixExpression</code> uses it to fill the <code>Right</code> field of <code>*ast.PrefixExpression</code>.</p>
<p>Yes, this works, our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">$ <span class="kw">go</span> test ./parser
ok      monkey/parser   <span class="dv">0</span>.007s</code></pre></div>
<p>Note how the &quot;protocol&quot; for our parsing functions plays out here: <code>parsePrefixExpression</code> starts with <code>p.curToken</code> being the token of the prefix operator and it returns with <code>p.curToken</code> being the operand of the prefix expression, which is the last token of the expression. The tokens get advanced just enough, which works beautifully. The neat thing is how few lines of code are needed for this. The power lies in the recursive approach.</p>
<p>Granted, the <code>precedence</code> argument in <code>parseExpression</code> is confusing, since it's unused. But we've already seen something important about its usage: the value changes depending on the caller's knowledge and its context. <code>parseExpressionStatement</code> (the top-level method that kicks off expression parsing here) knows nothing about a precedence level and just uses <code>LOWEST</code>. But <code>parsePrefixExpression</code> passes the <code>PREFIX</code> precedence to <code>parseExpression</code>, since it's parsing a prefix expression.</p>
<p>And now we'll see how <code>precedence</code> in <code>parseExpression</code> is used. Because now we're going to parse infix expressions.</p>
<h3 id="infix-operators">Infix Operators</h3>
<p>Next up we're going to parse these eight infix operators:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">-</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> / <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">&gt;</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">&lt;</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">==</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">!=</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>Don't be bothered by the <code>5</code> here. As with prefix operator expressions, we can use any expressions to the left and right of the operator.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&lt;expression&gt; &lt;infix operator&gt; &lt;expression&gt;</code></pre></div>
<p>Because of the two operands (left and right) these expressions are sometimes called &quot;binary expressions&quot; (whereas our prefix expressions would be called &quot;unary expressions&quot;). Even though we can use any expressions on either side of the operator, we're going to start by writing a test that only uses integer literals as operands. As soon as we can get the test to pass, we'll extend it to incorporate more operand types. Here it is:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingInfixExpressions(t *testing.T) {
    infixTests := []<span class="kw">struct</span> {
        input      <span class="dt">string</span>
        leftValue  <span class="dt">int64</span>
        operator   <span class="dt">string</span>
        rightValue <span class="dt">int64</span>
    }{
        {<span class="st">&quot;5 + 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 - 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;-&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 * 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;*&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 / 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;/&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 &gt; 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;&gt;&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 &lt; 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;&lt;&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 == 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;==&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;5 != 5;&quot;</span>, <span class="dv">5</span>, <span class="st">&quot;!=&quot;</span>, <span class="dv">5</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> infixTests {
        l := lexer.New(tt.input)
        p := New(l)
        program := p.ParseProgram()
        checkParserErrors(t, p)

        <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
            t.Fatalf(<span class="st">&quot;program.Statements does not contain %d statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
                <span class="dv">1</span>, <span class="bu">len</span>(program.Statements))
        }

        stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
        <span class="kw">if</span> !ok {
            t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
                program.Statements[<span class="dv">0</span>])
        }

        exp, ok := stmt.Expression.(*ast.InfixExpression)
        <span class="kw">if</span> !ok {
            t.Fatalf(<span class="st">&quot;exp is not ast.InfixExpression. got=%T&quot;</span>, stmt.Expression)
        }

        <span class="kw">if</span> !testIntegerLiteral(t, exp.Left, tt.leftValue) {
            <span class="kw">return</span>
        }

        <span class="kw">if</span> exp.Operator != tt.operator {
            t.Fatalf(<span class="st">&quot;exp.Operator is not &#39;%s&#39;. got=%s&quot;</span>,
                tt.operator, exp.Operator)
        }

        <span class="kw">if</span> !testIntegerLiteral(t, exp.Right, tt.rightValue) {
            <span class="kw">return</span>
        }
    }
}</code></pre></div>
<p>This test is nearly a straight copy of <code>TestParsingPrefixExpressions</code>, except that we now make assertions about the <code>Right</code> <em>and</em> <code>Left</code> fields of the resulting AST node. Here the table-driven approach gives us great leverage that we'll soon use when we extend the test to also include identifiers.</p>
<p>The tests fail, of course, because they can't find a definition of <code>*ast.InfixExpression</code>. And in order to get real failing tests, we define <code>ast.InfixExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> InfixExpression <span class="kw">struct</span> {
    Token    token.Token <span class="co">// The operator token, e.g. +</span>
    Left     Expression
    Operator <span class="dt">string</span>
    Right    Expression
}

<span class="kw">func</span> (oe *InfixExpression) expressionNode()      {}
<span class="kw">func</span> (oe *InfixExpression) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> oe.Token.Literal }
<span class="kw">func</span> (oe *InfixExpression) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(oe.Left.String())
    out.WriteString(<span class="st">&quot; &quot;</span> + oe.Operator + <span class="st">&quot; &quot;</span>)
    out.WriteString(oe.Right.String())
    out.WriteString(<span class="st">&quot;)&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>Just like with <code>ast.PrefixExpression</code>, we define <code>ast.InfixExpression</code> to fulfill the <code>ast.Expression</code> and <code>ast.Node</code> interfaces, by defining the <code>expressionNode()</code>, <code>TokenLiteral()</code> and <code>String()</code> methods. The only difference to <code>ast.PrefixExpression</code> is the new field called <code>Left</code>, which can hold any expression.</p>
<p>With that out of the way, we can build and run our tests. And the tests even return one of our own new error messages:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestParsingInfixExpressions (0.00s)
  parser_test.go:246: parser has 1 errors
  parser_test.go:248: parser error: &quot;no prefix parse function for + found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>But that error message is deceiving. It says &quot;no prefix parse function for + found&quot;. The problem is that we do not want our parser to find a prefix parse function for <code>+</code>. We want it to find an infix parse function.</p>
<p>This is the point where we're going from &quot;I guess it's neat&quot; to &quot;Wow, this is beautiful&quot;, because we now need to complete our <code>parseExpression</code> method. And to do that, we first need a precedence table and a few helper methods:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">var</span> precedences = <span class="kw">map</span>[token.TokenType]<span class="dt">int</span>{
    token.EQ:       EQUALS,
    token.NOT_EQ:   EQUALS,
    token.LT:       LESSGREATER,
    token.GT:       LESSGREATER,
    token.PLUS:     SUM,
    token.MINUS:    SUM,
    token.SLASH:    PRODUCT,
    token.ASTERISK: PRODUCT,
}

<span class="co">// [...]</span>

<span class="kw">func</span> (p *Parser) peekPrecedence() <span class="dt">int</span> {
    <span class="kw">if</span> p, ok := precedences[p.peekToken.Type]; ok {
        <span class="kw">return</span> p
    }

    <span class="kw">return</span> LOWEST
}

<span class="kw">func</span> (p *Parser) curPrecedence() <span class="dt">int</span> {
    <span class="kw">if</span> p, ok := precedences[p.curToken.Type]; ok {
        <span class="kw">return</span> p
    }

    <span class="kw">return</span> LOWEST
}</code></pre></div>
<p><code>precedences</code> is our precedence table: it associates token types with their precedence. The precedence values themselves are the constants we defined earlier, the integers with increasing value. This table can now tell us that <code>+</code> (<code>token.PLUS</code>) and <code>-</code> (<code>token.MINUS</code>) have the same precedence, which is lower than the precedence of <code>*</code> (<code>token.ASTERISK</code>) and <code>/</code> (<code>token.SLASH</code>), for example.</p>
<p>The <code>peekPrecedence</code> method returns the precedence associated with the token type of <code>p.peekToken</code>. If it doesn't find a precedence for <code>p.peekToken</code> it defaults to <code>LOWEST</code>, the lowest possible precedence any operator can have. The <code>curPrecedence</code> method does the same thing, but for <code>p.curToken</code>.</p>
<p>The next step is to register one infix parse function for all of our infix operators:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.infixParseFns = <span class="bu">make</span>(<span class="kw">map</span>[token.TokenType]infixParseFn)
    p.registerInfix(token.PLUS, p.parseInfixExpression)
    p.registerInfix(token.MINUS, p.parseInfixExpression)
    p.registerInfix(token.SLASH, p.parseInfixExpression)
    p.registerInfix(token.ASTERISK, p.parseInfixExpression)
    p.registerInfix(token.EQ, p.parseInfixExpression)
    p.registerInfix(token.NOT_EQ, p.parseInfixExpression)
    p.registerInfix(token.LT, p.parseInfixExpression)
    p.registerInfix(token.GT, p.parseInfixExpression)
<span class="co">// [...]</span>
}</code></pre></div>
<p>We already have the <code>registerInfix</code> method in our repertoire and now we finally use it. Every infix operator gets associated with the same parsing function called <code>parseInfixExpression</code>, which looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
    expression := &amp;ast.InfixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
        Left:     left,
    }

    precedence := p.curPrecedence()
    p.nextToken()
    expression.Right = p.parseExpression(precedence)

    <span class="kw">return</span> expression
}</code></pre></div>
<p>The notable difference here is that, in contrast to <code>parsePrefixExpression</code>, this new method takes an argument, an <code>ast.Expression</code> called <code>left</code>. It uses this argument to construct an <code>*ast.InfixExpression</code> node, with <code>left</code> being in the <code>Left</code> field. Then it assigns the precedence of the current token (which is the operator of the infix expression) to the local variable <code>precedence</code>, before advancing the tokens by calling <code>nextToken</code> and filling the <code>Right</code> field of the node with another call to <code>parseExpression</code> - this time passing in the precedence of the operator token.</p>
<p>It's time to lift the curtain. Here is the heart of our Pratt parser, here is the final version of <code>parseExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseExpression(precedence <span class="dt">int</span>) ast.Expression {
    prefix := p.prefixParseFns[p.curToken.Type]
    <span class="kw">if</span> prefix == <span class="ot">nil</span> {
        p.noPrefixParseFnError(p.curToken.Type)
        <span class="kw">return</span> <span class="ot">nil</span>
    }
    leftExp := prefix()

    <span class="kw">for</span> !p.peekTokenIs(token.SEMICOLON) &amp;&amp; precedence &lt; p.peekPrecedence() {
        infix := p.infixParseFns[p.peekToken.Type]
        <span class="kw">if</span> infix == <span class="ot">nil</span> {
            <span class="kw">return</span> leftExp
        }

        p.nextToken()

        leftExp = infix(leftExp)
    }

    <span class="kw">return</span> leftExp
}</code></pre></div>
<p>And, boom! Our tests pass! It's all green, baby:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.006s</code></pre></div>
<p>We are now officially able to parse infix operator expressions correctly! <em>Wait, what? What the hell did just happen? How does this work?</em></p>
<p>Obviously <code>parseExpression</code> now does a few more things. We already know how it finds an associated <code>prefixParseFn</code> with the current token and calls it. We've seen this work with prefix operators, identifiers and integer literals.</p>
<p>What's new is the loop right in the middle of <code>parseExpression</code>. In the loop's body the method tries to find <code>infixParseFn</code>s for the next token. If it finds such a function, it calls it, passing in the expression returned by a <code>prefixParseFn</code> as an argument. And it does all this again and again until it encounters a token that has a higher precedence.</p>
<p>This works beautifully. Look at these tests that use multiple operators with different precedences and how the AST in string form correctly represents this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestOperatorPrecedenceParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">string</span>
    }{
        {
            <span class="st">&quot;-a * b&quot;</span>,
            <span class="st">&quot;((-a) * b)&quot;</span>,
        },
        {
            <span class="st">&quot;!-a&quot;</span>,
            <span class="st">&quot;(!(-a))&quot;</span>,
        },
        {
            <span class="st">&quot;a + b + c&quot;</span>,
            <span class="st">&quot;((a + b) + c)&quot;</span>,
        },
        {
            <span class="st">&quot;a + b - c&quot;</span>,
            <span class="st">&quot;((a + b) - c)&quot;</span>,
        },
        {
            <span class="st">&quot;a * b * c&quot;</span>,
            <span class="st">&quot;((a * b) * c)&quot;</span>,
        },
        {
            <span class="st">&quot;a * b / c&quot;</span>,
            <span class="st">&quot;((a * b) / c)&quot;</span>,
        },
        {
            <span class="st">&quot;a + b / c&quot;</span>,
            <span class="st">&quot;(a + (b / c))&quot;</span>,
        },
        {
            <span class="st">&quot;a + b * c + d / e - f&quot;</span>,
            <span class="st">&quot;(((a + (b * c)) + (d / e)) - f)&quot;</span>,
        },
        {
            <span class="st">&quot;3 + 4; -5 * 5&quot;</span>,
            <span class="st">&quot;(3 + 4)((-5) * 5)&quot;</span>,
        },
        {
            <span class="st">&quot;5 &gt; 4 == 3 &lt; 4&quot;</span>,
            <span class="st">&quot;((5 &gt; 4) == (3 &lt; 4))&quot;</span>,
        },
        {
            <span class="st">&quot;5 &lt; 4 != 3 &gt; 4&quot;</span>,
            <span class="st">&quot;((5 &lt; 4) != (3 &gt; 4))&quot;</span>,
        },
        {
            <span class="st">&quot;3 + 4 * 5 == 3 * 1 + 4 * 5&quot;</span>,
            <span class="st">&quot;((3 + (4 * 5)) == ((3 * 1) + (4 * 5)))&quot;</span>,
        },
        {
            <span class="st">&quot;3 + 4 * 5 == 3 * 1 + 4 * 5&quot;</span>,
            <span class="st">&quot;((3 + (4 * 5)) == ((3 * 1) + (4 * 5)))&quot;</span>,
        },
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        l := lexer.New(tt.input)
        p := New(l)
        program := p.ParseProgram()
        checkParserErrors(t, p)

        actual := program.String()
        <span class="kw">if</span> actual != tt.expected {
            t.Errorf(<span class="st">&quot;expected=%q, got=%q&quot;</span>, tt.expected, actual)
        }
    }
}</code></pre></div>
<p>They're all passing! That's pretty amazing, isn't it? The different <code>*ast.InfixExpression</code>s are nested correctly, which we can observe thanks to our usage of parentheses in the <code>String()</code> methods of the AST nodes.</p>
<p>If you're scratching your head and wondering how all of this works, don't worry. We're now going to take a really close look at our <code>parseExpression</code> method.</p>
<h2 id="how-pratt-parsing-works">2.7 - How Pratt Parsing Works</h2>
<p>The algorithm behind the <code>parseExpression</code> method and its combination of parsing functions and precedences is fully described by Vaughan Pratt in his &quot;Top Down Operator Precedence&quot; paper. But there are differences between his and our implementation.</p>
<p>Pratt doesn't use a <code>Parser</code> structure and doesn't pass around methods defined on <code>*Parser</code>. He also doesn't use maps and, of course, he didn't use Go. His paper predates the release of Go by 36 years. And then there are naming differences: what we call <code>prefixParseFn</code>s are &quot;nuds&quot; (for &quot;null denotations&quot;) for Pratt. <code>infixParseFns</code> are &quot;leds&quot; (for &quot;left denotations&quot;).</p>
<p>Formulated in pseudocode though, our <code>parseExpression</code> method looks strikingly similar to the code presented in Pratt's paper. It uses the same algorithm with barely any changes.</p>
<p>We're going to skip the theory that answers <em>why</em> it works and just follow <em>how</em> it works and how all the pieces (<code>parseExpression</code>, parsing functions and precedences) fit together by looking at an example. Suppose we're parsing the following expression statement:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">1</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span><span class="op">;</span></code></pre></div>
<p>The big challenge here is not to represent every operator and operand in the resulting AST, but to nest the nodes of the AST correctly. What we want is an AST that (serialized as a string) looks like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">((<span class="dv">1</span> <span class="op">+</span> <span class="dv">2</span>) <span class="op">+</span> <span class="dv">3</span>)</code></pre></div>
<p>The AST needs to have two <code>*ast.InfixExpression</code> nodes. The <code>*ast.InfixExpression</code> higher in the tree should have the integer literal <code>3</code> as its <code>Right</code> child node and its <code>Left</code> child node needs to be the other <code>*ast.InfixExpression</code>. This second <code>*ast.InfixExpression</code> then needs to have the integer literals <code>1</code> and <code>2</code> as its <code>Left</code> and <code>Right</code> child nodes, respectively. Like this:</p>
<div class="figure">
<img src="./images/infix_expression.png" width="400" />

</div>
<p>And this is exactly what our parser outputs when it parses <code>1 + 2 + 3;</code>. But how? We'll answer that question in the following paragraphs. We're going take a close look at what the parser does as soon as <code>parseExpressionStatement</code> is called for the first time. It's not a mistake to have the code open while reading the following paragraphs.</p>
<p>So here we go. Here is what happens when we parse <code>1 + 2 + 3;</code>:</p>
<p><code>parseExpressionStatement</code> calls <code>parseExpression(LOWEST)</code>. The <code>p.curToken</code> and <code>p.peekToken</code> are the <code>1</code> and the first <code>+</code>:</p>
<div class="figure">
<img src="./images/curtoken_peektoken_1.png" width="400" />

</div>
<p>The first thing <code>parseExpression</code> then does is to check whether there is a <code>prefixParseFn</code> associated with the current <code>p.curToken.Type</code>, which is a <code>token.INT</code>. And, yes, there is: <code>parseIntegerLiteral</code>. So it calls <code>parseIntegerLiteral</code>, which returns an <code>*ast.IntegerLiteral</code>. <code>parseExpression</code> assigns this to <code>leftExp</code>.</p>
<p>Then comes the new for-loop in <code>parseExpression</code>. Its condition evaluates to true:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">for</span> !p.peekTokenIs(token.SEMICOLON) &amp;&amp; precedence &lt; p.peekPrecedence() {
<span class="co">// [...]</span>
}</code></pre></div>
<p><code>p.peekToken</code> is not a <code>token.SEMICOLON</code> and <code>peekPrecedence</code> (which returns the precedence of the <code>+</code> token) is higher than the argument passed to <code>parseExpression</code>, which is <code>LOWEST</code>. Here are our defined precedences again to refresh our memory:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">const</span> (
    _ <span class="dt">int</span> = <span class="ot">iota</span>
    LOWEST
    EQUALS      <span class="co">// ==</span>
    LESSGREATER <span class="co">// &gt; or &lt;</span>
    SUM         <span class="co">// +</span>
    PRODUCT     <span class="co">// *</span>
    PREFIX      <span class="co">// -X or !X</span>
    CALL        <span class="co">// myFunction(X)</span>
)</code></pre></div>
<p>So the condition evaluates to true and <code>parseExpression</code> executes the body of the loop, which looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">infix := p.infixParseFns[p.peekToken.Type]
<span class="kw">if</span> infix == <span class="ot">nil</span> {
  <span class="kw">return</span> leftExp
}

p.nextToken()

leftExp = infix(leftExp)</code></pre></div>
<p>Now it fetches the <code>infixParseFn</code> for <code>p.peekToken.Type</code>, which is <code>parseInfixExpression</code> defined on <code>*Parser</code>. Before calling it and assigning its return value to <code>leftExp</code> (reusing the <code>leftExp</code> variable!) it advances the tokens so they now look like this:</p>
<div class="figure">
<img src="./images/curtoken_peektoken_2.png" width="400" />

</div>
<p>With the tokens in this state, it calls <code>parseInfixExpression</code> and passes in the already parsed <code>*ast.IntegerLiteral</code> (assigned to <code>leftExp</code> outside the for-loop). What happens next in <code>parseInfixExpression</code> is where things get interesting. Here is the method again:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
    expression := &amp;ast.InfixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
        Left:     left,
    }

    precedence := p.curPrecedence()
    p.nextToken()
    expression.Right = p.parseExpression(precedence)

    <span class="kw">return</span> expression
}</code></pre></div>
<p>It's important to note that <code>left</code> is our already parsed <code>*ast.IntegerLiteral</code> that represents the <code>1</code>.</p>
<p><code>parseInfixExpression</code> saves the precedence of <code>p.curToken</code> (the first <code>+</code> token!), advances the tokens and calls <code>parseExpression</code> - passing in the just saved precedence. So now <code>parseExpression</code> is called the second time, with the tokens looking like this:</p>
<div class="figure">
<img src="./images/curtoken_peektoken_3.png" width="400" />

</div>
<p>The first thing <code>parseExpression</code> does again is to look for a <code>prefixParseFn</code> for <code>p.curToken</code>. And again it's <code>parseIntegerLiteral</code>. But now the condition of the for-loop doesn't evaluate to true: <code>precedence</code> (the argument passed to <code>parseExpression</code>) is the precedence of the <em>first</em> <code>+</code> operator in <code>1 + 2 + 3</code>, which is <em>not</em> smaller than the precedence of <code>p.peekToken</code>, the second <code>+</code> operator. They are equal. The body of the for-loop is not executed and the <code>*ast.IntegerLiteral</code> representing the <code>2</code> is returned.</p>
<p>Now back in <code>parseInfixExpression</code> the return-value of <code>parseExpression</code> is assigned to the <code>Right</code> field of the newly constructed <code>*ast.InfixExpression</code>. So now we have this:</p>
<div class="figure">
<img src="./images/first_infix_expression.png" width="400" />

</div>
<p>This <code>*ast.InfixExpressions</code> gets returned by <code>parseInfixExpression</code> and now we're back in the outer-most call to <code>parseExpression</code>, where <code>precedence</code> is still <code>LOWEST</code>. We are back where we started and the condition of the for-loop is evaluated again.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">for</span> !p.peekTokenIs(token.SEMICOLON) &amp;&amp; precedence &lt; p.peekPrecedence() {
<span class="co">// [...]</span>
}</code></pre></div>
<p>This still evaluates to true, since <code>precedence</code> is <code>LOWEST</code> and <code>peekPrecedence</code> now returns the precedence of the second <code>+</code> in our expression, which is higher. <code>parseExpression</code> executes the body of the for-loop a second time. The difference is that now <code>leftExp</code> is not an <code>*ast.IntegerLiteral</code> representing the <code>1</code>, but the <code>*ast.InfixExpression</code> returned by <code>parseInfixExpression</code>, representing <code>1 + 2</code>.</p>
<p>In the body of the loop <code>parseExpression</code> fetches <code>parseInfixExpression</code> as the <code>infixParseFn</code> for <code>p.peekToken.Type</code> (which is the second <code>+</code>), advances the tokens and calls <code>parseInfixExpression</code> with <code>leftExp</code> as the argument. <code>parseInfixExpression</code> in turn calls <code>parseExpression</code> again, which returns the last <code>*ast.IntegerLiteral</code> (that represents the <code>3</code> in our expression).</p>
<p>After all this, at the end of the loop-body, <code>leftExp</code> looks like this:</p>
<div class="figure">
<img src="./images/infix_expression.png" width="400" />

</div>
<p>That's exactly what we wanted! The operators and operands are nested correctly! And our tokens look like this:</p>
<div class="figure">
<img src="./images/curtoken_peektoken_4.png" width="400" />

</div>
<p>The condition of the for-loop evaluates to false:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">for</span> !p.peekTokenIs(token.SEMICOLON) &amp;&amp; precedence &lt; p.peekPrecedence() {
<span class="co">// [...]</span>
}</code></pre></div>
<p>Now <code>p.peekTokenIs(token.SEMICOLON)</code> evaluates to true, which stops the body of the loop from being executed again.</p>
<p>(The call to <code>p.peekTokenIs(token.SEMICOLON)</code> is not strictly necessary. Our <code>peekPrecedence</code> method returns <code>LOWEST</code> as the default value if no precedence for <code>p.peekToken.Type</code> can be found - which is the case for <code>token.SEMICOLON</code> tokens. But I think it makes the behaviour of semicolons as expression-ending-delimiters more explicit and easier to understand.)</p>
<p>And that's it! The for-loop is done and <code>leftExp</code> is returned. We're back in <code>parseExpressionStatement</code> and have the final and correct <code>*ast.InfixExpression</code> at hand. And that's used as the <code>Expression</code> in <code>*ast.ExpressionStatement</code>.</p>
<p>Now we know how our parser manages to parse <code>1 + 2 + 3</code> correctly. It's pretty fascinating, isn't it? I think the usage of <code>precedence</code> and <code>peekPrecedence</code> is particularly interesting.</p>
<p>But what about &quot;real precedence issues&quot;? In our example every operator (the <code>+</code>) had the same precedence. What do the different precedence levels for operators accomplish? Couldn't we just use <code>LOWEST</code> per default and something called <code>HIGHEST</code> for all operators?</p>
<p>No, because that would give us a wrong AST. The goal is to have expressions involving operators with a higher precedence to be deeper in the tree than expressions with lower precedence operators. This is accomplished by the <code>precedence</code> value (the argument) in <code>parseExpression</code>.</p>
<p>When <code>parseExpression</code> is called the value of <code>precedence</code> stands for the current &quot;right-binding power&quot; of the current <code>parseExpression</code> invocation. What does &quot;right-binding power&quot; mean? Well, the higher it is, the more tokens/operators/operands to the right of the current expressions (the future peek tokens) can we &quot;bind&quot; to it, or as I like to think, &quot;suck in&quot;.</p>
<p>In case our current right-binding power is of the highest possible value, what we parsed so far (assigned to <code>leftExp</code>) is <em>never</em> passed to an <code>infixParseFn</code> associated with the next operator (or token). It will never end up as a &quot;left&quot; child node. Because the condition of the for-loop never evaluates to true.</p>
<p>A counterpart to right-binding power exists and it's called (you guessed it!) &quot;left-binding power&quot;. But which value signifies this left-binding power? Since the <code>precedence</code> argument in <code>parseExpression</code> stands for the current right-binding power, where does the left-binding power of the next operator come from? Simply put: from our call to <code>peekPrecedence</code>. The value this call returns stands for the left-binding power of the next operator, of <code>p.peekToken</code>.</p>
<p>It all comes down to the <code>precedence &lt; p.peekPrecedence()</code> condition of our for-loop. This condition checks if the left-binding power of the next operator/token is higher than our current right-binding power. If it is, what we parsed so far gets &quot;sucked in&quot; by the next operator, from left to right, and ends up being passed to the <code>infixParseFn</code> of the next operator.</p>
<p>An example: let's say we're parsing the expression statement <code>-1 + 2;</code>. What we want the AST to represent is <code>(-1) + 2</code> and not <code>-(1 + 2)</code>. The first method we end up in (after <code>parseExpressionStatement</code> and <code>parseExpression</code>) is the <code>prefixParseFn</code> we associated with <code>token.MINUS</code>: <code>parsePrefixExpression</code>. To refresh our memory of <code>parsePrefixExpression</code> here it is in its entirety:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parsePrefixExpression() ast.Expression {
  expression := &amp;ast.PrefixExpression{
    Token:    p.curToken,
    Operator: p.curToken.Literal,
  }
  p.nextToken()
  expression.Right = p.parseExpression(PREFIX)
  <span class="kw">return</span> expression
}</code></pre></div>
<p>This passes <code>PREFIX</code> to <code>parseExpression</code> as <code>precedence</code>, turning <code>PREFIX</code> into the right-binding power of that <code>parseExpression</code> invocation. <code>PREFIX</code> is a really high precedence, as per our definition. The result of this is that <code>parseExpression(PREFIX)</code> is <em>never</em> going to parse the <code>1</code> in <code>-1</code> and pass it to another <code>infixParseFn</code>. The <code>precedence &lt; p.peekPrecedence()</code> will never be true in this case, meaning that no other <code>infixParseFn</code> is going to get our <code>1</code> as the left arm. Instead the <code>1</code> is returned as the &quot;right&quot; arm of our prefix expression. Just the <code>1</code>, not some other expression that comes after and needs to be parsed.</p>
<p>Back in the outer call to <code>parseExpression</code> (in which we called <code>parsePrefixExpression</code> as a <code>prefixParseFn</code>), right after the first <code>leftExp := prefix()</code>, the value of <code>precedence</code> is still <code>LOWEST</code>. Since that was the value we used in the outer-most call. Our right-binding power is still <code>LOWEST</code>. The <code>p.peekToken</code> is now the <code>+</code> in <code>-1 + 2</code>.</p>
<p>We're now sitting on the condition of the for-loop and evaluate it to determine whether we should execute the body of the loop. And it turns out that the precedence of the <code>+</code> operator (returned by <code>p.peekPrecedence()</code>) is higher than our current right-binding power. What we parsed so far (the <code>-1</code> prefix expression) is now passed to the <code>infixParseFn</code> associated with <code>+</code>. The left-binding power of the <code>+</code> &quot;sucks in&quot; what we parsed so far and uses it as the &quot;left arm&quot; of the AST node it is constructing.</p>
<p>The <code>infixParseFn</code> for <code>+</code> is <code>parseInfixExpression</code>, which now uses the precedence of <code>+</code> as the right-binding power in its call to <code>parseExpression</code>. It doesn't use <code>LOWEST</code>, because that would result in another <code>+</code> having a higher left-binding power and &quot;sucking&quot; away our &quot;right arm&quot;. If it did, then an expression like <code>a + b + c</code> would result in <code>(a + (b + c))</code>, which is not what we want. We want <code>((a + b) + c)</code>.</p>
<p>The high precedence of prefix operators worked. And it even works great for infix operators. In the classic example for operator precedences <code>1 + 2 * 3</code>, the left-binding power of <code>*</code> would be higher than the right-binding power of <code>+</code>. Parsing this would result in the <code>2</code> being passed to the <code>infixParseFn</code> associated with the <code>*</code> token.</p>
<p>Notable is that in our parser, every token has the same right- and left-binding power. We simply use one value (in our <code>precedences</code> table) as both. What this value means changes depending on the context.</p>
<p>If an operator should be right-associative instead of left-associative (in the case of <code>+</code> that would result in <code>(a + (b  + c))</code> instead of <code>((a + b) + c)</code>, then we must use a smaller &quot;right-binding power&quot; when parsing the &quot;right arm&quot; of the operator expression. If you think about the <code>++</code> and <code>--</code> operators in other languages, where they can be used in a pre- and a postfix position, you can see why it's sometimes useful to have differing left- and right-binding powers for operators.</p>
<p>Since we did not define separate right- and left-binding powers for operators, but only use one value, we can't just change a definition to achieve this. But, as an example, to make <code>+</code> right-associate we can decrement its precedence when calling <code>parseExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
    expression := &amp;ast.InfixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
        Left:     left,
    }

    precedence := p.curPrecedence()
    p.nextToken()
    expression.Right = p.parseExpression(precedence)
    <span class="co">//                                   ^^^ decrement here for right-associativity</span>

    <span class="kw">return</span> expression
}</code></pre></div>
<p>For demonstration purposes, let's change this method for a minute and see what happens:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
    expression := &amp;ast.InfixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
        Left:     left,
    }

    precedence := p.curPrecedence()
    p.nextToken()

    <span class="kw">if</span> expression.Operator == <span class="st">&quot;+&quot;</span> {
        expression.Right = p.parseExpression(precedence - <span class="dv">1</span>)
    } <span class="kw">else</span> {
        expression.Right = p.parseExpression(precedence)
    }

    <span class="kw">return</span> expression
}</code></pre></div>
<p>With this change made, our tests tell us that <code>+</code> is officially right-associative:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test -run TestOperatorPrecedenceParsing ./parser
--- FAIL: TestOperatorPrecedenceParsing (0.00s)
  parser_test.go:359: expected=&quot;((a + b) + c)&quot;, got=&quot;(a + (b + c))&quot;
  parser_test.go:359: expected=&quot;((a + b) - c)&quot;, got=&quot;(a + (b - c))&quot;
  parser_test.go:359: expected=&quot;(((a + (b * c)) + (d / e)) - f)&quot;,\
    got=&quot;(a + ((b * c) + ((d / e) - f)))&quot;
FAIL</code></pre></div>
<p>And that marks the end of our deep dive into the bowels of <code>parseExpression</code>. If you're still unsure and can't grasp how it works, don't worry, I felt the same. What really helped though was putting tracing statements in the methods of <code>Parser</code> to see what was happening when parsing certain expressions. In the folder of code accompanying this chapter I've included a file called <code>./parser/parser_tracing.go</code>, which we haven't looked at before. The file includes two function definitions that are really helpful when trying to understand what the parser does: <code>trace</code> and <code>untrace</code>. Use them like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
    <span class="kw">defer</span> untrace(trace(<span class="st">&quot;parseExpressionStatement&quot;</span>))
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseExpression(precedence <span class="dt">int</span>) ast.Expression {
    <span class="kw">defer</span> untrace(trace(<span class="st">&quot;parseExpression&quot;</span>))
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseIntegerLiteral() ast.Expression {
    <span class="kw">defer</span> untrace(trace(<span class="st">&quot;parseIntegerLiteral&quot;</span>))
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parsePrefixExpression() ast.Expression {
    <span class="kw">defer</span> untrace(trace(<span class="st">&quot;parsePrefixExpression&quot;</span>))
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseInfixExpression(left ast.Expression) ast.Expression {
    <span class="kw">defer</span> untrace(trace(<span class="st">&quot;parseInfixExpression&quot;</span>))
<span class="co">// [...]</span>
}</code></pre></div>
<p>With these tracing statements included we can now use our parser and see what it does. Here is the output when parsing the expression statement <code>-1 * 2 + 3</code> in the test suite:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test -v -run TestOperatorPrecedenceParsing ./parser
=== RUN   TestOperatorPrecedenceParsing
BEGIN parseExpressionStatement
        BEGIN parseExpression
                BEGIN parsePrefixExpression
                        BEGIN parseExpression
                                BEGIN parseIntegerLiteral
                                END parseIntegerLiteral
                        END parseExpression
                END parsePrefixExpression
                BEGIN parseInfixExpression
                        BEGIN parseExpression
                                BEGIN parseIntegerLiteral
                                END parseIntegerLiteral
                        END parseExpression
                END parseInfixExpression
                BEGIN parseInfixExpression
                        BEGIN parseExpression
                                BEGIN parseIntegerLiteral
                                END parseIntegerLiteral
                        END parseExpression
                END parseInfixExpression
        END parseExpression
END parseExpressionStatement
--- PASS: TestOperatorPrecedenceParsing (0.00s)
PASS
ok      monkey/parser   0.008s</code></pre></div>
<h2 id="extending-the-parser">2.8 - Extending the Parser</h2>
<p>Before we move on and extend our parser, we first need to clean up and extend our existing test suite. I won't bore you by listing the complete changes, but I will show you a few small helper functions that make the tests easier to understand.</p>
<p>We already have a <code>testIntegerLiteral</code> test helper. A second function called <code>testIdentifier</code> can clean up a lot of other tests:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> testIdentifier(t *testing.T, exp ast.Expression, value <span class="dt">string</span>) <span class="dt">bool</span> {
    ident, ok := exp.(*ast.Identifier)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;exp not *ast.Identifier. got=%T&quot;</span>, exp)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> ident.Value != value {
        t.Errorf(<span class="st">&quot;ident.Value not %s. got=%s&quot;</span>, value, ident.Value)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> ident.TokenLiteral() != value {
        t.Errorf(<span class="st">&quot;ident.TokenLiteral not %s. got=%s&quot;</span>, value,
            ident.TokenLiteral())
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>The fun part is now using <code>testIntegerLiteral</code> and <code>testIdentifier</code> to build more generic helper functions:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> testLiteralExpression(
    t *testing.T,
    exp ast.Expression,
    expected <span class="kw">interface</span>{},
) <span class="dt">bool</span> {
    <span class="kw">switch</span> v := expected.(<span class="kw">type</span>) {
    <span class="kw">case</span> <span class="dt">int</span>:
        <span class="kw">return</span> testIntegerLiteral(t, exp, <span class="dt">int64</span>(v))
    <span class="kw">case</span> <span class="dt">int64</span>:
        <span class="kw">return</span> testIntegerLiteral(t, exp, v)
    <span class="kw">case</span> <span class="dt">string</span>:
        <span class="kw">return</span> testIdentifier(t, exp, v)
    }
    t.Errorf(<span class="st">&quot;type of exp not handled. got=%T&quot;</span>, exp)
    <span class="kw">return</span> <span class="ot">false</span>
}

<span class="kw">func</span> testInfixExpression(t *testing.T, exp ast.Expression, left <span class="kw">interface</span>{},
    operator <span class="dt">string</span>, right <span class="kw">interface</span>{}) <span class="dt">bool</span> {

    opExp, ok := exp.(*ast.InfixExpression)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;exp is not ast.OperatorExpression. got=%T(%s)&quot;</span>, exp, exp)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> !testLiteralExpression(t, opExp.Left, left) {
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> opExp.Operator != operator {
        t.Errorf(<span class="st">&quot;exp.Operator is not &#39;%s&#39;. got=%q&quot;</span>, operator, opExp.Operator)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> !testLiteralExpression(t, opExp.Right, right) {
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>With these in place it's possible to write test code like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">testInfixExpression(t, stmt.Expression, <span class="dv">5</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">10</span>)
testInfixExpression(t, stmt.Expression, <span class="st">&quot;alice&quot;</span>, <span class="st">&quot;*&quot;</span>, <span class="st">&quot;bob&quot;</span>)</code></pre></div>
<p>That makes it a lot easier to test properties of the ASTs produced by our parser. See <code>parser/parser_test.go</code> for the cleaned up and extended test suite.</p>
<h3 id="boolean-literals">Boolean Literals</h3>
<p>There are a few things in the Monkey programming language that we still need to implement in our parser and AST. Easiest are boolean literals. In Monkey we can use booleans in place of any other expression:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">true</span><span class="op">;</span>
<span class="kw">false</span><span class="op">;</span>
<span class="kw">let</span> foobar <span class="op">=</span> <span class="kw">true</span><span class="op">;</span>
<span class="kw">let</span> barfoo <span class="op">=</span> <span class="kw">false</span><span class="op">;</span></code></pre></div>
<p>Like identifiers and integer literals their AST representation is simple and small:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> Boolean <span class="kw">struct</span> {
    Token token.Token
    Value <span class="dt">bool</span>
}

<span class="kw">func</span> (b *Boolean) expressionNode()      {}
<span class="kw">func</span> (b *Boolean) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> b.Token.Literal }
<span class="kw">func</span> (b *Boolean) String() <span class="dt">string</span>       { <span class="kw">return</span> b.Token.Literal }</code></pre></div>
<p>The <code>Value</code> field can hold values of the type <code>bool</code>, which means that we're going to save either <code>true</code> or <code>false</code> in there (the Go <code>bool</code> values, not the Monkey literals).</p>
<p>With the AST node defined we can now add our tests. The single <code>TestBooleanExpression</code> test function is so similar to <code>TestIdentifierExpression</code> and <code>TestIntegerLiteralExpression</code> that I won't show it here. It's enough to show the error message which points us in the right direction as to how to implement boolean literal parsing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestBooleanExpression (0.00s)
  parser_test.go:470: parser has 1 errors
  parser_test.go:472: parser error: &quot;no prefix parse function for true found&quot;
FAIL
FAIL    monkey/parser   0.008s</code></pre></div>
<p>Of course, yes. We need to register a <code>prefixParseFn</code> for <code>token.TRUE</code> and <code>token.FALSE</code> tokens.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.TRUE, p.parseBoolean)
    p.registerPrefix(token.FALSE, p.parseBoolean)
<span class="co">// [...]</span>
}</code></pre></div>
<p>And the <code>parseBoolean</code> method is exactly what you imagine it to be:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseBoolean() ast.Expression {
    <span class="kw">return</span> &amp;ast.Boolean{Token: p.curToken, Value: p.curTokenIs(token.TRUE)}
}</code></pre></div>
<p>The only mildly interesting part about this method is the inlining of the <code>p.curTokenIs(token.TRUE)</code> call, which is not really interesting. Other than that it's straightforward, maybe even boring. Or in other words: the structure of our parser serves us well! That actually is one of the beauties of Pratt's approach: it's so easy to extend.</p>
<p>And boom! The tests are green:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.006s</code></pre></div>
<p>But what's interesting is that we can now extend several tests to incorporate the newly implemented boolean literals. The first candidate is <code>TestOperatorPrecedenceParsing</code>, with its string comparison mechanism:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestOperatorPrecedenceParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">&quot;true&quot;</span>,
            <span class="st">&quot;true&quot;</span>,
        },
        {
            <span class="st">&quot;false&quot;</span>,
            <span class="st">&quot;false&quot;</span>,
        },
        {
            <span class="st">&quot;3 &gt; 5 == false&quot;</span>,
            <span class="st">&quot;((3 &gt; 5) == false)&quot;</span>,
        },
        {
            <span class="st">&quot;3 &lt; 5 == true&quot;</span>,
            <span class="st">&quot;((3 &lt; 5) == true)&quot;</span>,
        },
<span class="co">// [...]</span>
}</code></pre></div>
<p>We can test for boolean literals in even more tests by extending our <code>testLiteralExpression</code> helper and providing a new <code>testBooleanLiteral</code> function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser_test.go</span>

<span class="kw">func</span> testLiteralExpression(
    t *testing.T,
    exp ast.Expression,
    expected <span class="kw">interface</span>{},
) <span class="dt">bool</span> {
    <span class="kw">switch</span> v := expected.(<span class="kw">type</span>) {
<span class="co">// [...]</span>
    <span class="kw">case</span> <span class="dt">bool</span>:
        <span class="kw">return</span> testBooleanLiteral(t, exp, v)
    }
<span class="co">// [...]</span>
}

<span class="kw">func</span> testBooleanLiteral(t *testing.T, exp ast.Expression, value <span class="dt">bool</span>) <span class="dt">bool</span> {
    bo, ok := exp.(*ast.Boolean)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;exp not *ast.Boolean. got=%T&quot;</span>, exp)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> bo.Value != value {
        t.Errorf(<span class="st">&quot;bo.Value not %t. got=%t&quot;</span>, value, bo.Value)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">if</span> bo.TokenLiteral() != fmt.Sprintf(<span class="st">&quot;%t&quot;</span>, value) {
        t.Errorf(<span class="st">&quot;bo.TokenLiteral not %t. got=%s&quot;</span>,
            value, bo.TokenLiteral())
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>Nothing surprising here, just another case in a switch statement and a new helper function. But with this in place, it's easy to extend <code>TestParsingInfixExpressions</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingInfixExpressions(t *testing.T) {
    infixTests := []<span class="kw">struct</span> {
        input      <span class="dt">string</span>
        leftValue  <span class="kw">interface</span>{}
        operator   <span class="dt">string</span>
        rightValue <span class="kw">interface</span>{}
    }{
<span class="co">// [...]</span>
        {<span class="st">&quot;true == true&quot;</span>, <span class="ot">true</span>, <span class="st">&quot;==&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;true != false&quot;</span>, <span class="ot">true</span>, <span class="st">&quot;!=&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;false == false&quot;</span>, <span class="ot">false</span>, <span class="st">&quot;==&quot;</span>, <span class="ot">false</span>},
    }
<span class="co">// [...]</span>

    <span class="kw">if</span> !testLiteralExpression(t, exp.Left, tt.leftValue) {
      <span class="kw">return</span>
    }

    <span class="kw">if</span> !testLiteralExpression(t, exp.Right, tt.rightValue) {
      <span class="kw">return</span>
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>And also <code>TestParsingPrefixExpressions</code> is easy to extend by just adding new entries to the test table:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingPrefixExpressions(t *testing.T) {
    prefixTests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        operator <span class="dt">string</span>
        value    <span class="kw">interface</span>{}
    }{
<span class="co">// [...]</span>
        {<span class="st">&quot;!true;&quot;</span>, <span class="st">&quot;!&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;!false;&quot;</span>, <span class="st">&quot;!&quot;</span>, <span class="ot">false</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>It's time to pat ourselves on the back! We implemented the parsing of booleans and extended our tests in a way that gives us more test coverage now and better tools later on. Good job!</p>
<h3 id="grouped-expressions">Grouped Expressions</h3>
<p>What we're about to see next is sometimes called &quot;the greatest trick Vaughan Pratt ever pulled&quot;. Actually, no, I just lied there, nobody says that. But they should! I'm talking about parsing grouped expressions, of course. In Monkey we can group expression with parantheses to influence their precedence and thus the order in which they are evaluated in their context. We've seen the canonical example for this before:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">(<span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span>) <span class="op">*</span> <span class="dv">2</span><span class="op">;</span></code></pre></div>
<p>The parentheses group the <code>5 + 5</code> expression in order to give them a higher precedence and position them deeper in the AST, resulting in the correct evaluation order for this mathematical expression.</p>
<p>Now you might be thinking <em>&quot;Oh come on, not with the precedence stuff again! My head still hurts! This guy... &quot;</em> and you contemplate whether to skip to the end of this chapter. Don't! You have to see this!</p>
<p>We're not going to write a unit test for grouped expressions, since they are not represented by a separate AST node type. Yes, that's right. We do not need to change our AST in order to parse grouped expressions correctly! What we're going to do instead is to extend our <code>TestOperatorPrecedenceParsing</code> test function to make sure that parentheses actually group expressions and have an effect on the resulting AST.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestOperatorPrecedenceParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">&quot;1 + (2 + 3) + 4&quot;</span>,
            <span class="st">&quot;((1 + (2 + 3)) + 4)&quot;</span>,
        },
        {
            <span class="st">&quot;(5 + 5) * 2&quot;</span>,
            <span class="st">&quot;((5 + 5) * 2)&quot;</span>,
        },
        {
            <span class="st">&quot;2 / (5 + 5)&quot;</span>,
            <span class="st">&quot;(2 / (5 + 5))&quot;</span>,
        },
        {
            <span class="st">&quot;-(5 + 5)&quot;</span>,
            <span class="st">&quot;(-(5 + 5))&quot;</span>,
        },
        {
            <span class="st">&quot;!(true == true)&quot;</span>,
            <span class="st">&quot;(!(true == true))&quot;</span>,
        },
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>They fail, as expected:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">$ <span class="kw">go</span> test ./parser
--- FAIL: TestOperatorPrecedenceParsing (<span class="dv">0</span>.00s)
  parser_test.<span class="kw">go</span>:<span class="dv">531</span>: parser has <span class="dv">3</span> errors
  parser_test.<span class="kw">go</span>:<span class="dv">533</span>: parser <span class="dt">error</span>: <span class="st">&quot;no prefix parse function for ( found&quot;</span>
  parser_test.<span class="kw">go</span>:<span class="dv">533</span>: parser <span class="dt">error</span>: <span class="st">&quot;no prefix parse function for ) found&quot;</span>
  parser_test.<span class="kw">go</span>:<span class="dv">533</span>: parser <span class="dt">error</span>: <span class="st">&quot;no prefix parse function for + found&quot;</span>
FAIL
FAIL    monkey/parser   <span class="dv">0</span>.007s</code></pre></div>
<p>Here comes the mind-blowing part. In order to get these tests to pass, all we need to do is add this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.LPAREN, p.parseGroupedExpression)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseGroupedExpression() ast.Expression {
    p.nextToken()

    exp := p.parseExpression(LOWEST)

    <span class="kw">if</span> !p.expectPeek(token.RPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> exp
}</code></pre></div>
<p>And that's it! Yes, it really is. The tests pass and the parentheses work as expected by boosting the precedence of the enclosed expressions. The concept of associating token types with functions really shines here. That's all there is to it. There is nothing happening here that we haven't seen before.</p>
<p>I told you, didn't I? It's a great trick. With that said, let's keep some of the magic and move on.</p>
<h3 id="if-expressions">If Expressions</h3>
<p>In Monkey we can use <code>if</code> and <code>else</code> just like we did hundreds of times in other programming languages:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (x <span class="op">&gt;</span> y) <span class="op">{</span>
  <span class="cf">return</span> x<span class="op">;</span>
<span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
  <span class="cf">return</span> y<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>The <code>else</code> is optional and can be left out:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (x <span class="op">&gt;</span> y) <span class="op">{</span>
  <span class="cf">return</span> x<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>That's all very familiar. In Monkey though, if-else-conditionals are expressions. That means that they produce a value and in the case of if expressions that's the last evaluated line. We don't need the return statements here:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> foobar <span class="op">=</span> <span class="cf">if</span> (x <span class="op">&gt;</span> y) <span class="op">{</span> x <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span> y <span class="op">};</span></code></pre></div>
<p>Explaining the structure of if-else-conditionals is probably not necessary, but just so we're clear on the naming, here it is:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">if (&lt;condition&gt;) &lt;consequence&gt; else &lt;alternative&gt;</code></pre></div>
<p>The braces are part of <code>consequence</code> and <code>alternative</code>, because both are block statements. Block statements are a series of statements (just like programs in Monkey) enclosed by an opening <code>{</code> and a closing <code>}</code>.</p>
<p>So far our recipe for success has been to &quot;define AST nodes, write tests, make tests pass by writing parsing code, celebrate, pat ourselves on the back, congratulate each other, tell everyone&quot; and, well, there's no reason to change it now.</p>
<p>Here is the definition of the <code>ast.IfExpression</code> AST node:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> IfExpression <span class="kw">struct</span> {
    Token       token.Token <span class="co">// The &#39;if&#39; token</span>
    Condition   Expression
    Consequence *BlockStatement
    Alternative *BlockStatement
}

<span class="kw">func</span> (ie *IfExpression) expressionNode()      {}
<span class="kw">func</span> (ie *IfExpression) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> ie.Token.Literal }
<span class="kw">func</span> (ie *IfExpression) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(<span class="st">&quot;if&quot;</span>)
    out.WriteString(ie.Condition.String())
    out.WriteString(<span class="st">&quot; &quot;</span>)
    out.WriteString(ie.Consequence.String())

    <span class="kw">if</span> ie.Alternative != <span class="ot">nil</span> {
        out.WriteString(<span class="st">&quot;else &quot;</span>)
        out.WriteString(ie.Alternative.String())
    }

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>No surprises here. <code>ast.IfExpression</code> fulfills the <code>ast.Expression</code> interface and has three fields that can represent an if-else-conditional. <code>Condition</code> holds the condition, which can be any expression, and <code>Consequence</code> and <code>Alternative</code> point to the consequence and alternative of the conditional respectively. But they reference a new type, <code>ast.BlockStatement</code>. As we saw before, the consequence/alternative of an if-else-condition is just a series of statements. That's exactly what <code>ast.BlockStatement</code> represents:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> BlockStatement <span class="kw">struct</span> {
    Token      token.Token <span class="co">// the { token</span>
    Statements []Statement
}

<span class="kw">func</span> (bs *BlockStatement) statementNode()       {}
<span class="kw">func</span> (bs *BlockStatement) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> bs.Token.Literal }
<span class="kw">func</span> (bs *BlockStatement) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    <span class="kw">for</span> _, s := <span class="kw">range</span> bs.Statements {
        out.WriteString(s.String())
    }

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>The next step in our recipe for success is to add a test. By now, we know the drill and the test looks familiar:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestIfExpression(t *testing.T) {
    input := <span class="st">`if (x &lt; y) { x }`</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;program.Body does not contain %d statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="dv">1</span>, <span class="bu">len</span>(program.Statements))
    }

    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
            program.Statements[<span class="dv">0</span>])
    }

    exp, ok := stmt.Expression.(*ast.IfExpression)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;stmt.Expression is not ast.IfExpression. got=%T&quot;</span>,
            stmt.Expression)
    }

    <span class="kw">if</span> !testInfixExpression(t, exp.Condition, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;&lt;&quot;</span>, <span class="st">&quot;y&quot;</span>) {
        <span class="kw">return</span>
    }

    <span class="kw">if</span> <span class="bu">len</span>(exp.Consequence.Statements) != <span class="dv">1</span> {
        t.Errorf(<span class="st">&quot;consequence is not 1 statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="bu">len</span>(exp.Consequence.Statements))
    }

    consequence, ok := exp.Consequence.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
            exp.Consequence.Statements[<span class="dv">0</span>])
    }

    <span class="kw">if</span> !testIdentifier(t, consequence.Expression, <span class="st">&quot;x&quot;</span>) {
        <span class="kw">return</span>
    }

    <span class="kw">if</span> exp.Alternative != <span class="ot">nil</span> {
        t.Errorf(<span class="st">&quot;exp.Alternative.Statements was not nil. got=%+v&quot;</span>, exp.Alternative)
    }
}</code></pre></div>
<p>I also added a <code>TestIfElseExpression</code> test function that uses the following test input:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (x <span class="op">&lt;</span> y) <span class="op">{</span> x <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span> y <span class="op">}</span></code></pre></div>
<p>In <code>TestIfElseExpression</code> there are additional assertions on the <code>Alternative</code> field of <code>*ast.IfExpression</code>. Both tests make assertions about the structure of the resulting <code>*ast.IfExpression</code> node and use the helper functions <code>testInfixExpression</code> and <code>testIdentifier</code> to keep the focus on the conditional itself but also make sure that the rest of our parser is correctly integrated.</p>
<p>Both tests fail with a lot of error messages. But we are familiar with all of them by now:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestIfExpression (0.00s)
  parser_test.go:659: parser has 3 errors
  parser_test.go:661: parser error: &quot;no prefix parse function for IF found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for } found&quot;
--- FAIL: TestIfElseExpression (0.00s)
  parser_test.go:659: parser has 6 errors
  parser_test.go:661: parser error: &quot;no prefix parse function for IF found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for } found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for ELSE found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for } found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>We're going to start with the first failing test: <code>TestIfExpression</code>. Clearly, we need to register a <code>prefixParseFn</code> for <code>token.IF</code> tokens.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.IF, p.parseIfExpression)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseIfExpression() ast.Expression {
    expression := &amp;ast.IfExpression{Token: p.curToken}

    <span class="kw">if</span> !p.expectPeek(token.LPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    p.nextToken()
    expression.Condition = p.parseExpression(LOWEST)

    <span class="kw">if</span> !p.expectPeek(token.RPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">if</span> !p.expectPeek(token.LBRACE) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    expression.Consequence = p.parseBlockStatement()

    <span class="kw">return</span> expression
}</code></pre></div>
<p>In no other parsing function did we use <code>expectPeek</code> so extensively. There just wasn't a need. Here it makes sense. <code>expectPeek</code> adds an error to the parser if <code>p.peekToken</code> is not of the expected type, but if it is, then it advances the tokens by calling the <code>nextToken</code> method. That's exactly what we need here. We need there to be a <code>(</code> right after the <code>if</code> and if it's there we need to jump over it. The same goes for the <code>)</code> after the expression and the <code>{</code> that marks the beginning of a block statement.</p>
<p>This method also follows our parsing function protocol: the tokens get advanced just enough so that <code>parseBlockStatement</code> sits on the <code>{</code> with <code>p.curToken</code> being of type <code>token.LBRACE</code>. Here is <code>parseBlockStatement</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseBlockStatement() *ast.BlockStatement {
    block := &amp;ast.BlockStatement{Token: p.curToken}
    block.Statements = []ast.Statement{}

    p.nextToken()

    <span class="kw">for</span> !p.curTokenIs(token.RBRACE) &amp;&amp; !p.curTokenIs(token.EOF) {
        stmt := p.parseStatement()
        <span class="kw">if</span> stmt != <span class="ot">nil</span> {
            block.Statements = <span class="bu">append</span>(block.Statements, stmt)
        }
        p.nextToken()
    }

    <span class="kw">return</span> block
}</code></pre></div>
<p><code>parseBlockStatement</code> calls <code>parseStatement</code> until it encounters either a <code>}</code>, which signifies the end of the block statement, or a <code>token.EOF</code>, which tells us that there's no more tokens left to parse. In that case, we can't successfully parse the block statement and there's no need to keep on calling <code>parseStatement</code> in an endless loop.</p>
<p>This looks really similar to our top-level <code>ParseProgram</code> method, where we also call <code>parseStatement</code> repeatedly until we encounter an &quot;end token&quot;, which in the case of <code>ParseProgram</code> is just the <code>token.EOF</code> token. The duplication of the loop doesn't hurt though, so we leave these two methods be and instead take care of our tests:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestIfElseExpression (0.00s)
  parser_test.go:659: parser has 3 errors
  parser_test.go:661: parser error: &quot;no prefix parse function for ELSE found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:661: parser error: &quot;no prefix parse function for } found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p><code>TestIfExpression</code> passes and <code>TestIfElseExpression</code> does not, exactly as expected. Now, in order to support the <code>else</code> part of an if-else-condition, we need to check if it even exists and if so we need to parse the block statement that comes directly after the <code>else</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseIfExpression() ast.Expression {
<span class="co">// [...]</span>
    expression.Consequence = p.parseBlockStatement()

    <span class="kw">if</span> p.peekTokenIs(token.ELSE) {
        p.nextToken()

        <span class="kw">if</span> !p.expectPeek(token.LBRACE) {
            <span class="kw">return</span> <span class="ot">nil</span>
        }

        expression.Alternative = p.parseBlockStatement()
    }

    <span class="kw">return</span> expression
}</code></pre></div>
<p>That's all there is to it. The whole part of this method is constructed in a way that allows an optional <code>else</code> but doesn't add a parser error if there is none. After we parse the consequence-block-statement we check if the next token is a <code>token.ELSE</code> token. Remember, at the end of <code>parseBlockStatement</code> we're sitting on the <code>}</code>. If we have a <code>token.ELSE</code>, we advance the tokens two times. The first time with a call to <code>nextToken</code>, since we already know that the <code>p.peekToken</code> is the <code>else</code>. Then with a call to <code>expectPeek</code> since now the next token has to be the opening brace of a block statement, otherwise the program is invalid.</p>
<p>Yes, parsing is prone to off-by-one errors. It's easy to forget advancing the tokens or make a wrong call to <code>nextToken</code>. Having a strict protocol that dictates how every parsing function has to advance tokens helps a lot. Luckily we also have a great test suite that lets us know everything works:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>I don't think I have to tell you anymore: good job all around! We did it - again.</p>
<h3 id="function-literals">Function Literals</h3>
<p>You may have noticed that the <code>parseIfExpression</code> method we just added has a lot more meat to it than any of the <code>prefixParseFn</code>s or <code>infixParseFn</code>s we wrote before. The main reason is that we had to work with many different token and expression types and even optional parts. What we're going to do next is similar in its difficulty and variety of involved token types. We're going to parse function literals.</p>
<p>In Monkey a function literal is how we define functions: which parameters they have and what the function does. Function literals look like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span>
  <span class="cf">return</span> x <span class="op">+</span> y<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>It starts with the keyword <code>fn</code>, followed by a list of parameters, followed by a block statement, which is the function's body, that gets executed when the function is called. The abstract structure of a function literal is this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">fn &lt;parameters&gt; &lt;block statement&gt;</code></pre></div>
<p>We already know what block statements are and how to parse them. The parameters are new though, but not much more difficult to parse. They are just a list of identifiers that are comma-separated and surrounded by parentheses:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">(&lt;parameter one&gt;, &lt;parameter two&gt;, &lt;parameter three&gt;, ...)</code></pre></div>
<p>This list can also be empty:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">fn</span>() <span class="op">{</span>
  <span class="cf">return</span> foobar <span class="op">+</span> barfoo<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>That's the structure of function literals. But what type of AST node are they? Expressions, of course! We can use function literals in every place where any other expression is valid. For example, here is a function literal as the expression in a let statement:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> myFunction <span class="op">=</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> <span class="cf">return</span> x <span class="op">+</span> y<span class="op">;</span> <span class="op">}</span></code></pre></div>
<p>And here is a function literal as the expression in a return statement inside another function literal:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">fn</span>() <span class="op">{</span>
  <span class="cf">return</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> <span class="cf">return</span> x <span class="op">&gt;</span> y<span class="op">;</span> <span class="op">};</span>
<span class="op">}</span></code></pre></div>
<p>Using a function literal as an argument when calling another function is also possible:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">myFunc</span>(x<span class="op">,</span> y<span class="op">,</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> <span class="cf">return</span> x <span class="op">&gt;</span> y<span class="op">;</span> <span class="op">}</span>)<span class="op">;</span></code></pre></div>
<p>That does sound complicated, but it's not. One of the great things about our parser is that once we define function literals as expressions and provide a function to correctly parse them the rest works. Sounds amazing? I agree.</p>
<p>We just saw that the two main parts of a function literal are the list of parameters and the block statement that is the function's body. That's all we need to keep in mind when defining the AST node:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> FunctionLiteral <span class="kw">struct</span> {
    Token      token.Token <span class="co">// The &#39;fn&#39; token</span>
    Parameters []*Identifier
    Body       *BlockStatement
}

<span class="kw">func</span> (fl *FunctionLiteral) expressionNode()      {}
<span class="kw">func</span> (fl *FunctionLiteral) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> fl.Token.Literal }
<span class="kw">func</span> (fl *FunctionLiteral) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    params := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, p := <span class="kw">range</span> fl.Parameters {
        params = <span class="bu">append</span>(params, p.String())
    }

    out.WriteString(fl.TokenLiteral())
    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(strings.Join(params, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;) &quot;</span>)
    out.WriteString(fl.Body.String())

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>The <code>Parameters</code> field is a slice of <code>*ast.Identifiers</code>, because that's all there is to it, and <code>Body</code> is an <code>*ast.BlockStatement</code>, which we saw and used before.</p>
<p>Here is the test, in which we can use our helper functions <code>testLiteralExpression</code> and <code>testInfixExpression</code> again:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestFunctionLiteralParsing(t *testing.T) {
    input := <span class="st">`fn(x, y) { x + y; }`</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;program.Body does not contain %d statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="dv">1</span>, <span class="bu">len</span>(program.Statements))
    }

    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;program.Statements[0] is not ast.ExpressionStatement. got=%T&quot;</span>,
            program.Statements[<span class="dv">0</span>])
    }

    function, ok := stmt.Expression.(*ast.FunctionLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;stmt.Expression is not ast.FunctionLiteral. got=%T&quot;</span>,
            stmt.Expression)
    }

    <span class="kw">if</span> <span class="bu">len</span>(function.Parameters) != <span class="dv">2</span> {
        t.Fatalf(<span class="st">&quot;function literal parameters wrong. want 2, got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="bu">len</span>(function.Parameters))
    }

    testLiteralExpression(t, function.Parameters[<span class="dv">0</span>], <span class="st">&quot;x&quot;</span>)
    testLiteralExpression(t, function.Parameters[<span class="dv">1</span>], <span class="st">&quot;y&quot;</span>)

    <span class="kw">if</span> <span class="bu">len</span>(function.Body.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;function.Body.Statements has not 1 statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="bu">len</span>(function.Body.Statements))
    }

    bodyStmt, ok := function.Body.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;function body stmt is not ast.ExpressionStatement. got=%T&quot;</span>,
            function.Body.Statements[<span class="dv">0</span>])
    }

    testInfixExpression(t, bodyStmt.Expression, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;+&quot;</span>, <span class="st">&quot;y&quot;</span>)
}</code></pre></div>
<p>So, the test has three main parts: check that the <code>*ast.FunctionLiteral</code> is there, check that the parameter list is correct and make sure that the function body contains the correct statements. The last part is not strictly necessary, since we already tested parsing block statements before in our tests for <code>IfExpression</code>s. But I'm okay with duplicating some test assertions here that possibly alarm us when hooking up the parsing of block statements failed.</p>
<p>With only <code>ast.FunctionLiteral</code> defined and nothing changed in the parser, the tests fail:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestFunctionLiteralParsing (0.00s)
  parser_test.go:755: parser has 6 errors
  parser_test.go:757: parser error: &quot;no prefix parse function for FUNCTION found&quot;
  parser_test.go:757: parser error: &quot;expected next token to be ), got , instead&quot;
  parser_test.go:757: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:757: parser error: &quot;no prefix parse function for ) found&quot;
  parser_test.go:757: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:757: parser error: &quot;no prefix parse function for } found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>It's clear that we need to register a new <code>prefixParseFn</code> for <code>token.FUNCTION</code> tokens.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.FUNCTION, p.parseFunctionLiteral)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseFunctionLiteral() ast.Expression {
    lit := &amp;ast.FunctionLiteral{Token: p.curToken}

    <span class="kw">if</span> !p.expectPeek(token.LPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    lit.Parameters = p.parseFunctionParameters()

    <span class="kw">if</span> !p.expectPeek(token.LBRACE) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    lit.Body = p.parseBlockStatement()

    <span class="kw">return</span> lit
}</code></pre></div>
<p>The <code>parseFunctionParameters</code> method we use here to parse the literal's parameters looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseFunctionParameters() []*ast.Identifier {
    identifiers := []*ast.Identifier{}

    <span class="kw">if</span> p.peekTokenIs(token.RPAREN) {
        p.nextToken()
        <span class="kw">return</span> identifiers
    }

    p.nextToken()

    ident := &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
    identifiers = <span class="bu">append</span>(identifiers, ident)

    <span class="kw">for</span> p.peekTokenIs(token.COMMA) {
        p.nextToken()
        p.nextToken()
        ident := &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
        identifiers = <span class="bu">append</span>(identifiers, ident)
    }

    <span class="kw">if</span> !p.expectPeek(token.RPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> identifiers
}</code></pre></div>
<p>There's the heart of the matter. <code>parseFunctionParameters</code> constructs the slice of parameters by repeatedly building identifiers from the comma separated list. It also makes an early exit if the list is empty and it carefully handles lists of varying sizes.</p>
<p>For a method like this it really pays off to have another set of tests that check the edge cases: an empty parameter list, a list with one parameter and a list with multiple parameters.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestFunctionParameterParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input          <span class="dt">string</span>
        expectedParams []<span class="dt">string</span>
    }{
        {input: <span class="st">&quot;fn() {};&quot;</span>, expectedParams: []<span class="dt">string</span>{}},
        {input: <span class="st">&quot;fn(x) {};&quot;</span>, expectedParams: []<span class="dt">string</span>{<span class="st">&quot;x&quot;</span>}},
        {input: <span class="st">&quot;fn(x, y, z) {};&quot;</span>, expectedParams: []<span class="dt">string</span>{<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;z&quot;</span>}},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        l := lexer.New(tt.input)
        p := New(l)
        program := p.ParseProgram()
        checkParserErrors(t, p)

        stmt := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
        function := stmt.Expression.(*ast.FunctionLiteral)

        <span class="kw">if</span> <span class="bu">len</span>(function.Parameters) != <span class="bu">len</span>(tt.expectedParams) {
            t.Errorf(<span class="st">&quot;length parameters wrong. want %d, got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
                <span class="bu">len</span>(tt.expectedParams), <span class="bu">len</span>(function.Parameters))
        }

        <span class="kw">for</span> i, ident := <span class="kw">range</span> tt.expectedParams {
            testLiteralExpression(t, function.Parameters[i], ident)
        }
    }
}</code></pre></div>
<p>Both of these test functions now pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>Function literals are in the bag! Sweet! There is only one last thing to do now before we can leave the parser and start talking about the evaluation of our AST.</p>
<h3 id="call-expressions">Call Expressions</h3>
<p>Now that we know how to parse function literals the next step is to parse the calling of a function: call expressions. Here is their structure:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&lt;expression&gt;(&lt;comma separated expressions&gt;)</code></pre></div>
<p>What? Yup, that's it, but granted, a few examples are needed. Here is the normal call expression we all know:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>)</code></pre></div>
<p>Now think about this: the <code>add</code> is an identifier. And identifiers are expressions. The arguments <code>2</code> and <code>3</code> are expressions too - integer literals. But they don't have to be, the arguments are just a list of expressions:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(<span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span> <span class="op">*</span> <span class="dv">3</span> <span class="op">*</span> <span class="dv">3</span>)</code></pre></div>
<p>That's valid, too. The first argument is the infix expression <code>2 + 2</code> and the second one is <code>3 * 3 * 3</code>. So far, so good. Now, let's look at the function that's being called here. In this case the function is bound to the identifier <code>add</code>. The identifier <code>add</code> returns this function when it's evaluated. That means, we could go straight to the source, skip the identifier and replace <code>add</code> with a function literal:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> x <span class="op">+</span> y<span class="op">;</span> <span class="op">}</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>)</code></pre></div>
<p>Yes, that's valid. We can also use function literals as arguments:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">callsFunction</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> x <span class="op">+</span> y<span class="op">;</span> <span class="op">}</span>)<span class="op">;</span></code></pre></div>
<p>Let's look at the structure again:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&lt;expression&gt;(&lt;comma separated expressions&gt;)</code></pre></div>
<p>Call expressions consist of an expression that results in a function when evaluated and a list of expressions that are the arguments to this function call. As an AST node they look like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> CallExpression <span class="kw">struct</span> {
    Token     token.Token <span class="co">// The &#39;(&#39; token</span>
    Function  Expression  <span class="co">// Identifier or FunctionLiteral</span>
    Arguments []Expression
}

<span class="kw">func</span> (ce *CallExpression) expressionNode()      {}
<span class="kw">func</span> (ce *CallExpression) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> ce.Token.Literal }
<span class="kw">func</span> (ce *CallExpression) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    args := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, a := <span class="kw">range</span> ce.Arguments {
        args = <span class="bu">append</span>(args, a.String())
    }

    out.WriteString(ce.Function.String())
    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(strings.Join(args, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;)&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>The test case for call expressions is just like the rest of our test suite and makes assertions about the <code>*ast.CallExpression</code> structure:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestCallExpressionParsing(t *testing.T) {
    input := <span class="st">&quot;add(1, 2 * 3, 4 + 5);&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;program.Statements does not contain %d statements. got=%d</span><span class="ch">\n</span><span class="st">&quot;</span>,
            <span class="dv">1</span>, <span class="bu">len</span>(program.Statements))
    }

    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;stmt is not ast.ExpressionStatement. got=%T&quot;</span>,
            program.Statements[<span class="dv">0</span>])
    }

    exp, ok := stmt.Expression.(*ast.CallExpression)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;stmt.Expression is not ast.CallExpression. got=%T&quot;</span>,
            stmt.Expression)
    }

    <span class="kw">if</span> !testIdentifier(t, exp.Function, <span class="st">&quot;add&quot;</span>) {
        <span class="kw">return</span>
    }

    <span class="kw">if</span> <span class="bu">len</span>(exp.Arguments) != <span class="dv">3</span> {
        t.Fatalf(<span class="st">&quot;wrong length of arguments. got=%d&quot;</span>, <span class="bu">len</span>(exp.Arguments))
    }

    testLiteralExpression(t, exp.Arguments[<span class="dv">0</span>], <span class="dv">1</span>)
    testInfixExpression(t, exp.Arguments[<span class="dv">1</span>], <span class="dv">2</span>, <span class="st">&quot;*&quot;</span>, <span class="dv">3</span>)
    testInfixExpression(t, exp.Arguments[<span class="dv">2</span>], <span class="dv">4</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">5</span>)
}</code></pre></div>
<p>As with function literals and parameter parsing it's also a good idea to add a separate test for the argument parsing. Just to make sure that every corner case works and is covered by a test. I added a <code>TestCallExpressionParameterParsing</code> test function that does exactly this. You can see it in the code for this chapter.</p>
<p>So far, so familiar. But now comes the twist. If we run the tests we get this error message:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestCallExpressionParsing (0.00s)
  parser_test.go:853: parser has 4 errors
  parser_test.go:855: parser error: &quot;expected next token to be ), got , instead&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for ) found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>Huh, that doesn't make a lot of sense. Why is there no error message telling us to register a <code>prefixParseFn</code> for call expressions? Because there <em>are no new token types</em> in call expressions. So what do we do instead of registering a <code>prefixParseFn</code>? Take at look at this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span>)<span class="op">;</span></code></pre></div>
<p>The <code>add</code> is an identifier that's parsed by a <code>prefixParseFn</code>. And after the identifier comes a <code>token.LPAREN</code>, right between the identifier and the list of arguments, just in the middle, in infix position... Yes, we need to register an <code>infixParseFn</code> for <code>token.LPAREN</code>. This way we parse the expression that is the function (either an identifier, or a function literal), then check for an <code>infixParseFn</code> associated with <code>token.LPAREN</code> and call it with the already parsed expression as argument. And in this <code>infixParseFn</code> we can then parse the argument list. Perfect!</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerInfix(token.LPAREN, p.parseCallExpression)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseCallExpression(function ast.Expression) ast.Expression {
    exp := &amp;ast.CallExpression{Token: p.curToken, Function: function}
    exp.Arguments = p.parseCallArguments()
    <span class="kw">return</span> exp
}

<span class="kw">func</span> (p *Parser) parseCallArguments() []ast.Expression {
    args := []ast.Expression{}

    <span class="kw">if</span> p.peekTokenIs(token.RPAREN) {
        p.nextToken()
        <span class="kw">return</span> args
    }

    p.nextToken()
    args = <span class="bu">append</span>(args, p.parseExpression(LOWEST))

    <span class="kw">for</span> p.peekTokenIs(token.COMMA) {
        p.nextToken()
        p.nextToken()
        args = <span class="bu">append</span>(args, p.parseExpression(LOWEST))
    }

    <span class="kw">if</span> !p.expectPeek(token.RPAREN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> args
}</code></pre></div>
<p><code>parseCallExpression</code> receives the already parsed <code>function</code> as argument and uses it to construct an <code>*ast.CallExpression</code> node. To parse the argument list we call <code>parseCallArguments</code>, which looks strikingly similar to <code>parseFunctionParameters</code>, except that it's more generic and returns a slice of <code>ast.Expression</code> and not <code>*ast.Identifier</code>.</p>
<p>There is nothing here we haven't seen before. All we did was register a new <code>infixParseFn</code>. The tests still fail though:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestCallExpressionParsing (0.00s)
  parser_test.go:853: parser has 4 errors
  parser_test.go:855: parser error: &quot;expected next token to be ), got , instead&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:855: parser error: &quot;no prefix parse function for ) found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>The reason that it still doesn't work is that the <code>(</code> in <code>add(1, 2)</code> acts like an infix operator now, but we haven't assigned a precedence to it. It doesn't have the right &quot;stickiness&quot; yet, so <code>parseExpression</code> doesn't return what we want. But call expressions have the highest precedence of all, so it's important that we fix our precedences table:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">var</span> precedences = <span class="kw">map</span>[token.TokenType]<span class="dt">int</span>{
<span class="co">// [...]</span>
    token.LPAREN:   CALL,
}</code></pre></div>
<p>To make sure that call expressions really have the highest precedence we can just extend our <code>TestOperatorPrecedenceParsing</code> test function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestOperatorPrecedenceParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">&quot;a + add(b * c) + d&quot;</span>,
            <span class="st">&quot;((a + add((b * c))) + d)&quot;</span>,
        },
        {
            <span class="st">&quot;add(a, b, 1, 2 * 3, 4 + 5, add(6, 7 * 8))&quot;</span>,
            <span class="st">&quot;add(a, b, 1, (2 * 3), (4 + 5), add(6, (7 * 8)))&quot;</span>,
        },
        {
            <span class="st">&quot;add(a + b + c * d / f + g)&quot;</span>,
            <span class="st">&quot;add((((a + b) + ((c * d) / f)) + g))&quot;</span>,
        },
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>If we now run the tests again, we can see that all of them pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.008s</code></pre></div>
<p>Yes, all of them: the unit test, the test for argument parsing and the precedence tests - wow! They all pass! And if that wasn't enough, here's some more good news: we are done. Yes, the parser is finished. Granted, we'll come back to it later, at the end of the book, to extend it once more. But for now: that's it! The AST is fully defined and the parser works - it's time to move on to the topic of evaluation.</p>
<p>Before we do that though, let's remove the TODOs we left in the code and extend our REPL to integrate the parser.</p>
<h3 id="removing-todos">Removing TODOs</h3>
<p>When we wrote the code that parses let and return statements we took a shortcut by skipping over the expressions:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseLetStatement() *ast.LetStatement {
    stmt := &amp;ast.LetStatement{Token: p.curToken}

    <span class="kw">if</span> !p.expectPeek(token.IDENT) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    stmt.Name = &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

    <span class="kw">if</span> !p.expectPeek(token.ASSIGN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="co">// TODO: We&#39;re skipping the expressions until we</span>
    <span class="co">// encounter a semicolon</span>
    <span class="kw">for</span> !p.curTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}</code></pre></div>
<p>The same <code>TODO</code> sits in <code>parseReturnStatement</code>. It's time to get rid of them. No shortcuts. First of all, we need to extend our existing tests to make sure that the expressions, that are parsed as part of a let or return statement, are actually there. We do this by using our helper functions (that don't distract from the focus of the test) and different expression types, so we know that <code>parseExpression</code> is correctly integrated.</p>
<p>Here is what the <code>TestLetStatement</code> function looks like:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestLetStatements(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input              <span class="dt">string</span>
        expectedIdentifier <span class="dt">string</span>
        expectedValue      <span class="kw">interface</span>{}
    }{
        {<span class="st">&quot;let x = 5;&quot;</span>, <span class="st">&quot;x&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;let y = true;&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;let foobar = y;&quot;</span>, <span class="st">&quot;foobar&quot;</span>, <span class="st">&quot;y&quot;</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        l := lexer.New(tt.input)
        p := New(l)
        program := p.ParseProgram()
        checkParserErrors(t, p)

        <span class="kw">if</span> <span class="bu">len</span>(program.Statements) != <span class="dv">1</span> {
            t.Fatalf(<span class="st">&quot;program.Statements does not contain 1 statements. got=%d&quot;</span>,
                <span class="bu">len</span>(program.Statements))
        }

        stmt := program.Statements[<span class="dv">0</span>]
        <span class="kw">if</span> !testLetStatement(t, stmt, tt.expectedIdentifier) {
            <span class="kw">return</span>
        }

        val := stmt.(*ast.LetStatement).Value
        <span class="kw">if</span> !testLiteralExpression(t, val, tt.expectedValue) {
            <span class="kw">return</span>
        }
    }
}</code></pre></div>
<p>The same needs to be done for <code>TestReturnStatements</code>. And the fix is trivial, since we did such great work before. We merely need to hook up <code>parseExpression</code> in <code>parseReturnStatement</code> and <code>parseLetStatement</code>. And we also need to take care of optional semicolons, which we already know how to do from <code>parseExpressionStatement</code>. The updated, fully-working versions of <code>parseReturnStatement</code> and <code>parseLetStatement</code> look like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseReturnStatement() *ast.ReturnStatement {
    stmt := &amp;ast.ReturnStatement{Token: p.curToken}

    p.nextToken()

    stmt.ReturnValue = p.parseExpression(LOWEST)

    <span class="kw">if</span> p.peekTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}

<span class="kw">func</span> (p *Parser) parseLetStatement() *ast.LetStatement {
    stmt := &amp;ast.LetStatement{Token: p.curToken}

    <span class="kw">if</span> !p.expectPeek(token.IDENT) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    stmt.Name = &amp;ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}

    <span class="kw">if</span> !p.expectPeek(token.ASSIGN) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    p.nextToken()

    stmt.Value = p.parseExpression(LOWEST)

    <span class="kw">if</span> p.peekTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    <span class="kw">return</span> stmt
}</code></pre></div>
<p>Ah! All TODOs removed from the code. Let's take this parser for a test drive.</p>
<h2 id="read-parse-print-loop">2.9 - Read-Parse-Print-Loop</h2>
<p>Up until now our REPL was more of a RLPL, a read-lex-print-loop. We don't know how to evaluate code yet, so replacing the &quot;lex&quot; with &quot;evaluate&quot; is still out of the question. But what we most certainly know by now is parsing. It's time to replace the &quot;lex&quot; with &quot;parse&quot; and build a RPPL.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// repl/repl.go</span>

<span class="kw">func</span> Start(in io.Reader, out io.Writer) {
    scanner := bufio.NewScanner(in)

    <span class="kw">for</span> {
        fmt.Printf(PROMPT)
        scanned := scanner.Scan()
        <span class="kw">if</span> !scanned {
            <span class="kw">return</span>
        }

        line := scanner.Text()
        l := lexer.New(line)
        p := parser.New(l)

        program := p.ParseProgram()
        <span class="kw">if</span> <span class="bu">len</span>(p.Errors()) != <span class="dv">0</span> {
            printParserErrors(out, p.Errors())
            <span class="kw">continue</span>
        }

        io.WriteString(out, program.String())
        io.WriteString(out, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
    }
}

<span class="kw">func</span> printParserErrors(out io.Writer, errors []<span class="dt">string</span>) {
    <span class="kw">for</span> _, msg := <span class="kw">range</span> errors {
        io.WriteString(out, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>+msg+<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
    }
}</code></pre></div>
<p>Here we extend our loop to parse the line we just entered in the REPL. The output of the parser, an <code>*ast.Program</code>, is then printed by calling its <code>String</code> method, which recursively calls the <code>String</code> method of all statements belonging to that program. Now we can take the parser for a spin - interactively on the command line:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let x = 1 * 2 * 3 * 4 * 5
let x = ((((1 * 2) * 3) * 4) * 5);
&gt;&gt; x * y / 2 + 3 * 8 - 123
((((x * y) / 2) + (3 * 8)) - 123)
&gt;&gt; true == false
(true == false)
&gt;&gt;</code></pre></div>
<p>Sweet! Now instead of calling <code>String</code> we could use any string-based representation of the AST to output here. We could add a <code>PrettyPrint</code> method that prints the type of the AST node and intends its child nodes correctly, or we could use ASCII color codes, or we could print an ASCII graph, or... The point is: the sky is the limit.</p>
<p>But our RPPL still has a huge drawback. Here is what happens when the parser runs into an error:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let x 12 * 3;
        expected next token to be =, got INT instead
&gt;&gt;</code></pre></div>
<p>That's not a very nice error message. I mean, it does the job, yes, but it's not very nice, is it? The Monkey programming language deserves better. Here is a more user-friendly <code>printParseError</code> function that enhances the user-experience:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// repl/repl.go</span>

<span class="kw">const</span> MONKEY_FACE = <span class="st">`            __,__</span>
<span class="st">   .--.  .-&quot;     &quot;-.  .--.</span>
<span class="st">  / .. \/  .-. .-.  \/ .. \</span>
<span class="st"> | |  &#39;|  /   Y   \  |&#39;  | |</span>
<span class="st"> | \   \  \ 0 | 0 /  /   / |</span>
<span class="st">  \ &#39;- ,\.-&quot;&quot;&quot;&quot;&quot;&quot;&quot;-./, -&#39; /</span>
<span class="st">   &#39;&#39;-&#39; /_   ^ ^   _\ &#39;-&#39;&#39;</span>
<span class="st">       |  \._   _./  |</span>
<span class="st">       \   \ &#39;~&#39; /   /</span>
<span class="st">        &#39;._ &#39;-=-&#39; _.&#39;</span>
<span class="st">           &#39;-----&#39;</span>
<span class="st">`</span>

<span class="kw">func</span> printParserErrors(out io.Writer, errors []<span class="dt">string</span>) {
    io.WriteString(out, MONKEY_FACE)
    io.WriteString(out, <span class="st">&quot;Woops! We ran into some monkey business here!</span><span class="ch">\n</span><span class="st">&quot;</span>)
    io.WriteString(out, <span class="st">&quot; parser errors:</span><span class="ch">\n</span><span class="st">&quot;</span>)
    <span class="kw">for</span> _, msg := <span class="kw">range</span> errors {
        io.WriteString(out, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>+msg+<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
    }
}</code></pre></div>
<p>That's better! If we now run into any parser errors, we get to see a monkey, which, really, is more than anyone could ask for:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let x 12 * 3
            __,__
   .--.  .-&quot;     &quot;-.  .--.
  / .. \/  .-. .-.  \/ .. \
 | |  &#39;|  /   Y   \  |&#39;  | |
 | \   \  \ 0 | 0 /  /   / |
  \ &#39;- ,\.-&quot;&quot;&quot;&quot;&quot;&quot;&quot;-./, -&#39; /
   &#39;&#39;-&#39; /_   ^ ^   _\ &#39;-&#39;&#39;
       |  \._   _./  |
       \   \ &#39;~&#39; /   /
        &#39;._ &#39;-=-&#39; _.&#39;
           &#39;-----&#39;
Woops! We ran into some monkey business here!
 parser errors:
        expected next token to be =, got INT instead
&gt;&gt;</code></pre></div>
<p>On second thought... Anyway, it's time to start evaluating our AST.</p>
<h1 id="evaluation">Evaluation</h1>
<h2 id="giving-meaning-to-symbols">3.1 - Giving Meaning to Symbols</h2>
<p>We are finally here. Evaluation. The E in REPL and the last thing an interpreter has to do when processing source code. This is where code becomes meaningful. Without evaluation an expression like <code>1 + 2</code> is just a series of characters, tokens, or a tree structure that represents this expression. It doesn't mean anything. Evaluated, of course, <code>1 + 2</code> becomes <code>3</code>. <code>5 &gt; 1</code> becomes <code>true</code>, <code>5 &lt; 1</code> becomes <code>false</code> and <code>puts(&quot;Hello World!&quot;)</code> becomes the friendly message we all know.</p>
<p>The evaluation process of an interpreter defines how the programming language being interpreted works.</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> num <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="cf">if</span> (num) <span class="op">{</span>
  <span class="cf">return</span> a<span class="op">;</span>
<span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
  <span class="cf">return</span> b<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>Whether this returns <code>a</code> or <code>b</code> depends on the decision of the interpreter's evaluation process whether the integer <code>5</code> is truthy or not. In some languages it's truthy, in others we'd need to use an expression that produces a boolean like <code>5 != 0</code>.</p>
<p>Consider this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> one <span class="op">=</span> <span class="at">fn</span>() <span class="op">{</span>
  <span class="at">printLine</span>(<span class="st">&quot;one&quot;</span>)<span class="op">;</span>
  <span class="cf">return</span> <span class="dv">1</span><span class="op">;</span>
<span class="op">};</span>

<span class="kw">let</span> two <span class="op">=</span> <span class="at">fn</span>() <span class="op">{</span>
  <span class="at">printLine</span>(<span class="st">&quot;two&quot;</span>)<span class="op">;</span>
  <span class="cf">return</span> <span class="dv">2</span><span class="op">;</span>
<span class="op">};</span>

<span class="at">add</span>(<span class="at">one</span>()<span class="op">,</span> <span class="at">two</span>())<span class="op">;</span></code></pre></div>
<p>Does this first output <code>one</code> and then <code>two</code> or the other way around? It depends on the specification of the language and ultimately on the implementation of its interpreter and in which order it evaluates the arguments in a call expression.</p>
<p>In this chapter there will be many more small choices like these, where we get to decide how Monkey is going to work and how our interpreter evaluates Monkey source code.</p>
<p>Maybe you're skeptical, after I told you that writing a parser was fun, but trust me: this is the best part. This is where the Monkey programming language comes to life, where source code quickens and starts to breathe.</p>
<h2 id="strategies-of-evaluation">3.2 - Strategies of Evaluation</h2>
<p>Evaluation is also where interpreter implementations (regardless of which language they're interpreting) diverge the most. There are a lot of different strategies to choose from when evaluating source code. I've already hinted at this in the introduction of this book, where we took a brief look at different interpreter architectures. Now that we're here, AST in hand, the question of what to do with it and how to evaluate this shiny tree of ours is more relevant than ever, so looking at different options again is worthwhile.</p>
<p>Before we start, though, it's also worth noting again that the line between interpreters and compilers is a blurry one. The notion of an interpreter as something that doesn't leave executable artifacts behind (in contrast to a compiler, which does just that) gets fuzzy real fast when looking at the implementations of real-world and highly-optimized programming languages.</p>
<p>With that said, the most obvious and classical choice of what to do with the AST is to just interpret it. Traverse the AST, visit each node and do what the node signifies: print a string, add two numbers, execute a function's body - all on the fly. Interpreters working this way are called &quot;tree-walking interpreters&quot; and are the archetype of interpreters. Sometimes their evaluation step is preceded by small optimizations that rewrite the AST (e.g. remove unused variable bindings) or convert it into another intermediate representation (IR) that's more suitable for recursive and repeated evaluation.</p>
<p>Other interpreters also traverse the AST, but instead of interpreting the AST itself they first convert it to bytecode. Bytecode is another IR of the AST and a really dense one at that. The exact format and of which opcodes (the instructions that make up the bytecode) it's composed of varies and depends on the guest and host programming languages. In general though, the opcodes are pretty similar to the mnemonics of most assembly languages; it's a safe bet to say that most bytecode definitions contain opcodes for <code>push</code> and <code>pop</code> to do stack operations. But bytecode is not native machine code, nor is it assembly language. It can't and won't be executed by the operating system and the CPU of the machine the interpreter is running on. Instead it's interpreted by a virtual machine, that's part of the interpreter. Just like VMWare and VirtualBox emulate real machines and CPUs, these virtual machines emulate a machine that understands this particular bytecode format. This approach can yield great performance benefits.</p>
<p>A variation of this strategy doesn't involve an AST at all. Instead of building an AST the parser emits bytecode directly. Now, are we still talking about interpreters or compilers? Isn't emitting bytecode that gets then interpreted (or should we say &quot;executed&quot;?) a form of compilation? I told you: the line becomes blurry. And to make it even more fuzzy, consider this: some implementations of programming languages parse the source code, build an AST and convert this AST to bytecode. But instead of executing the operations specified by the bytecode directly in a virtual machine, the virtual machine then compiles the bytecode to native machine code, right before its executed - just in time. That's called a JIT (for &quot;just in time&quot;) interpreter/compiler.</p>
<p>Others skip the compilation to bytecode. They recursively traverse the AST but before executing a particular branch of it the node is compiled to native machine code. And then executed. Again, &quot;just in time&quot;.</p>
<p>A slight variation of this is a mixed mode of interpretation where the interpreter recursively evaluates the AST and only after evaluating a particular branch of the AST multiple times does it compile the branch to machine code.</p>
<p>Amazing, isn't it? So many different ways to go about this task of evaluation, so many twists and variations.</p>
<p>The choice of which strategy to choose largely depends on performance and portability needs, the programming language that's being interpreted and how far you're willing to go. A tree-walking interpreter that recursively evaluates an AST is probably the slowest of all approaches, but easy to build, extend, reason about and as portable as the language it's implemented in.</p>
<p>An interpreter that compiles to bytecode and uses a virtual machine to evaluate said bytecode is going to be a lot faster. But more complicated and harder to build, too. Throw JIT compilation to machine code into the mix and now you also need to support multiple machine architectures if you want the interpreter to work on both ARM and x86 CPUs.</p>
<p>All of these approaches can be found in real-world programming languages. And most of the time the chosen approach changed with the lifetime of the language. Ruby is a great example here. Up to and including version 1.8 the interpreter was a tree-walking interpreter, executing the AST while traversing it. But with version 1.9 came the switch to a virtual machine architecture. Now the Ruby interpreter parses source code, builds an AST and then compiles this AST into bytecode, which gets then executed in a virtual machine. The increase in performance was huge.</p>
<p>The WebKit JavaScript engine JavaScriptCore and its interpreter named &quot;Squirrelfish&quot; also used AST walking and direct execution as its approach. Then in 2008 came the switch to a virtual machine and bytecode interpretation. Nowadays the engine has four (!) different stages of JIT compilation, which kick in at different times in the lifetime of the interpreted program -- depending on which part of the program needs the best performance.</p>
<p>Another example is Lua. The main implementation of the Lua programming language started out as an interpreter that compiles to bytecode and executes the bytecode in a register-based virtual machine. 12 years after its first release another implementation of the language was born: LuaJIT. The clear goal of Mike Pall, the creator of LuaJIT, was to create the fastest Lua implementation possible. And he did. By JIT compiling a dense bytecode format to highly-optimized machine code for different architectures the LuaJIT implementation beats the original Lua in every benchmark. And not just by a tiny bit, no; it's sometimes 50 times faster.</p>
<p>So, a lot of interpreters started out small with room for improvement. That's exactly what we're going to do. There are a lot of ways to build a faster interpreter, but not necessarily one that's easier to understand. We are here to learn, to understand and to be able to build upon our work.</p>
<h2 id="a-tree-walking-interpreter">3.3 - A Tree-Walking Interpreter</h2>
<p>What we're going to build is a tree-walking interpreter. We're going to take the AST our parser builds for us and interpret it &quot;on the fly&quot;, without any preprocessing or compilation step.</p>
<p>Our interpreter will be a lot like a classic Lisp interpreter. The design we're going to use is heavily inspired by the interpreter presented in &quot;The Structure and Interpretation of Computer Programs&quot; (SICP), especially its usage of environments. That doesn't mean that we're copying one particular interpreter, no, we're rather using a blueprint that you can see in lot of other interpreters too, if you squint hard enough. There are really good reasons for the prevalence of this particular design: it's the easiest way to get started, it's easy to understand and to extend later on.</p>
<p>We only need two things really: a tree-walking evaluator and a way to represent Monkey values in our host language Go. Evaluator sounds mighty and grand, but it will be just one function called &quot;eval&quot;. Its job is to evaluate the AST. Here is a pseudocode version that illustrates what &quot;evaluating on the fly&quot; and &quot;tree-walking&quot; mean in the context of interpretation:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">function</span> <span class="at">eval</span>(astNode) <span class="op">{</span>
  <span class="cf">if</span> (astNode is integerliteral) <span class="op">{</span>
    <span class="cf">return</span> <span class="va">astNode</span>.<span class="at">integerValue</span>

  <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (astNode is booleanLiteral) <span class="op">{</span>
    <span class="cf">return</span> <span class="va">astNode</span>.<span class="at">booleanValue</span>

  <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> (astNode is infixExpression) <span class="op">{</span>

    leftEvaluated <span class="op">=</span> <span class="at">eval</span>(<span class="va">astNode</span>.<span class="at">Left</span>)
    rightEvaluated <span class="op">=</span> <span class="at">eval</span>(<span class="va">astNode</span>.<span class="at">Right</span>)

    <span class="cf">if</span> <span class="va">astNode</span>.<span class="at">Operator</span> <span class="op">==</span> <span class="st">&quot;+&quot;</span> <span class="op">{</span>
      <span class="cf">return</span> leftEvaluated <span class="op">+</span> rightEvaluated
    <span class="op">}</span> <span class="cf">else</span> <span class="cf">if</span> <span class="va">ast</span>.<span class="at">Operator</span> <span class="op">==</span> <span class="st">&quot;-&quot;</span> <span class="op">{</span>
      <span class="cf">return</span> leftEvaluated <span class="op">-</span> rightEvaluated
    <span class="op">}</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>As you can see, <code>eval</code> is recursive. When <code>astNode is infixExpression</code> is true, <code>eval</code> calls itself again two times to evaluate the left and the right operands of the infix expression. This in turn may lead to the evaluation of another infix expression or an integer literal or a boolean literal or an identifier... We've already seen recursion at work when building and testing the AST. The same concepts apply here, except that we're evaluating the tree and not building it.</p>
<p>Looking at this snippet of pseudocode you can probably imagine how easy it is to extend this function. That comes to our advantage. We're going to build up our own <code>Eval</code> function piece by piece and add new branches and capabilities as we go along and extend our interpreter.</p>
<p>But the most interesting lines of this snippet are the return statements. What do they return? Here are two lines that bind the return value of a call to <code>eval</code> to names:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">leftEvaluated = eval(astNode.Left)
rightEvaluated = eval(astNode.Right)</code></pre></div>
<p>What does <code>eval</code> return here? Of which type are the return values? The answer to these questions is the same as the one for &quot;what kind of internal object system will our interpreter have?&quot;</p>
<h2 id="representing-objects">3.4 - Representing Objects</h2>
<p><em>Wait, what? You never said Monkey was object oriented!</em> Yes, I never did and it's not. <em>Why do we need &quot;a object system&quot; then?</em> Call it a &quot;value system&quot; or &quot;object representation&quot; then. The point is, we need to define what our &quot;eval&quot; function returns. We need a system that can represent the values our AST represents or values that we generate when evaluating the AST in memory.</p>
<p>Let's say we're evaluating the following Monkey code:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> a <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="co">// [...]</span>
a <span class="op">+</span> a<span class="op">;</span></code></pre></div>
<p>As you can see, we're binding the integer literal <code>5</code> to the name <code>a</code>. Then things happen. It doesn't matter what. What matters is that when we come across the <code>a + a</code> expression later we need to access the value <code>a</code> is bound to. In order to evaluate <code>a + a</code> we need to get to the <code>5</code>. In the AST it's represented as an <code>*ast.IntegerLiteral</code>, but how are we going to keep track of and represent the <code>5</code> while we're evaluating the rest of the AST?</p>
<p>There are a lot of different choices when building an internal representation of values in an interpreted language. And there is a lot of wisdom about this topic spread throughout the codebases of the world's interpreters and compilers. Each interpreter has its own way to represent values, always slightly differing from the solution that came before, adjusted for the requirements of the interpreted language.</p>
<p>Some use native types (integers, booleans, etc.) of the host language to represent values in the interpreted language, not wrapped in anything. In other languages values/objects are represented only as pointers, whereas in some programming languages native types and pointers are mixed.</p>
<p>Why the variety? For one, the host languages differ. How you represent a string of your interpreted language depends on how a string can be represented in the language the interpreter is implemented in. An interpreter written in Ruby can't represent values the same way an interpreter written in C can.</p>
<p>And not only do the host languages differ, but the languages being interpreted do too. Some interpreted languages may only need representations of primitive data types, like integers, characters or bytes. But in others you'll have lists, dictionaries, functions or compound data types. These differences lead to highly different requirements in regards to value representation.</p>
<p>Besides the host language and the interpreted language, the biggest influence on the design and implementation of value representations are the resulting execution speed and the memory consumption while evaluating programs. If you want to build a fast interpreter you can't get away with a slow and bloated object system. And if you're going to write your own garbage collector, you need to think about how it'll keep track of the values in the system. But, on the other hand, if you don't care about performance, then it does make sense to keep things simple and easy to understand until further requirements arise.</p>
<p>The point is this: there are a lot of different ways to represent values of the interpreted languages in the host language. The best (and maybe the only) way to learn about these different representations is to actually read through the source code of some popular interpreters. I heartily recommended the <a href="https://github.com/munificent/wren">Wren source code</a>, which includes two types of value representation, enabled/disabled by using a compiler flag.</p>
<p>Besides the representation of values inside the host language there is also the matter of how to expose these values and their representation to the user of the interpreted language. What does the &quot;public API&quot; of these values look like?</p>
<p>Java, for example, offers both &quot;primitive data types&quot; (int, byte, short, long, float, double, boolean, char) and reference types to the user. The primitive data types do not have a huge representation inside the Java implementation, they closely map to their native counterparts. Reference types on the other hand are references to compound data structures defined in the host language.</p>
<p>In Ruby the user doesn't have access to &quot;primitive data types&quot;, nothing like a native value type exists because everything is an object and thus wrapped inside an internal representation. Internally Ruby doesn't distinguish between a byte and an instance of the class <code>Pizza</code>: both are the same value type, wrapping different values.</p>
<p>There are a myriad ways to expose data to users of programming languages. Which one to choose depends on the language design and also, again, on performance requirements. If you don't care about performance everything goes. But if you do, you need to make some smart decisions to achieve your goals.</p>
<h3 id="foundation-of-our-object-system">Foundation of our Object System</h3>
<p>Carefree as we still are about the performance of our Monkey interpreter, we choose the easy way: we're going to represent every value we encounter when evaluating Monkey source code as an <code>Object</code>, an interface of our design. Every value will be wrapped inside a struct, which fulfills this <code>Object</code> interface.</p>
<p>In a new <code>object</code> package we define the <code>Object</code> interface and the <code>ObjectType</code> type:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">package</span> object

<span class="kw">type</span> ObjectType <span class="dt">string</span>

<span class="kw">type</span> Object <span class="kw">interface</span> {
    Type() ObjectType
    Inspect() <span class="dt">string</span>
}</code></pre></div>
<p>That's pretty simple and looks a lot like what we did in the <code>token</code> package with the <code>Token</code> and <code>TokenType</code> types. Except that instead of being a struct like <code>Token</code> the <code>Object</code> type is an interface. The reason is that every value needs a different internal representation and it's easier to define two different struct types than trying to fit booleans and integers into the same struct field.</p>
<p>At the moment we only have three data types in our Monkey interpreter: null, booleans and integers. Let's start with implementing the integer representation and build up our object system.</p>
<h3 id="integers">Integers</h3>
<p>The <code>object.Integer</code> type is as small as you'd expect it to be:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">import</span> (
    <span class="st">&quot;fmt&quot;</span>
)

<span class="kw">type</span> Integer <span class="kw">struct</span> {
    Value <span class="dt">int64</span>
}

<span class="kw">func</span> (i *Integer) Inspect() <span class="dt">string</span> { <span class="kw">return</span> fmt.Sprintf(<span class="st">&quot;%d&quot;</span>, i.Value) }</code></pre></div>
<p>Whenever we encounter an integer literal in the source code we first turn it into an <code>ast.IntegerLiteral</code> and then, when evaluating that AST node, we turn it into an <code>object.Integer</code>, saving the value inside our struct and passing around a reference to this struct.</p>
<p>In order for <code>object.Integer</code> to fulfill the <code>object.Object</code> interface, it still needs a <code>Type()</code> method that returns its <code>ObjectType</code>. Just like we did with <code>token.TokenType</code> we define constants for each <code>ObjectType</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">import</span> <span class="st">&quot;fmt&quot;</span>

<span class="kw">type</span> ObjectType <span class="dt">string</span>

<span class="kw">const</span> (
    INTEGER_OBJ = <span class="st">&quot;INTEGER&quot;</span>
)</code></pre></div>
<p>As I said, this is pretty much what we did in the <code>token</code> package. And with that in place we can add the <code>Type()</code> method to <code>*object.Integer</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">func</span> (i *Integer) Type() ObjectType { <span class="kw">return</span> INTEGER_OBJ }</code></pre></div>
<p>And we're done with <code>Integer</code>! Onto another data type: booleans.</p>
<h3 id="booleans">Booleans</h3>
<p>If you were expecting big things of this section, I'm sorry to disappoint. <code>object.Boolean</code> is as tiny as it gets:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    BOOLEAN_OBJ = <span class="st">&quot;BOOLEAN&quot;</span>
)

<span class="kw">type</span> Boolean <span class="kw">struct</span> {
    Value <span class="dt">bool</span>
}

<span class="kw">func</span> (b *Boolean) Type() ObjectType { <span class="kw">return</span> BOOLEAN_OBJ }
<span class="kw">func</span> (b *Boolean) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> fmt.Sprintf(<span class="st">&quot;%t&quot;</span>, b.Value) }</code></pre></div>
<p>Just a struct that wraps a single value, a <code>bool</code>.</p>
<p>We're close to finishing the foundation of our object system. The last thing we need to do now, before we can start with our <code>Eval</code> function, is to represent a value that isn't there.</p>
<h3 id="null">Null</h3>
<p>Tony Hoare introduced null references to the ALGOL W language in 1965 and called this his <a href="https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare">&quot;billion-dollar mistake&quot;</a>. Since their introduction countless systems have crashed because of references to &quot;null&quot;, a value that represents the absence of a value. Null (or &quot;nil&quot; as in some languages) doesn't have the best reputation, to say the least.</p>
<p>I debated with myself whether Monkey should have null. On one hand, yes, the language would be safer to use if it doesn't allow null or null references. But on the other, we're not trying to reinvent the wheel, but to learn something. And I found that having null at my disposal lead me to think twice whenever there was a chance to use it. Kinda like having something explosive in your car leads you to driving slower and more carefully. It really made me appreciate the choices that go into the design of a programming language. That's something I consider worthwhile. So let's implement the <code>Null</code> type and keep a close look and steady hand when using it later on.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    NULL_OBJ  = <span class="st">&quot;NULL&quot;</span>
)

<span class="kw">type</span> Null <span class="kw">struct</span>{}

<span class="kw">func</span> (n *Null) Type() ObjectType { <span class="kw">return</span> NULL_OBJ }
<span class="kw">func</span> (n *Null) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> <span class="st">&quot;null&quot;</span> }</code></pre></div>
<p><code>object.Null</code> is a struct just like <code>object.Boolean</code> and <code>object.Integer</code>, except that it doesn't wrap any value. It represents the absence of any value.</p>
<p>With <code>object.Null</code> added, our object system is now capable of representing boolean, integer and null values. That's more than enough to get started with <code>Eval</code>.</p>
<h2 id="evaluating-expressions">3.5 - Evaluating Expressions</h2>
<p>Alright, here we go. Let's start writing <code>Eval</code>! We have our AST and we have a new object system, that allows us to keep track of values we encounter when executing Monkey source code. It's time to finally evaluate the AST.</p>
<p>Here is what the signature of <code>Eval</code> will look like in its first version:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">func</span> Eval(node ast.Node) object.Object</code></pre></div>
<p><code>Eval</code> will take an <code>ast.Node</code> as input and return an <code>object.Object</code>. Remember that every node we defined in the <code>ast</code> package fulfills the <code>ast.Node</code> interface and can thus be passed to <code>Eval</code>. This allows us to use <code>Eval</code> recursively and call itself while evaluating a part of the AST. Each AST node needs a different form of evaluation and <code>Eval</code> is the place where we decide what these forms look like. As an example, let's say that we pass an <code>*ast.Program</code> node to <code>Eval</code>. What <code>Eval</code> should do then is to evaluate each of <code>*ast.Program.Statements</code> by calling itself with a single statement. The return value of the outer call to <code>Eval</code> is the return value of the last call.</p>
<p>We're going to start by implementing self-evaluating expressions. That's what we call literals in the land of <code>Eval</code>. Specifically, boolean and integer literals. They are the constructs in Monkey that are easiest to evaluate, because they evaluate to themselves. If I type <code>5</code> into my REPL then <code>5</code> is also what should come out. And if I type in <code>true</code> then <code>true</code> is what I want.</p>
<p>Sounds easy enough? It is! So, let's turn &quot;type in 5, get back 5&quot; into reality.</p>
<h3 id="integer-literals-1">Integer Literals</h3>
<p>Before writing any code though, what does this mean exactly? We're given a single expression statement as input, which only contains an integer literal, and want to evaluate it so that the integer itself is returned.</p>
<p>Translated into the language of our system, it means that, given an <code>*ast.IntegerLiteral</code>, our <code>Eval</code> function should return an <code>*object.Integer</code> whose <code>Value</code> field contains the same integer as <code>*ast.IntegerLiteral.Value</code>.</p>
<p>We can easily write a test for this in our new <code>evaluator</code> package:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">package</span> evaluator

<span class="kw">import</span> (
    <span class="st">&quot;monkey/lexer&quot;</span>
    <span class="st">&quot;monkey/object&quot;</span>
    <span class="st">&quot;monkey/parser&quot;</span>
    <span class="st">&quot;testing&quot;</span>
)

<span class="kw">func</span> TestEvalIntegerExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;5&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;10&quot;</span>, <span class="dv">10</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        testIntegerObject(t, evaluated, tt.expected)
    }
}

<span class="kw">func</span> testEval(input <span class="dt">string</span>) object.Object {
    l := lexer.New(input)
    p := parser.New(l)
    program := p.ParseProgram()

    <span class="kw">return</span> Eval(program)
}

<span class="kw">func</span> testIntegerObject(t *testing.T, obj object.Object, expected <span class="dt">int64</span>) <span class="dt">bool</span> {
    result, ok := obj.(*object.Integer)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;object is not Integer. got=%T (%+v)&quot;</span>, obj, obj)
        <span class="kw">return</span> <span class="ot">false</span>
    }
    <span class="kw">if</span> result.Value != expected {
        t.Errorf(<span class="st">&quot;object has wrong value. got=%d, want=%d&quot;</span>,
            result.Value, expected)
        <span class="kw">return</span> <span class="ot">false</span>
    }

    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>That's a lot of code for such a small test, isn't it? As with our parser tests, we're building up our testing infrastructure here. The <code>TestEvalIntegerExpression</code> test will need to grow and its current structure makes this really easy. The <code>testEval</code> and <code>testIntegerObject</code> will also find a lot of use.</p>
<p>The heart of the test is the call to <code>Eval</code> inside <code>testEval</code>. We take our input, pass it to the lexer, pass the lexer to the parser and get back an AST. And then, this is new, we pass the AST to <code>Eval</code>. The return value of <code>Eval</code> is what we make assertions about. In this case, we want the return value to be an <code>*object.Integer</code> with the correct <code>.Value</code>. In other words: we want <code>5</code> to evaluate to <code>5</code>.</p>
<p>Of course, the test fails because we haven't defined <code>Eval</code> yet. But we already know that <code>Eval</code> should take an <code>ast.Node</code> as argument and return an <code>object.Object</code>. And whenever it encounters an <code>*ast.IntegerLiteral</code> it should return an <code>*object.Integer</code> with the correct <code>.Value</code>. Turning this into code and defining our new <code>Eval</code> with this behaviour in the <code>evaluator</code> package, we get this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">package</span> evaluator

<span class="kw">import</span> (
    <span class="st">&quot;monkey/ast&quot;</span>
    <span class="st">&quot;monkey/object&quot;</span>
)

<span class="kw">func</span> Eval(node ast.Node) object.Object {
    <span class="kw">switch</span> node := node.(<span class="kw">type</span>) {
    <span class="kw">case</span> *ast.IntegerLiteral:
        <span class="kw">return</span> &amp;object.Integer{Value: node.Value}
    }

    <span class="kw">return</span> <span class="ot">nil</span>
}</code></pre></div>
<p>Nothing surprising here, it does just what we said it should. Except that it doesn't work. The test still fails because <code>Eval</code> returns <code>nil</code> instead of an <code>*object.Integer</code>.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestEvalIntegerExpression (0.00s)
  evaluator_test.go:36: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:36: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
FAIL
FAIL    monkey/evaluator        0.006s</code></pre></div>
<p>The reason for this failure is that we never encounter an <code>*ast.IntegerLiteral</code> in <code>Eval</code>. We don't traverse the AST. We should always start at the top of the tree, receiving an <code>*ast.Program</code>, and then traverse every node in it. And that's exactly what we're not doing here. We're just waiting for an <code>*ast.IntegerLiteral</code>. The fix is to actually traverse the tree and evaluate every statement of the <code>*ast.Program</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
    <span class="kw">switch</span> node := node.(<span class="kw">type</span>) {

    <span class="co">// Statements</span>
    <span class="kw">case</span> *ast.Program:
        <span class="kw">return</span> evalStatements(node.Statements)

    <span class="kw">case</span> *ast.ExpressionStatement:
        <span class="kw">return</span> Eval(node.Expression)

    <span class="co">// Expressions</span>
    <span class="kw">case</span> *ast.IntegerLiteral:
        <span class="kw">return</span> &amp;object.Integer{Value: node.Value}
    }

    <span class="kw">return</span> <span class="ot">nil</span>
}

<span class="kw">func</span> evalStatements(stmts []ast.Statement) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> stmts {
        result = Eval(statement)
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>With this changes we evaluate every statement in a Monkey program. And if the statement is an <code>*ast.ExpressionStatement</code> we evaluate its expression. That mirrors the AST structure we get from a one line input like <code>5</code>: a program that consists of one statement, an expression statement (not a return statement and not a let statement) with an integer literal as its expression.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.006s</code></pre></div>
<p>Alright, the tests pass! We can evaluate integer literals! <em>Hey everyone, if we type in a number, a number comes out and it only took us a couple thousand lines of code and tests to do so!</em> Okay, granted, it doesn't look like much. But it's a start. We're beginning to see how evaluation works and how we can extend our evaluator. The structure of <code>Eval</code> won't change, we'll only add to and extend it.</p>
<p>Next up on our list of self-evaluating expressions are boolean literals. But before we do that, we should celebrate our first evaluation success and treat ourselves. Let's put the E in REPL!</p>
<h3 id="completing-the-repl">Completing the REPL</h3>
<p>Up until now the E in in our REPL was missing and we had nothing but a RPPL - a Read-Parse-Print-Loop. Now that we have <code>Eval</code> we can build a real Read-Evaluate-Print-Loop!</p>
<p>Using the evaluator in the <code>repl</code> package is as easy as you'd think it is:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// repl/repl.go</span>

<span class="kw">import</span> (
<span class="co">// [...]</span>
    <span class="st">&quot;monkey/evaluator&quot;</span>
)

<span class="co">// [...]</span>

<span class="kw">func</span> Start(in io.Reader, out io.Writer) {
    scanner := bufio.NewScanner(in)

    <span class="kw">for</span> {
        fmt.Printf(PROMPT)
        scanned := scanner.Scan()
        <span class="kw">if</span> !scanned {
            <span class="kw">return</span>
        }

        line := scanner.Text()
        l := lexer.New(line)
        p := parser.New(l)

        program := p.ParseProgram()
        <span class="kw">if</span> <span class="bu">len</span>(p.Errors()) != <span class="dv">0</span> {
            printParserErrors(out, p.Errors())
            <span class="kw">continue</span>
        }

        evaluated := evaluator.Eval(program)
        <span class="kw">if</span> evaluated != <span class="ot">nil</span> {
            io.WriteString(out, evaluated.Inspect())
            io.WriteString(out, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
        }
    }
}</code></pre></div>
<p>Instead of printing <code>program</code> (the AST returned by the parser) we pass <code>program</code> to <code>Eval</code>. If <code>Eval</code> returns a non-nil value, an <code>object.Object</code>, we print the output of its <code>Inspect()</code> method. In the case of an <code>*object.Integer</code> that would be the string representation of the integer it's wrapping.</p>
<p>And with that we now have a working REPL:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; 5
5
&gt;&gt; 10
10
&gt;&gt; 999
999
&gt;&gt;</code></pre></div>
<p>Feels good, doesn't it? Lexing, parsing, evaluating - it's all in there. We've come a long way.</p>
<h3 id="boolean-literals-1">Boolean Literals</h3>
<p>Boolean literals, just like their integer counterparts, evaluate to themselves. <code>true</code> evaluates to <code>true</code> and <code>false</code> to <code>false</code>. Implementing this in <code>Eval</code> is as easy as adding support for integer literals was. The tests are equally boring:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestEvalBooleanExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">bool</span>
    }{
        {<span class="st">&quot;true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;false&quot;</span>, <span class="ot">false</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        testBooleanObject(t, evaluated, tt.expected)
    }
}

<span class="kw">func</span> testBooleanObject(t *testing.T, obj object.Object, expected <span class="dt">bool</span>) <span class="dt">bool</span> {
    result, ok := obj.(*object.Boolean)
    <span class="kw">if</span> !ok {
        t.Errorf(<span class="st">&quot;object is not Boolean. got=%T (%+v)&quot;</span>, obj, obj)
        <span class="kw">return</span> <span class="ot">false</span>
    }
    <span class="kw">if</span> result.Value != expected {
        t.Errorf(<span class="st">&quot;object has wrong value. got=%t, want=%t&quot;</span>,
            result.Value, expected)
        <span class="kw">return</span> <span class="ot">false</span>
    }
    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>We'll extend the <code>tests</code> slice as soon as we support more expressions that result in booleans. For now, we only make sure that we get the correct output when we enter <code>true</code> or <code>false</code>. The tests fail:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestEvalBooleanExpression (0.00s)
  evaluator_test.go:42: Eval didn&#39;t return BooleanObject. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:42: Eval didn&#39;t return BooleanObject. got=&lt;nil&gt; (&lt;nil&gt;)
FAIL
FAIL    monkey/evaluator        0.006s</code></pre></div>
<p>Making this green is as easy as copying the <code>case</code> branch from <code>*ast.IntegerLiteral</code> and changing two identifiers:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.Boolean:
        <span class="kw">return</span> &amp;object.Boolean{Value: node.Value}
<span class="co">// [...]</span>
}</code></pre></div>
<p>That's it! Let's give it a spin in the REPL:</p>
<pre><code>$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; true
true
&gt;&gt; false
false
&gt;&gt;</code></pre>
<p>Pretty! But, let me ask you this: the fact that we're creating a new <code>object.Boolean</code> every time we encounter a <code>true</code> or <code>false</code> is absurd, isn't it? There is no difference between two <code>true</code>s. The same goes for <code>false</code>. Why use new instances every time? There are only two possible values, so let's reference them instead of creating new ones.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">var</span> (
    TRUE  = &amp;object.Boolean{Value: <span class="ot">true</span>}
    FALSE = &amp;object.Boolean{Value: <span class="ot">false</span>}
)

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.Boolean:
        <span class="kw">return</span> nativeBoolToBooleanObject(node.Value)
<span class="co">// [...]</span>
}

<span class="kw">func</span> nativeBoolToBooleanObject(input <span class="dt">bool</span>) *object.Boolean {
    <span class="kw">if</span> input {
        <span class="kw">return</span> TRUE
    }
    <span class="kw">return</span> FALSE
}</code></pre></div>
<p>Now there are only two instances of <code>object.Boolean</code> in our package: <code>TRUE</code> and <code>FALSE</code> and we reference them instead of allocating new <code>object.Boolean</code>s. That makes much more sense and is a small performance improvement we get without a lot of work. And while we're at it, let's take care of null, too.</p>
<h3 id="null-1">Null</h3>
<p>Just as there is only one <code>true</code> and one <code>false</code>, there should only be one reference to a null value. There are no variations of null. No kinda-but-not-quite-null, no half-null and no basically-the-same-as-the-other-null. Either something is this one null, or it isn't. So let's create one <code>NULL</code> we can reference throughout our evaluator instead of creating new <code>object.Null</code>s.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">var</span> (
    NULL  = &amp;object.Null{}
    TRUE  = &amp;object.Boolean{Value: <span class="ot">true</span>}
    FALSE = &amp;object.Boolean{Value: <span class="ot">false</span>}
)</code></pre></div>
<p>And that's all there is to it. Now we have one <code>NULL</code> we can reference.</p>
<p>With integer literals and our trio of <code>NULL</code>, <code>TRUE</code> and <code>FALSE</code> in place we're ready to evaluate operator expressions.</p>
<h3 id="prefix-expressions">Prefix Expressions</h3>
<p>The simplest form of operator expressions Monkey supports is the prefix expression, or unary operator expression, where one operand follows the operator. In our parser we treated a lot of language constructs like prefix expressions, because that's the easiest way to parse them. But in this section prefix expressions are just operator expressions with one operator and one operand. Monkey supports two of these prefix operators: <code>!</code> and <code>-</code>.</p>
<p>Evaluating operator expression (especially with a prefix operator and one operand) isn't hard. We'll do it in small steps and build up the desired behaviour bit by bit. But we also need to pay close attention. What we're about to implement has far reaching consequences. Remember: in the evaluation process the input language receives meaning; we're defining the semantics of the Monkey programming language. A small change in the evaluation of operator expressions might cause something unintended in a part of the language that seems entirely unrelated. Tests help us to nail down the desired behaviour and also act as a specification for us.</p>
<p>We're going to start by implementing support for the <code>!</code> operator. The tests show that the operator should &quot;convert&quot; its operand to a boolean value and negate it:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestBangOperator(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">bool</span>
    }{
        {<span class="st">&quot;!true&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;!false&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;!5&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;!!true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;!!false&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;!!5&quot;</span>, <span class="ot">true</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        testBooleanObject(t, evaluated, tt.expected)
    }
}</code></pre></div>
<p>As I said, this is where we decide how the language works. The <code>!true</code> and <code>!false</code> expressions and their expected results seem like common sense, but the <code>!5</code> may be something where other language designers feel an error should be returned. But what we're saying here is that <code>5</code> acts as &quot;truthy&quot;.</p>
<p>The tests don't pass, of course, because <code>Eval</code> returns <code>nil</code> instead of <code>TRUE</code> or <code>FALSE</code>. The first step to evaluating a prefix expression is to evaluate its operand and then use the result of this evaluation with the operator:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.PrefixExpression:
        right := Eval(node.Right)
        <span class="kw">return</span> evalPrefixExpression(node.Operator, right)
<span class="co">// [...]</span>
}</code></pre></div>
<p>After the first call to <code>Eval</code> here, <code>right</code> may be an <code>*object.Integer</code> or an <code>*object.Boolean</code> or maybe even <code>NULL</code>. We then take this <code>right</code> operand and pass it to <code>evalPrefixExpression</code> which checks if the operator is supported:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalPrefixExpression(operator <span class="dt">string</span>, right object.Object) object.Object {
    <span class="kw">switch</span> operator {
    <span class="kw">case</span> <span class="st">&quot;!&quot;</span>:
        <span class="kw">return</span> evalBangOperatorExpression(right)
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>If the operator is not supported we return <code>NULL</code>. Is that the best choice? Maybe, maybe not. For now, it's definitely the easiest choice, since we don't have any error handling implemented yet.</p>
<p>The <code>evalBangOperatorExpression</code> function is where the behaviour of the <code>!</code> is specified:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalBangOperatorExpression(right object.Object) object.Object {
    <span class="kw">switch</span> right {
    <span class="kw">case</span> TRUE:
        <span class="kw">return</span> FALSE
    <span class="kw">case</span> FALSE:
        <span class="kw">return</span> TRUE
    <span class="kw">case</span> NULL:
        <span class="kw">return</span> TRUE
    <span class="kw">default</span>:
        <span class="kw">return</span> FALSE
    }
}</code></pre></div>
<p>And with that the tests pass!</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Let's move on to the <code>-</code> prefix operator. We can extend our <code>TestEvalIntegerExpression</code> test function to incorporate it:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestEvalIntegerExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;5&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;10&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;-5&quot;</span>, -<span class="dv">5</span>},
        {<span class="st">&quot;-10&quot;</span>, -<span class="dv">10</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>I choose to extend this test rather than writing a new test function solely for the <code>-</code> prefix operator for two reasons. First, integers are the only supported operands of the <code>-</code> operator in prefix position. And second, because this test function should grow to encompass all integer arithmetic in order to have one place that shows the desired behaviour in a clear and neat way.</p>
<p>We have to extend the <code>evalPrefixExpression</code> function we wrote earlier in order to make the test cases pass. A new branch in the switch statement is needed:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalPrefixExpression(operator <span class="dt">string</span>, right object.Object) object.Object {
    <span class="kw">switch</span> operator {
    <span class="kw">case</span> <span class="st">&quot;!&quot;</span>:
        <span class="kw">return</span> evalBangOperatorExpression(right)
    <span class="kw">case</span> <span class="st">&quot;-&quot;</span>:
        <span class="kw">return</span> evalMinusPrefixOperatorExpression(right)
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>The <code>evalMinusPrefixOperatorExpression</code> function looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalMinusPrefixOperatorExpression(right object.Object) object.Object {
    <span class="kw">if</span> right.Type() != object.INTEGER_OBJ {
        <span class="kw">return</span> NULL
    }

    value := right.(*object.Integer).Value
    <span class="kw">return</span> &amp;object.Integer{Value: -value}
}</code></pre></div>
<p>The first thing we do here is to check if the operand is an integer. If it isn't, we return <code>NULL</code>. But if it is, we extract the value of the <code>*object.Integer</code>. Then we allocate a new object to wrap a negated version of this value.</p>
<p>That wasn't a lot of code, was it? But still, it did the job:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Excellent! Now we can give our prefix expressions a spin in the REPL before moving on to their infix friends:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; -5
-5
&gt;&gt; !true
false
&gt;&gt; !-5
false
&gt;&gt; !!-5
true
&gt;&gt; !!!!-5
true
&gt;&gt; -true
null</code></pre></div>
<p>Amazing!</p>
<h3 id="infix-expressions">Infix Expressions</h3>
<p>As a refresher, here are the eight infix operators that Monkey supports:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">-</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> / <span class="dv">5</span><span class="op">;</span>

<span class="dv">5</span> <span class="op">&gt;</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">&lt;</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">==</span> <span class="dv">5</span><span class="op">;</span>
<span class="dv">5</span> <span class="op">!=</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>These eight operators can be separated into two groups: one group of operators produces booleans as their result and one group doesn't. We'll start by implementing support for the second group: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>. And first only in combination with integer operands. As soon as that works, we'll add support for booleans on either side of the operator.</p>
<p>The test infrastructure is already in place. We'll just extend our <code>TestEvalIntegerExpression</code> test function with test cases for these new operators:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestEvalIntegerExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;5&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;10&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;-5&quot;</span>, -<span class="dv">5</span>},
        {<span class="st">&quot;-10&quot;</span>, -<span class="dv">10</span>},
        {<span class="st">&quot;5 + 5 + 5 + 5 - 10&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;2 * 2 * 2 * 2 * 2&quot;</span>, <span class="dv">32</span>},
        {<span class="st">&quot;-50 + 100 + -50&quot;</span>, <span class="dv">0</span>},
        {<span class="st">&quot;5 * 2 + 10&quot;</span>, <span class="dv">20</span>},
        {<span class="st">&quot;5 + 2 * 10&quot;</span>, <span class="dv">25</span>},
        {<span class="st">&quot;20 + 2 * -10&quot;</span>, <span class="dv">0</span>},
        {<span class="st">&quot;50 / 2 * 2 + 10&quot;</span>, <span class="dv">60</span>},
        {<span class="st">&quot;2 * (5 + 10)&quot;</span>, <span class="dv">30</span>},
        {<span class="st">&quot;3 * 3 * 3 + 10&quot;</span>, <span class="dv">37</span>},
        {<span class="st">&quot;3 * (3 * 3) + 10&quot;</span>, <span class="dv">37</span>},
        {<span class="st">&quot;(5 + 10 * 2 + 15 / 3) * 2 + -10&quot;</span>, <span class="dv">50</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Yes, there are probably some test cases that can be removed because they duplicate another one and some add nothing new, but to be honest: I was really trigger happy with these tests once I realized that the implementation works and I just couldn't believe it. &quot;It can't be that easy, can it?&quot; Well, yes, it can.</p>
<p>To get these test cases to pass, the first thing we need to do is to extend our switch statement in <code>Eval</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.InfixExpression:
        left := Eval(node.Left)
        right := Eval(node.Right)
        <span class="kw">return</span> evalInfixExpression(node.Operator, left, right)
<span class="co">// [...]</span>
}</code></pre></div>
<p>Just as with <code>*ast.PrefixExpression</code> we evaluate the operands first. And now we have two: the left and the right arm of the AST node. We already know that these may be any other expression - a function call, an integer literal, an operator expression, etc. We don't care. We let <code>Eval</code> take care of it.</p>
<p>After evaluating the operands we take the returned values and the operator and pass them to <code>evalIntegerInfixExpressions</code>, which looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    <span class="kw">switch</span> {
    <span class="kw">case</span> left.Type() == object.INTEGER_OBJ &amp;&amp; right.Type() == object.INTEGER_OBJ:
        <span class="kw">return</span> evalIntegerInfixExpression(operator, left, right)
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>In case the operands aren't both integers we return <code>NULL</code>, just as I promised. Of course, we'll extend this function later on, but in order to get the tests to pass, this is enough. The heart of the matter lies in <code>evalIntegerInfixExpression</code>, where the values wrapped by <code>*object.Integer</code>s are added, subtracted, multiplied and divided:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalIntegerInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    leftVal := left.(*object.Integer).Value
    rightVal := right.(*object.Integer).Value

    <span class="kw">switch</span> operator {
    <span class="kw">case</span> <span class="st">&quot;+&quot;</span>:
        <span class="kw">return</span> &amp;object.Integer{Value: leftVal + rightVal}
    <span class="kw">case</span> <span class="st">&quot;-&quot;</span>:
        <span class="kw">return</span> &amp;object.Integer{Value: leftVal - rightVal}
    <span class="kw">case</span> <span class="st">&quot;*&quot;</span>:
        <span class="kw">return</span> &amp;object.Integer{Value: leftVal * rightVal}
    <span class="kw">case</span> <span class="st">&quot;/&quot;</span>:
        <span class="kw">return</span> &amp;object.Integer{Value: leftVal / rightVal}
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>And now, believe it or not, the tests pass. Yes, really, they do:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Go on, add a few more. Knock yourself out. And then come back here so we can add support for the operators that result in booleans: <code>==</code>, <code>!=</code>, <code>&lt;</code> and <code>&gt;</code>.</p>
<p>We can extend our <code>TestEvalBooleanExpression</code> test function with test cases for these operators, since they all produce a boolean:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestEvalBooleanExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">bool</span>
    }{
        {<span class="st">&quot;true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;false&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 &lt; 2&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;1 &gt; 2&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 &lt; 1&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 &gt; 1&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 == 1&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;1 != 1&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 == 2&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;1 != 2&quot;</span>, <span class="ot">true</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>A few added lines in <code>evalIntegerInfixExpression</code> is all that's needed to get these tests to pass:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalIntegerInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    leftVal := left.(*object.Integer).Value
    rightVal := right.(*object.Integer).Value

    <span class="kw">switch</span> operator {
<span class="co">// [...]</span>
    <span class="kw">case</span> <span class="st">&quot;&lt;&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(leftVal &lt; rightVal)
    <span class="kw">case</span> <span class="st">&quot;&gt;&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(leftVal &gt; rightVal)
    <span class="kw">case</span> <span class="st">&quot;==&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(leftVal == rightVal)
    <span class="kw">case</span> <span class="st">&quot;!=&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(leftVal != rightVal)
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>The <code>nativeBoolToBooleanObject</code> function we already used for boolean literals now finds some reuse when we need to return either <code>TRUE</code> or <code>FALSE</code> based on the comparison between the unwrapped values.</p>
<p>And that's it! Well, at least for integers. We now fully support the eight infix operators when both operands are integers. What's left in this section is adding support for boolean operands.</p>
<p>Monkey only supports boolean operands for the equality operators <code>==</code> and <code>!=</code>. It doesn't support adding, subtracting, dividing and multiplying booleans. Checking whether <code>true</code> is greater than <code>false</code> with <code>&lt;</code> or <code>&gt;</code> is also unsupported. That reduces our task to just adding support for two operators.</p>
<p>The first thing we have to do, as you know, is to add tests. And, as before, we can extend an existing test function. In this case, we'll use <code>TestEvalBooleanExpression</code> and add test cases for the <code>==</code> and <code>!=</code> operators:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestEvalBooleanExpression(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">bool</span>
    }{
<span class="co">// [...]</span>
        {<span class="st">&quot;true == true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;false == false&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;true == false&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;true != false&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;false != true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;(1 &lt; 2) == true&quot;</span>, <span class="ot">true</span>},
        {<span class="st">&quot;(1 &lt; 2) == false&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;(1 &gt; 2) == true&quot;</span>, <span class="ot">false</span>},
        {<span class="st">&quot;(1 &gt; 2) == false&quot;</span>, <span class="ot">true</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Strictly speaking, only the first five cases are necessary to test the new and desired behaviour. But let's throw in the other four too to check the comparison between generated booleans.</p>
<p>So far, so good. Nothing surprising here. Just another set of of failing tests:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestEvalBooleanExpression (0.00s)
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
  evaluator_test.go:121: object is not Boolean. got=*object.Null (&amp;{})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>And here's something neat to make those tests pass:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    <span class="kw">switch</span> {
<span class="co">// [...]</span>
    <span class="kw">case</span> operator == <span class="st">&quot;==&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(left == right)
    <span class="kw">case</span> operator == <span class="st">&quot;!=&quot;</span>:
        <span class="kw">return</span> nativeBoolToBooleanObject(left != right)
    <span class="kw">default</span>:
        <span class="kw">return</span> NULL
    }
}</code></pre></div>
<p>Yes, that's right. We only add four lines to our existing <code>evalInfixExpression</code> and the tests pass. We're using pointer comparison here to check for equality between booleans. That works because we're always using pointers to our objects and in the case of booleans we only ever use two: <code>TRUE</code> and <code>FALSE</code>. So, if something has the same value as <code>TRUE</code> (the memory address that is) then it's true. This also works with <code>NULL</code>.</p>
<p>This doesn't work for integers or other data types we might add later on. In the case of <code>*object.Integer</code> we're always allocating new instances of <code>object.Integer</code> and thus use new pointers. We can't compare these pointers to different instances, otherwise <code>5 == 5</code> would be false, which is not what we want. In this case we want to explicitly compare the values and not the objects that wrap these values.</p>
<p>That's why the check for integer operands has to be higher up in the switch statement and match earlier than these newly added <code>case</code> branches. As long as we're taking care of other operand types before arriving at these pointer comparisons we're fine and it works.</p>
<p>In ten years, when Monkey is a famous programming language and the discussion about research-ignoring dilettantes designing programming languages is still ongoing and we're both rich and famous, someone will ask on StackOverflow why integer comparison in Monkey is slower than boolean comparison. The answer will be written by either you or me and one of us will say that Monkey's object system doesn't allow pointer comparison for integer objects. It has to unwrap the value before a comparison can be made. Thus the comparison between booleans is faster. We'll add a &quot;Source: I wrote it.&quot; to the bottom of our answer and earn an unheard of amount of karma.</p>
<p>But I digress. To get back to topic, let me just say: Wow! We did it! I know, I'm pretty lavish with my praise and can spot a cause for celebration pretty easily, but if there ever was a time to pop the champagne, it's now. Yes, we did it. Just look at what our interpreter can do now:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; 5 * 5 + 10
35
&gt;&gt; 3 + 4 * 5 == 3 * 1 + 4 * 5
true
&gt;&gt; 5 * 10 &gt; 40 + 5
true
&gt;&gt; (10 + 2) * 30 == 300 + 20 * 3
true
&gt;&gt; (5 &gt; 5 == true) != false
false
&gt;&gt; 500 / 2 != 250
false</code></pre></div>
<p>So, now we have a fully functional calculator that's ready to do more. Let's give him more. Let's make it look more like a programming language.</p>
<h2 id="conditionals">3.6 - Conditionals</h2>
<p>You'll be amazed how easy it is to add support for conditionals in our evaluator. The only hard thing about their implementation is deciding when to evaluate what. Because that's the whole point of conditionals: only ever evaluate something based on a condition. Consider this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (x <span class="op">&gt;</span> <span class="dv">10</span>) <span class="op">{</span>
  <span class="at">puts</span>(<span class="st">&quot;everything okay!&quot;</span>)<span class="op">;</span>
<span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
  <span class="at">puts</span>(<span class="st">&quot;x is too low!&quot;</span>)<span class="op">;</span>
  <span class="at">shutdownSystem</span>()<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>When evaluating this if-else-expression the important thing is to only evaluate the correct branch. If the condition is met, we must never evaluate the else-branch, only the if-branch. And if it isn't met we must only evaluate the else-branch.</p>
<p>In other words: we can only evaluate the else-branch of this conditional if the condition <code>x &gt; 10</code> is not ... well, when it's not what exactly? Should we evaluate the consequence, the <code>&quot;everything okay!&quot;</code> branch, only when the condition expression generates a <code>true</code> or when it generates something &quot;truthy&quot;, something that's not false or not null?</p>
<p>And <em>that's</em> the tough part about this, because that's a design decision, a language design decision to be exact, with wide ranging consequences.</p>
<p>In the case of Monkey, the consequence part of the conditional will be evaluated when the condition is &quot;truthy&quot;. And &quot;truthy&quot; means: it's not null and it's not false. It doesn't necessarily need to be <code>true</code>.</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">10</span><span class="op">;</span>
<span class="cf">if</span> (x) <span class="op">{</span>
  <span class="at">puts</span>(<span class="st">&quot;everything okay!&quot;</span>)<span class="op">;</span>
<span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
  <span class="at">puts</span>(<span class="st">&quot;x is too high!&quot;</span>)<span class="op">;</span>
  <span class="at">shutdownSystem</span>()<span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>In this example <code>&quot;everything okay!&quot;</code> should be printed. Why? Because <code>x</code> is bound to <code>10</code>, evaluates to <code>10</code> and <code>10</code> is not null and not false. That's how conditionals are supposed to work in Monkey.</p>
<p>Now that we've talked about this, we can turn this specification into a set of test cases:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestIfElseExpressions(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="kw">interface</span>{}
    }{
        {<span class="st">&quot;if (true) { 10 }&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;if (false) { 10 }&quot;</span>, <span class="ot">nil</span>},
        {<span class="st">&quot;if (1) { 10 }&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;if (1 &lt; 2) { 10 }&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;if (1 &gt; 2) { 10 }&quot;</span>, <span class="ot">nil</span>},
        {<span class="st">&quot;if (1 &gt; 2) { 10 } else { 20 }&quot;</span>, <span class="dv">20</span>},
        {<span class="st">&quot;if (1 &lt; 2) { 10 } else { 20 }&quot;</span>, <span class="dv">10</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        integer, ok := tt.expected.(<span class="dt">int</span>)
        <span class="kw">if</span> ok {
            testIntegerObject(t, evaluated, <span class="dt">int64</span>(integer))
        } <span class="kw">else</span> {
            testNullObject(t, evaluated)
        }
    }
}

<span class="kw">func</span> testNullObject(t *testing.T, obj object.Object) <span class="dt">bool</span> {
    <span class="kw">if</span> obj != NULL {
        t.Errorf(<span class="st">&quot;object is not NULL. got=%T (%+v)&quot;</span>, obj, obj)
        <span class="kw">return</span> <span class="ot">false</span>
    }
    <span class="kw">return</span> <span class="ot">true</span>
}</code></pre></div>
<p>This test function also specifies behaviour we haven't talked about yet. When a conditional doesn't evaluate to a value it's supposed to return <code>NULL</code>, e.g.:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (<span class="kw">false</span>) <span class="op">{</span> <span class="dv">10</span> <span class="op">}</span></code></pre></div>
<p>The <code>else</code> is missing and thus the conditional should produce <code>NULL</code>.</p>
<p>We have to do a little type assertion and conversion dance to allow <code>nil</code> in our <code>expected</code> field, granted, but the tests are readable and clearly show the desired and hereby specified behaviour. They also fail, because we don't return any <code>*object.Integer</code>s or <code>NULL</code>:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestIfElseExpressions (0.00s)
  evaluator_test.go:125: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:153: object is not NULL. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:125: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:125: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:153: object is not NULL. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:125: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:125: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>Earlier I told you that you'll be amazed at how easy it is to implement support for conditionals. Didn't believe me? Well, look at this small amount of code necessary to make the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.BlockStatement:
        <span class="kw">return</span> evalStatements(node.Statements)

    <span class="kw">case</span> *ast.IfExpression:
        <span class="kw">return</span> evalIfExpression(node)
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalIfExpression(ie *ast.IfExpression) object.Object {
    condition := Eval(ie.Condition)

    <span class="kw">if</span> isTruthy(condition) {
        <span class="kw">return</span> Eval(ie.Consequence)
    } <span class="kw">else</span> <span class="kw">if</span> ie.Alternative != <span class="ot">nil</span> {
        <span class="kw">return</span> Eval(ie.Alternative)
    } <span class="kw">else</span> {
        <span class="kw">return</span> NULL
    }
}

<span class="kw">func</span> isTruthy(obj object.Object) <span class="dt">bool</span> {
    <span class="kw">switch</span> obj {
    <span class="kw">case</span> NULL:
        <span class="kw">return</span> <span class="ot">false</span>
    <span class="kw">case</span> TRUE:
        <span class="kw">return</span> <span class="ot">true</span>
    <span class="kw">case</span> FALSE:
        <span class="kw">return</span> <span class="ot">false</span>
    <span class="kw">default</span>:
        <span class="kw">return</span> <span class="ot">true</span>
    }
}</code></pre></div>
<p>As I said: the only hard thing is deciding what to evaluate. And that decision is encapsulated in <code>evalIfExpression</code> where the logic of the behaviour is pretty clear. <code>isTruthy</code> is equally expressive. Besides these two functions we also added the <code>case</code> branch for <code>*ast.BlockStatement</code> to our <code>Eval</code> switch statement, because the <code>.Consequence</code> and <code>.Alternative</code> of <code>*ast.IfExpression</code> are both block statements.</p>
<p>We added two new and concise functions that show the semantics of the Monkey programming language in a clear way, reused another function we already had in place and with doing so added support for conditionals and made the tests pass. Our interpreter now supports if-else-expressions! We're now leaving calculator territory and heading straight towards programming language land:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; if (5 * 5 + 10 &gt; 34) { 99 } else { 100 }
99
&gt;&gt; if ((1000 / 2) + 250 * 2 == 1000) { 9999 }
9999
&gt;&gt;</code></pre></div>
<h2 id="return-statements">3.7 - Return Statements</h2>
<p>Now here's something that you won't find on your standard calculator: return statements. Monkey has them, like a lot of other languages. They can be used in the bodies of functions but also as top-level statements in a Monkey program. But it doesn't really matter where they're used, because how they work doesn't change: return statements stop the evaluation of a series of statements and leave behind the value their expression has evaluated to.</p>
<p>Here is a top-level return statement in a Monkey program:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span><span class="op">;</span>
<span class="cf">return</span> <span class="dv">10</span><span class="op">;</span>
<span class="dv">9</span> <span class="op">*</span> <span class="dv">9</span> <span class="op">*</span> <span class="dv">9</span><span class="op">;</span></code></pre></div>
<p>When evaluated this program should return <code>10</code>. If these statements were the body of a function, calling the function should evaluate to <code>10</code>. The important thing is that the last line, the <code>9 * 9 * 9</code> expression, is never going to be evaluated.</p>
<p>There are a few different ways to implement return statements. In some host languages we could use gotos or exceptions. But in Go a &quot;rescue&quot; or &quot;catch&quot; are not easy to come by and we don't really have the option of using gotos in a clean way. That's why, in order to support return statements, we'll be passing a &quot;return value&quot; through our evaluator. Whenever we encounter a <code>return</code> we'll wrap the value it's supposed to return inside an object, so we can keep track of it. And we need to keep track of it so we can later decide whether to stop evaluation or not.</p>
<p>Here is the implementation of said object. Here is <code>object.ReturnValue</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    RETURN_VALUE_OBJ = <span class="st">&quot;RETURN_VALUE&quot;</span>
)

<span class="kw">type</span> ReturnValue <span class="kw">struct</span> {
    Value Object
}

<span class="kw">func</span> (rv *ReturnValue) Type() ObjectType { <span class="kw">return</span> RETURN_VALUE_OBJ }
<span class="kw">func</span> (rv *ReturnValue) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> rv.Value.Inspect() }</code></pre></div>
<p>Since this is just a wrapper around another object nothing here is surprising. What's interesting about <code>object.ReturnValue</code> is when and how it's used.</p>
<p>Here are the tests that demonstrate what we expect of the return statement in the context of a Monkey program:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestReturnStatements(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;return 10;&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;return 10; 9;&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;return 2 * 5; 9;&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;9; return 2 * 5; 9;&quot;</span>, <span class="dv">10</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        testIntegerObject(t, evaluated, tt.expected)
    }
}</code></pre></div>
<p>In order to get these tests to pass we have to change the <code>evalStatements</code> function we already have and add a <code>case</code> branch for <code>*ast.ReturnStatement</code> to <code>Eval</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.ReturnStatement:
        val := Eval(node.ReturnValue)
        <span class="kw">return</span> &amp;object.ReturnValue{Value: val}
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalStatements(stmts []ast.Statement) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> stmts {
        result = Eval(statement)

        <span class="kw">if</span> returnValue, ok := result.(*object.ReturnValue); ok {
            <span class="kw">return</span> returnValue.Value
        }
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>The first part of this change is the evaluation of <code>*ast.ReturnValue</code>, where we evaluate the expression associated with the return statement. We then wrap the result of this call to <code>Eval</code> in our new <code>object.ReturnValue</code> so we can keep track of it.</p>
<p>In <code>evalStatements</code>, which is used by <code>evalProgramStatements</code> and <code>evalBlockStatements</code> to evaluate a series of statements, we check if the last evaluation result is such an <code>object.ReturnValue</code> and if so, we stop the evaluation and return the unwrapped value. That's important. We don't return an <code>object.ReturnValue</code>, but only the value it's wrapping, which is what the user expects to be returned.</p>
<p>There's a problem, though. Sometimes we have to keep track of <code>object.ReturnValue</code>s for longer and can't unwrap their values on the first encounter. That's the case with block statements. Take a look at this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="cf">if</span> (<span class="dv">10</span> <span class="op">&gt;</span> <span class="dv">1</span>) <span class="op">{</span>
  <span class="cf">if</span> (<span class="dv">10</span> <span class="op">&gt;</span> <span class="dv">1</span>) <span class="op">{</span>
    <span class="cf">return</span> <span class="dv">10</span><span class="op">;</span>
  <span class="op">}</span>

  <span class="cf">return</span> <span class="dv">1</span><span class="op">;</span>
<span class="op">}</span></code></pre></div>
<p>This program should return <code>10</code>. But with our current implementation, it doesn't and returns <code>1</code>. A small test case confirms this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestReturnStatements(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">`</span>
<span class="st">if (10 &gt; 1) {</span>
<span class="st">  if (10 &gt; 1) {</span>
<span class="st">    return 10;</span>
<span class="st">  }</span>

<span class="st">  return 1;</span>
<span class="st">}</span>
<span class="st">`</span>,
            <span class="dv">10</span>,
        },
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>This test case fails with the expected message:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestReturnStatements (0.00s)
  evaluator_test.go:159: object has wrong value. got=1, want=10
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>I bet that you've already figured out what the problem with our current implementation is. But if you want me to spell it out, here it comes: if we have nested block statements (which is totally legit in a Monkey program!) we can't unwrap the value of <code>object.ReturnValue</code> on first sight, because we need to further keep track of it so we can stop the execution in the outermost block statement.</p>
<p>Non-nested block statements work fine with our current implementation. But to get nested ones to work, the first thing we have to do is to accept that we can't reuse our <code>evalStatements</code> function for evaluating block statements. That's why we're going to rename it to <code>evalProgram</code> and make it less generic.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.Program:
        <span class="kw">return</span> evalProgram(node)
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalProgram(program *ast.Program) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> program.Statements {
        result = Eval(statement)

        <span class="kw">if</span> returnValue, ok := result.(*object.ReturnValue); ok {
            <span class="kw">return</span> returnValue.Value
        }
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>For evaluating an <code>*ast.BlockStatement</code> we introduce a new function called <code>evalBlockStatement</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.BlockStatement:
        <span class="kw">return</span> evalBlockStatement(node)
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalBlockStatement(block *ast.BlockStatement) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> block.Statements {
        result = Eval(statement)

        <span class="kw">if</span> result != <span class="ot">nil</span> &amp;&amp; result.Type() == object.RETURN_VALUE_OBJ {
            <span class="kw">return</span> result
        }
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>Here we explicitly don't unwrap the return value and only check the <code>Type()</code> of each evaluation result. If it's <code>object.RETURN_VALUE_OBJ</code> we simply return the <code>*object.ReturnValue</code>, without unwrapping its <code>.Value</code>, so it stops execution in a possible outer block statement and bubbles up to <code>evalProgram</code>, where it finally get's unwrapped. (That last part will change when we implement the evaluation of function calls.)</p>
<p>And with that the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Return statements are implemented. Now we're definitely not building a calculator anymore. And since <code>evalProgram</code> and <code>evalBlockStatement</code> are still so fresh in our mind let's keep working on them.</p>
<h2 id="abort-abort-theres-been-a-mistake-or-error-handling">3.8 - Abort! Abort! There's been a mistake!, or: Error Handling</h2>
<p>Remember all the <code>NULL</code>s we were returning earlier and I said that you shouldn't worry and we'll come back to them? Here we are. It's time to implement some real error handling in Monkey before it's too late and we'd have to backpedal too much. Granted, we have to backpedal a little bit and correct previous code, but not much. We didn't implement error handling as the first thing in our interpreter, because, and to be completely honest, I thought implementing expressions first is a lot more fun than error handling. But we're now at a point where we need to add it, otherwise debugging and using our interpreter becomes too cumbersome in the near future.</p>
<p>First of all, let's define what I mean with &quot;real error handling&quot;. It is <em>not</em> user-defined exceptions. It's internal error handling. Errors for wrong operators, unsupported operations, and other user or internal errors that may arise during execution.</p>
<p>As for the implementation of such errors: this will probably sound weird, but the error handling is implemented in nearly the same way as handling return statements is. The reason for this similarity is easy to find: errors and return statements both stop the evaluation of a series of statements.</p>
<p>The first thing we need is an error object:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    ERROR_OBJ = <span class="st">&quot;ERROR&quot;</span>
)

<span class="kw">type</span> Error <span class="kw">struct</span> {
    Message <span class="dt">string</span>
}

<span class="kw">func</span> (e *Error) Type() ObjectType { <span class="kw">return</span> ERROR_OBJ }
<span class="kw">func</span> (e *Error) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> <span class="st">&quot;ERROR: &quot;</span> + e.Message }</code></pre></div>
<p>As you can see, <code>object.Error</code> is really, really simple. It only wraps a string that serves as error message. In a production-ready interpreter we'd want to attach a stack trace to such error objects, add the line and column numbers of its origin and provide more than just a message. That's not so hard to do, provided that line and column numbers are attached to the tokens by the lexer. Since our lexer doesn't do that, to keep things simple, we only use an error message, which still serves us a great deal by giving us some feedback and stopping execution.</p>
<p>We will add support for errors in a few places now. Later, with increased capability of our interpreter, we'll add more where appropriate. For now, this test function shows what we expect the error handling to do:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestErrorHandling(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input           <span class="dt">string</span>
        expectedMessage <span class="dt">string</span>
    }{
        {
            <span class="st">&quot;5 + true;&quot;</span>,
            <span class="st">&quot;type mismatch: INTEGER + BOOLEAN&quot;</span>,
        },
        {
            <span class="st">&quot;5 + true; 5;&quot;</span>,
            <span class="st">&quot;type mismatch: INTEGER + BOOLEAN&quot;</span>,
        },
        {
            <span class="st">&quot;-true&quot;</span>,
            <span class="st">&quot;unknown operator: -BOOLEAN&quot;</span>,
        },
        {
            <span class="st">&quot;true + false;&quot;</span>,
            <span class="st">&quot;unknown operator: BOOLEAN + BOOLEAN&quot;</span>,
        },
        {
            <span class="st">&quot;5; true + false; 5&quot;</span>,
            <span class="st">&quot;unknown operator: BOOLEAN + BOOLEAN&quot;</span>,
        },
        {
            <span class="st">&quot;if (10 &gt; 1) { true + false; }&quot;</span>,
            <span class="st">&quot;unknown operator: BOOLEAN + BOOLEAN&quot;</span>,
        },
        {
            <span class="st">`</span>
<span class="st">if (10 &gt; 1) {</span>
<span class="st">  if (10 &gt; 1) {</span>
<span class="st">    return true + false;</span>
<span class="st">  }</span>

<span class="st">  return 1;</span>
<span class="st">}</span>
<span class="st">`</span>,
            <span class="st">&quot;unknown operator: BOOLEAN + BOOLEAN&quot;</span>,
        },
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)

        errObj, ok := evaluated.(*object.Error)
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;no error object returned. got=%T(%+v)&quot;</span>,
                evaluated, evaluated)
            <span class="kw">continue</span>
        }

        <span class="kw">if</span> errObj.Message != tt.expectedMessage {
            t.Errorf(<span class="st">&quot;wrong error message. expected=%q, got=%q&quot;</span>,
                tt.expectedMessage, errObj.Message)
        }
    }
}</code></pre></div>
<p>When we run the tests we meet our old friend <code>NULL</code> again:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestErrorHandling (0.00s)
  evaluator_test.go:193: no error object returned. got=*object.Null(&amp;{})
  evaluator_test.go:193: no error object returned.\
    got=*object.Integer(&amp;{Value:5})
  evaluator_test.go:193: no error object returned. got=*object.Null(&amp;{})
  evaluator_test.go:193: no error object returned. got=*object.Null(&amp;{})
  evaluator_test.go:193: no error object returned.\
    got=*object.Integer(&amp;{Value:5})
  evaluator_test.go:193: no error object returned. got=*object.Null(&amp;{})
  evaluator_test.go:193: no error object returned.\
    got=*object.Integer(&amp;{Value:10})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>But there are also unexpected <code>*object.Integer</code>s. That's because these test cases actually assert two things: that errors are created for unsupported operations and that errors prevent any further evaluation. When the test fails because of an <code>*object.Integer</code> being returned, the evaluation didn't stop correctly.</p>
<p>Creating errors and passing them around in <code>Eval</code> is easy. We just need a helper function to help us create new <code>*object.Error</code>s and return them when we think we should:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> newError(format <span class="dt">string</span>, a ...<span class="kw">interface</span>{}) *object.Error {
    <span class="kw">return</span> &amp;object.Error{Message: fmt.Sprintf(format, a...)}
}</code></pre></div>
<p>This <code>newError</code> function finds its use in every place where we didn't know what to do before and returned <code>NULL</code> instead:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalPrefixExpression(operator <span class="dt">string</span>, right object.Object) object.Object {
    <span class="kw">switch</span> operator {
<span class="co">// [...]</span>
    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;unknown operator: %s%s&quot;</span>, operator, right.Type())
    }
}

<span class="kw">func</span> evalInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    <span class="kw">switch</span> {
<span class="co">// [...]</span>
    <span class="kw">case</span> left.Type() != right.Type():
        <span class="kw">return</span> newError(<span class="st">&quot;type mismatch: %s %s %s&quot;</span>,
            left.Type(), operator, right.Type())
    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;unknown operator: %s %s %s&quot;</span>,
            left.Type(), operator, right.Type())
    }
}

<span class="kw">func</span> evalMinusPrefixOperatorExpression(right object.Object) object.Object {
    <span class="kw">if</span> right.Type() != object.INTEGER_OBJ {
        <span class="kw">return</span> newError(<span class="st">&quot;unknown operator: -%s&quot;</span>, right.Type())
    }
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalIntegerInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
<span class="co">// [...]</span>
    <span class="kw">switch</span> operator {
<span class="co">// [...]</span>
    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;unknown operator: %s %s %s&quot;</span>,
            left.Type(), operator, right.Type())
    }
}</code></pre></div>
<p>With these changes made the number of failing test cases has been reduced to just two:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestErrorHandling (0.00s)
  evaluator_test.go:193: no error object returned.\
    got=*object.Integer(&amp;{Value:5})
  evaluator_test.go:193: no error object returned.\
    got=*object.Integer(&amp;{Value:5})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>That output tells us that creating errors poses no problem but stopping the evaluation still does. We already know where to look though, don't we? Yes, that's right: <code>evalProgram</code> and <code>evalBlockStatement</code>. Here are both functions in their entirety, with newly added support for error handling:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalProgram(program *ast.Program) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> program.Statements {
        result = Eval(statement)

        <span class="kw">switch</span> result := result.(<span class="kw">type</span>) {
        <span class="kw">case</span> *object.ReturnValue:
            <span class="kw">return</span> result.Value
        <span class="kw">case</span> *object.Error:
            <span class="kw">return</span> result
        }
    }

    <span class="kw">return</span> result
}

<span class="kw">func</span> evalBlockStatement(block *ast.BlockStatement) object.Object {
    <span class="kw">var</span> result object.Object

    <span class="kw">for</span> _, statement := <span class="kw">range</span> block.Statements {
        result = Eval(statement)

        <span class="kw">if</span> result != <span class="ot">nil</span> {
            rt := result.Type()
            <span class="kw">if</span> rt == object.RETURN_VALUE_OBJ || rt == object.ERROR_OBJ {
                <span class="kw">return</span> result
            }
        }
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>That did it. Evaluation is stopped at the right places and the tests now pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.010s</code></pre></div>
<p>There's still one last thing we need to do. We need to check for errors whenever we call <code>Eval</code> inside of <code>Eval</code>, in order to stop errors from being passed around and then bubbling up far away from their origin:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> isError(obj object.Object) <span class="dt">bool</span> {
    <span class="kw">if</span> obj != <span class="ot">nil</span> {
        <span class="kw">return</span> obj.Type() == object.ERROR_OBJ
    }
    <span class="kw">return</span> <span class="ot">false</span>
}

<span class="kw">func</span> Eval(node ast.Node) object.Object {
    <span class="kw">switch</span> node := node.(<span class="kw">type</span>) {

<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.ReturnStatement:
        val := Eval(node.ReturnValue)
        <span class="kw">if</span> isError(val) {
            <span class="kw">return</span> val
        }
        <span class="kw">return</span> &amp;object.ReturnValue{Value: val}

<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.PrefixExpression:
        right := Eval(node.Right)
        <span class="kw">if</span> isError(right) {
            <span class="kw">return</span> right
        }
        <span class="kw">return</span> evalPrefixExpression(node.Operator, right)

    <span class="kw">case</span> *ast.InfixExpression:
        left := Eval(node.Left)
        <span class="kw">if</span> isError(left) {
            <span class="kw">return</span> left
        }

        right := Eval(node.Right)
        <span class="kw">if</span> isError(right) {
            <span class="kw">return</span> right
        }

        <span class="kw">return</span> evalInfixExpression(node.Operator, left, right)
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalIfExpression(ie *ast.IfExpression) object.Object {
    condition := Eval(ie.Condition)
    <span class="kw">if</span> isError(condition) {
        <span class="kw">return</span> condition
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>And that's it. Error handling is in place.</p>
<h2 id="bindings-the-environment">3.9 - Bindings &amp; The Environment</h2>
<p>Up next we're going to add bindings to our interpreter by adding support for let statements. But not only do we need to support let statements, no, we need to support the evaluation of identifiers, too. Let's say we have evaluated the following piece of code:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> x <span class="op">=</span> <span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span><span class="op">;</span></code></pre></div>
<p>Only adding support for the evaluation of this statement is not enough. We also need to make sure that the <code>x</code> evaluates to <code>10</code> after interpreting the line above.</p>
<p>So, our task in this section is to evaluate let statements and identifiers. We evaluate let statements by evaluating their value-producing expression and keeping track of the produced value under the specified name. To evaluate identifiers we check if we already have a value bound to the name. If we do, the identifier evaluates to this value, and if we don't, we return an error.</p>
<p>Sounds like a good plan? Alright, so let's kick this off with a few tests:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestLetStatements(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;let a = 5; a;&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;let a = 5 * 5; a;&quot;</span>, <span class="dv">25</span>},
        {<span class="st">&quot;let a = 5; let b = a; b;&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;let a = 5; let b = a; let c = a + b + 5; c;&quot;</span>, <span class="dv">15</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        testIntegerObject(t, testEval(tt.input), tt.expected)
    }
}</code></pre></div>
<p>The test cases assert that these two things should work: evaluating the value-producing expression in a let statement and evaluating an identifier that's bound to a name. But we also need tests to make sure that we get an error when we try to evaluate an unbound identifier. And for that we can simply extend our existing <code>TestErrorHandling</code> function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestErrorHandling(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input           <span class="dt">string</span>
        expectedMessage <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">&quot;foobar&quot;</span>,
            <span class="st">&quot;identifier not found: foobar&quot;</span>,
        },
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>How do we make these tests pass? Obviously the first thing we have to do is add a new <code>case</code> branch for <code>*ast.LetStatement</code> to <code>Eval</code>. And in this branch we need to <code>Eval</code> the expression of the let statement, correct? So let's start with that:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.LetStatement:
        val := Eval(node.Value)
        <span class="kw">if</span> isError(val) {
            <span class="kw">return</span> val
        }

    <span class="co">// Huh? Now what?</span>


<span class="co">// [...]</span>
}</code></pre></div>
<p>The comment is right: now what? How to we keep track of values? We have the value and we have the name we should bind it too, <code>node.Name.Value</code>. How do we associate one with the other?</p>
<p>This is where something called the environment comes into play. The environment is what we use to keep track of value by associating them with a name. The name &quot;environment&quot; is a classic one, used in a lot of other interpreters, especially Lispy ones. But even though the name may sound sophisticated, at its heart the environment is a hash map that associates strings with objects. And that's exactly what we're going to use for our implementation.</p>
<p>We'll add a new <code>Environment</code> struct to the <code>object</code> package. And yes, for now it really is just a thin wrapper around a <code>map</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/environment.go</span>

<span class="kw">package</span> object

<span class="kw">func</span> NewEnvironment() *Environment {
    s := <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]Object)
    <span class="kw">return</span> &amp;Environment{store: s}
}

<span class="kw">type</span> Environment <span class="kw">struct</span> {
    store <span class="kw">map</span>[<span class="dt">string</span>]Object
}

<span class="kw">func</span> (e *Environment) Get(name <span class="dt">string</span>) (Object, <span class="dt">bool</span>) {
    obj, ok := e.store[name]
    <span class="kw">return</span> obj, ok
}

<span class="kw">func</span> (e *Environment) Set(name <span class="dt">string</span>, val Object) Object {
    e.store[name] = val
    <span class="kw">return</span> val
}</code></pre></div>
<p>Let me guess what you're thinking: <em>Why not use a map? Why the wrapper?</em> It'll all make sense as soon as we start implementing functions and function calls in the next section, I promise. This is the groundwork we'll build upon later.</p>
<p>As it is, the usage of <code>object.Environment</code> itself is self-explanatory. But how do we use it inside <code>Eval</code>? How and where do we keep track of the environment? We pass it around by making it a parameter of <code>Eval</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
}</code></pre></div>
<p>With that change nothing compiles anymore, because we have to change every call to <code>Eval</code> make use of the environment. And not only the calls to <code>Eval</code> in <code>Eval</code> itself, but also the ones in functions such as <code>evalProgram</code>, <code>evalIfExpression</code> and so on. This requires more manual editor work than anything else, so I won't bore you by showing the list of changes here.</p>
<p>The calls to <code>Eval</code> in our REPL and in our test suite need to use an environment too, of course. In the REPL we use a single environment:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// repl/repl.go</span>

<span class="kw">func</span> Start(in io.Reader, out io.Writer) {
    scanner := bufio.NewScanner(in)
    env := object.NewEnvironment()

    <span class="kw">for</span> {
<span class="co">// [...]</span>
        evaluated := evaluator.Eval(program, env)
        <span class="kw">if</span> evaluated != <span class="ot">nil</span> {
            io.WriteString(out, evaluated.Inspect())
            io.WriteString(out, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
        }
    }
}</code></pre></div>
<p>The environment we use here, <code>env</code>, persists between calls to <code>Eval</code>. If it didn't, binding a value to a name in the REPL would be without any effect. As soon as the next line is evaluated, the association wouldn't be in the new environment.</p>
<p>That's exactly what we want in our test suite, though. We don't want to keep state around for each test function and each test case. Each call to <code>testEval</code> should have a fresh environment so we don't run into weird bugs involving global state caused by the order in which tests are run. Every call to <code>Eval</code> here gets a fresh environment:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> testEval(input <span class="dt">string</span>) object.Object {
    l := lexer.New(input)
    p := parser.New(l)
    program := p.ParseProgram()
    env := object.NewEnvironment()

    <span class="kw">return</span> Eval(program, env)
}</code></pre></div>
<p>With updated <code>Eval</code> calls the tests compile again and we can start making them pass, which is not too hard with <code>*object.Environemnt</code> available. In the <code>case</code> branch for <code>*ast.LetStatement</code> we can just use the name and value we already have and save them in the current environment:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.LetStatement:
        val := Eval(node.Value, env)
        <span class="kw">if</span> isError(val) {
            <span class="kw">return</span> val
        }
        env.Set(node.Name.Value, val)
<span class="co">// [...]</span>
}</code></pre></div>
<p>Now we're adding associations to the environment when evaluating let statements. But we also need to get these values out when we're evaluating identifiers. Doing that is pretty easy, too:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.Identifier:
        <span class="kw">return</span> evalIdentifier(node, env)
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalIdentifier(
    node *ast.Identifier,
    env *object.Environment,
) object.Object {
    val, ok := env.Get(node.Value)
    <span class="kw">if</span> !ok {
        <span class="kw">return</span> newError(<span class="st">&quot;identifier not found: &quot;</span> + node.Value)
    }

    <span class="kw">return</span> val
}</code></pre></div>
<p><code>evalIdentifier</code> will be extended in the next section. For now it simply checks if a value has been associated with the given name in the current environment. If that's the case it returns the value, otherwise an error.</p>
<p>Look at this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Yes, you're right, that's exactly what this means: we're now firmly standing in programming language land.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let a = 5;
&gt;&gt; let b = a &gt; 3;
&gt;&gt; let c = a * 99;
&gt;&gt; if (b) { 10 } else { 1 };
10
&gt;&gt; let d = if (c &gt; a) { 99 } else { 100 };
&gt;&gt; d
99
&gt;&gt; d * c * a;
245025</code></pre></div>
<h2 id="functions-function-calls">3.10 - Functions &amp; Function Calls</h2>
<p>This is what we've been working towards. This is the third act. We're going to add support for functions and function calls to our interpreter. When we're done with this section, we'll be able to do this in our REPL:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let add = fn(a, b, c, d) { return a + b + c + d };
&gt;&gt; add(1, 2, 3, 4);
10
&gt;&gt; let addThree = fn(x) { return x + 3 };
&gt;&gt; addThree(3);
6
&gt;&gt; let max = fn(x, y) { if (x &gt; y) { x } else { y } };
&gt;&gt; max(5, 10)
10
&gt;&gt; let factorial = fn(n) { if (n == 0) { 1 } else { n * factorial(n - 1) } };
&gt;&gt; factorial(5)
120</code></pre></div>
<p>If that doesn't impress you then take a look at this. Passing around functions, higher-order functions and closures will also work:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let callTwoTimes = fn(x, func) { func(func(x)) };
&gt;&gt; callTwoTimes(3, addThree);
9
&gt;&gt; callTwoTimes(3, fn(x) { x + 1 });
5
&gt;&gt; let newAdder = fn(x) { fn(n) { x + n } };
&gt;&gt; let addTwo = newAdder(2);
&gt;&gt; addTwo(2);
4</code></pre></div>
<p>Yes, that's right, we will be able to do all of <em>that</em>.</p>
<p>In order to get from where we currently are to <em>there</em> we need to do two things: define an internal representation of functions in our object system and add support for function calls to <code>Eval</code>.</p>
<p>But don't worry. It's easy. The work we did in the last sections now pays off. We can reuse and extend a lot of things we already built. You'll see that a lot of things just start to fit together at a certain point in this section.</p>
<p>Since &quot;one step at a time&quot; brought us here there's no reason to abandon this strategy now. The first step is to take care of the internal representation of functions.</p>
<p>The need to represent functions internally comes from the fact that functions in Monkey are treated like any other value: we can bind them to names, use them in expressions, pass them to other functions, return them from functions and so on. And like other values, functions need a representation in our object system, so we can pass around, assign and return them.</p>
<p>But how do we represent a function internally, as an object? Our definition of <code>ast.FunctionLiteral</code> gives us a starting point:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> FunctionLiteral <span class="kw">struct</span> {
    Token      token.Token <span class="co">// The &#39;fn&#39; token</span>
    Parameters []*Identifier
    Body       *BlockStatement
}</code></pre></div>
<p>We don't need the <code>Token</code> field in a function object, but <code>Parameters</code> and <code>Body</code> make sense. We can't evaluate a function without its body and we can't evaluate the body if we don't know which parameters the function has. Besides <code>Parameters</code> and <code>Body</code> we also need a third field in our new function object:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    FUNCTION_OBJ = <span class="st">&quot;FUNCTION&quot;</span>
)

<span class="kw">type</span> Function <span class="kw">struct</span> {
    Parameters []*ast.Identifier
    Body       *ast.BlockStatement
    Env        *Environment
}

<span class="kw">func</span> (f *Function) Type() ObjectType { <span class="kw">return</span> FUNCTION_OBJ }
<span class="kw">func</span> (f *Function) Inspect() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    params := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, p := <span class="kw">range</span> f.Parameters {
        params = <span class="bu">append</span>(params, p.String())
    }

    out.WriteString(<span class="st">&quot;fn&quot;</span>)
    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(strings.Join(params, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;) {</span><span class="ch">\n</span><span class="st">&quot;</span>)
    out.WriteString(f.Body.String())
    out.WriteString(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">}&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>This definition of <code>object.Function</code> has the <code>Parameters</code> and <code>Body</code> fields. But it also has <code>Env</code>, a field that holds a pointer to an <code>object.Environment</code>, because functions in Monkey carry their own environment with them. That allows for closures, which &quot;close over&quot; the environment they're defined in and can later access it. That will make more sense when we start using the <code>Env</code> field. You'll see.</p>
<p>With that definition done, we can now write a test to assert that our interpreter knows how to build functions:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestFunctionObject(t *testing.T) {
    input := <span class="st">&quot;fn(x) { x + 2; };&quot;</span>

    evaluated := testEval(input)
    fn, ok := evaluated.(*object.Function)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;object is not Function. got=%T (%+v)&quot;</span>, evaluated, evaluated)
    }

    <span class="kw">if</span> <span class="bu">len</span>(fn.Parameters) != <span class="dv">1</span> {
        t.Fatalf(<span class="st">&quot;function has wrong parameters. Parameters=%+v&quot;</span>,
            fn.Parameters)
    }

    <span class="kw">if</span> fn.Parameters[<span class="dv">0</span>].String() != <span class="st">&quot;x&quot;</span> {
        t.Fatalf(<span class="st">&quot;parameter is not &#39;x&#39;. got=%q&quot;</span>, fn.Parameters[<span class="dv">0</span>])
    }

    expectedBody := <span class="st">&quot;(x + 2)&quot;</span>

    <span class="kw">if</span> fn.Body.String() != expectedBody {
        t.Fatalf(<span class="st">&quot;body is not %q. got=%q&quot;</span>, expectedBody, fn.Body.String())
    }
}</code></pre></div>
<p>This test function asserts that evaluating a function literal results in the correct <code>*object.Function</code> being returned, with correct parameters and the correct body. The function's environment will be tested later on in other tests, implicitly. Making this test pass takes just a few lines of code added to <code>Eval</code> in the form of a new <code>case</code> branch:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.FunctionLiteral:
        params := node.Parameters
        body := node.Body
        <span class="kw">return</span> &amp;object.Function{Parameters: params, Env: env, Body: body}
<span class="co">// [...]</span>
}</code></pre></div>
<p>Easy, right? The test passes. We just reuse the <code>Parameters</code> and <code>Body</code> fields of the AST node. Notice how we use the current environment when building the function object.</p>
<p>With that relatively low-level test passing and thus having made sure that we build the internal representation of functions correctly, we can turn to the topic of function application. That means, extending our interpreter so that we can call functions. The tests for this are much more readable and easier to write:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestFunctionApplication(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">int64</span>
    }{
        {<span class="st">&quot;let identity = fn(x) { x; }; identity(5);&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;let identity = fn(x) { return x; }; identity(5);&quot;</span>, <span class="dv">5</span>},
        {<span class="st">&quot;let double = fn(x) { x * 2; }; double(5);&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;let add = fn(x, y) { x + y; }; add(5, 5);&quot;</span>, <span class="dv">10</span>},
        {<span class="st">&quot;let add = fn(x, y) { x + y; }; add(5 + 5, add(5, 5));&quot;</span>, <span class="dv">20</span>},
        {<span class="st">&quot;fn(x) { x; }(5)&quot;</span>, <span class="dv">5</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        testIntegerObject(t, testEval(tt.input), tt.expected)
    }
}</code></pre></div>
<p>Each test case here does the same thing: define a function, apply it to arguments and then make an assertion about the produced value. But with their slight differences they test multiple important things: returning values implicitly, returning values using <code>return</code> statements, using parameters in expressions, multiple parameters and evaluating arguments before passing them to the function.</p>
<p>We are also testing two possible forms of <code>*ast.CallExpression</code> here. One where the function is an identifier that evaluates to a function object, and the second one where the function is a function literal. The neat thing is that it doesn't really matter. We already know how to evaluate identifiers and function literals:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.CallExpression:
        function := Eval(node.Function, env)
        <span class="kw">if</span> isError(function) {
            <span class="kw">return</span> function
        }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Yes, we're just using <code>Eval</code> to get the function we want to call. Whether that's an <code>*ast.Identifier</code> or an <code>*ast.FunctionLiteral</code>: <code>Eval</code> returns an <code>*object.Function</code> (if there's no error, of course).</p>
<p>But how do we do call this <code>*object.Function</code>? The first step is to evaluate the arguments of a call expression. The reason is simple:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> add <span class="op">=</span> <span class="at">fn</span>(x<span class="op">,</span> y) <span class="op">{</span> x <span class="op">+</span> y <span class="op">};</span>
<span class="at">add</span>(<span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">5</span> <span class="op">+</span> <span class="dv">5</span>)<span class="op">;</span></code></pre></div>
<p>Here we want to pass <code>4</code> and <code>10</code> to the <code>add</code> function as arguments and not the expressions <code>2 + 2</code> and <code>5 + 5</code>.</p>
<p>Evaluating the arguments is nothing more than evaluating a list of expressions and keeping track of the produced values. But we also have to stop the evaluation process as soon as it encounters an error. That leads us to this code:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.CallExpression:
        function := Eval(node.Function, env)
        <span class="kw">if</span> isError(function) {
            <span class="kw">return</span> function
        }
        args := evalExpressions(node.Arguments, env)
        <span class="kw">if</span> <span class="bu">len</span>(args) == <span class="dv">1</span> &amp;&amp; isError(args[<span class="dv">0</span>]) {
            <span class="kw">return</span> args[<span class="dv">0</span>]
        }
<span class="co">// [...]</span>
}

<span class="kw">func</span> evalExpressions(
    exps []ast.Expression,
    env *object.Environment,
) []object.Object {
    <span class="kw">var</span> result []object.Object

    <span class="kw">for</span> _, e := <span class="kw">range</span> exps {
        evaluated := Eval(e, env)
        <span class="kw">if</span> isError(evaluated) {
            <span class="kw">return</span> []object.Object{evaluated}
        }
        result = <span class="bu">append</span>(result, evaluated)
    }

    <span class="kw">return</span> result
}</code></pre></div>
<p>Nothing fancy going on here. We just iterate over a list of <code>ast.Expression</code>s and evaluate them in the context of the current environment. If we encounter an error, we stop the evaluation and return the error. This is also the part where we decided to evaluate the arguments from left-to-right. Hopefully we won't be writing code in Monkey that makes assertions about the order of argument evaluation, but if we do, we're on the conservative and safe side of programming language design.</p>
<p>So! Now that we have both the function and the list of evaluated arguments, how do we &quot;call the function&quot;? How do we apply the function to the arguments?</p>
<p>The obvious answer is that we have to evaluate the body of the function, which is just a block statement. We already know how to evaluate those, so why not just call <code>Eval</code> and pass it the body of the function? One word: arguments. The body of the function can contain references to the parameters of the function and just evaluating the body in the current environment would result in references to unknown names, which would lead to errors, which is not what we want. Evaluating the body as it is, in the current environment, does not work.</p>
<p>What we need to do instead is change the environment in which the function is evaluated, so that the references to parameters in the function's body resolve to the correct arguments. But we can't just add these arguments to the current environment. That could lead to previous bindings being overwritten, which is not what we want. We want this to work:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> i <span class="op">=</span> <span class="dv">5</span><span class="op">;</span>
<span class="kw">let</span> printNum <span class="op">=</span> <span class="at">fn</span>(i) <span class="op">{</span>
  <span class="at">puts</span>(i)<span class="op">;</span>
<span class="op">};</span>

<span class="at">printNum</span>(<span class="dv">10</span>)<span class="op">;</span>
<span class="at">puts</span>(i)<span class="op">;</span></code></pre></div>
<p>With a <code>puts</code> function that prints lines, this should print two lines, containing <code>10</code> and <code>5</code> respectively. If we were to overwrite the current environment before evaluating the body of <code>printNum</code>, the last line would also result in <code>10</code> being printed.</p>
<p>So adding the arguments of the function call to the current environment in order to make them accessible in the function's body does not work. What we need to do instead is to preserve previous bindings while at the same time making new ones available - we'll call that &quot;extending the environment&quot;.</p>
<p>Extending the environment means that we create a new instance of <code>object.Environment</code> with a pointer to the environment it should extend. By doing that we enclose a fresh and empty environment with an existing one.</p>
<p>When the new environment's <code>Get</code> method is called and it itself doesn't have a value associated with the given name, it calls the <code>Get</code> of the enclosing environment. That's the environment it's extending. And if that enclosing environment can't find the value, it calls its own enclosing environment and so on until there is no enclosing environment anymore and we can safely say that we have an &quot;ERROR: unknown identifier: foobar&quot;.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/environment.go</span>

<span class="kw">package</span> object

<span class="kw">func</span> NewEnclosedEnvironment(outer *Environment) *Environment {
    env := NewEnvironment()
    env.outer = outer
    <span class="kw">return</span> env
}

<span class="kw">func</span> NewEnvironment() *Environment {
    s := <span class="bu">make</span>(<span class="kw">map</span>[<span class="dt">string</span>]Object)
    <span class="kw">return</span> &amp;Environment{store: s, outer: <span class="ot">nil</span>}
}

<span class="kw">type</span> Environment <span class="kw">struct</span> {
    store <span class="kw">map</span>[<span class="dt">string</span>]Object
    outer *Environment
}

<span class="kw">func</span> (e *Environment) Get(name <span class="dt">string</span>) (Object, <span class="dt">bool</span>) {
    obj, ok := e.store[name]
    <span class="kw">if</span> !ok &amp;&amp; e.outer != <span class="ot">nil</span> {
        obj, ok = e.outer.Get(name)
    }
    <span class="kw">return</span> obj, ok
}

<span class="kw">func</span> (e *Environment) Set(name <span class="dt">string</span>, val Object) Object {
    e.store[name] = val
    <span class="kw">return</span> val
}</code></pre></div>
<p><code>object.Environment</code> now has a new field called <code>outer</code> that can contain a reference to another <code>object.Environment</code>, which is the enclosing environment, the one it's extending. The <code>NewEnclosedEnvironment</code> function makes creating such an enclosed environment easy. The <code>Get</code> method has also been changed. It now checks the enclosing environment for the given name, too.</p>
<p>This new behaviour mirrors how we think about variable scopes. There is an inner scope and an outer scope. If something is not found in the inner scope, it's looked up in the outer scope. The outer scope <em>encloses</em> the inner scope. And the inner scope <em>extends</em> the outer one.</p>
<p>With our updated <code>object.Environment</code> functionality we can correctly evaluate function bodies. Remember, the problem was this: possibly overwriting existing bindings in a environment when binding the arguments of a function call to the parameter names of the function. Now, instead of overwriting bindings, we create a new environment that's enclosed by the current environment and add our bindings to this fresh and empty environment.</p>
<p>But we won't use the current environment as the enclosing environment, no. Instead we'll use the environment our <code>*object.Function</code> carries around. Remember that one? That's the environment our function was defined in.</p>
<p>Here is the updated version of <code>Eval</code> that handles function calls completely and correctly:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>
    <span class="kw">case</span> *ast.CallExpression:
        function := Eval(node.Function, env)
        <span class="kw">if</span> isError(function) {
            <span class="kw">return</span> function
        }
        args := evalExpressions(node.Arguments, env)
        <span class="kw">if</span> <span class="bu">len</span>(args) == <span class="dv">1</span> &amp;&amp; isError(args[<span class="dv">0</span>]) {
            <span class="kw">return</span> args[<span class="dv">0</span>]
        }

        <span class="kw">return</span> applyFunction(function, args)
<span class="co">// [...]</span>
}

<span class="kw">func</span> applyFunction(fn object.Object, args []object.Object) object.Object {
    function, ok := fn.(*object.Function)
    <span class="kw">if</span> !ok {
        <span class="kw">return</span> newError(<span class="st">&quot;not a function: %s&quot;</span>, fn.Type())
    }

    extendedEnv := extendFunctionEnv(function, args)
    evaluated := Eval(function.Body, extendedEnv)
    <span class="kw">return</span> unwrapReturnValue(evaluated)
}

<span class="kw">func</span> extendFunctionEnv(
    fn *object.Function,
    args []object.Object,
) *object.Environment {
    env := object.NewEnclosedEnvironment(fn.Env)

    <span class="kw">for</span> paramIdx, param := <span class="kw">range</span> fn.Parameters {
        env.Set(param.Value, args[paramIdx])
    }

    <span class="kw">return</span> env
}

<span class="kw">func</span> unwrapReturnValue(obj object.Object) object.Object {
    <span class="kw">if</span> returnValue, ok := obj.(*object.ReturnValue); ok {
        <span class="kw">return</span> returnValue.Value
    }

    <span class="kw">return</span> obj
}</code></pre></div>
<p>In the new <code>applyFunction</code> function we not only check that we really have a <code>*object.Function</code> at hand but also convert the <code>fn</code> parameter to a <code>*object.Function</code> reference in order to get access to the function's <code>.Env</code> and <code>.Body</code> fields (which <code>object.Object</code> doesn't define).</p>
<p>The <code>extendFunctionEnv</code> function creates a new <code>*object.Environment</code> that's enclosed by the function's environment. In this new, enclosed environment it binds the arguments of the function call to the function's parameter names.</p>
<p>And this newly enclosed and updated environment is then the environment in which the function's body is evaluated. The result of this evaluation is unwrapped if it's an <code>*object.ReturnValue</code>. That's necessary, because otherwise a <code>return</code> statement would bubble up through several functions and stop the evaluation in all of them. But we only want to stop the evaluation of the last called function's body. That's why we need unwrap it, so that <code>evalBlockStatement</code> won't stop evaluating statements in &quot;outer&quot; functions. I also added a few test cases to our previous <code>TestReturnStatements</code> function to make sure that this works.</p>
<p>Those were the last missing pieces. <em>What? Really?</em> Yeah! Take a look a this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s
$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let addTwo = fn(x) { x + 2; };
&gt;&gt; addTwo(2)
4
&gt;&gt; let multiply = fn(x, y) { x * y };
&gt;&gt; multiply(50 / 2, 1 * 2)
50
&gt;&gt; fn(x) { x == 10 }(5)
false
&gt;&gt; fn(x) { x == 10 }(10)
true</code></pre></div>
<p><em>Whaaat?</em> Yes! It works! We can now finally define and call functions! There's a saying that goes &quot;this is nothing to write home about&quot;. Well, this is! But before we put on our party hats, it's worth taking a closer look at the interaction between functions and their environment and what it means for function application. Because what we've seen is not all we can do, there is a lot more.</p>
<p>So, I bet that one question still bugs you: &quot;Why extend the function's environment and not the current environment?&quot; The short answer is this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestClosures(t *testing.T) {
    input := <span class="st">`</span>
<span class="st">let newAdder = fn(x) {</span>
<span class="st">  fn(y) { x + y };</span>
<span class="st">};</span>

<span class="st">let addTwo = newAdder(2);</span>
<span class="st">addTwo(2);`</span>

    testIntegerObject(t, testEval(input), <span class="dv">4</span>)
}</code></pre></div>
<p>This test passes. Yes, really:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let newAdder = fn(x) { fn(y) { x + y } };
&gt;&gt; let addTwo = newAdder(2);
&gt;&gt; addTwo(3);
5
&gt;&gt; let addThree = newAdder(3);
&gt;&gt; addThree(10);
13</code></pre></div>
<p>Monkey has closures and they already work in our interpreter. How cool is that? Exactly. Very cool. But the connection between closures and the original question might not be so clear yet. Closures are functions that &quot;close over&quot; the environment they were defined in. They carry their own environment around and whenever they're called they can access it.</p>
<p>The two important lines from the example above are these:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> newAdder <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span> <span class="at">fn</span>(y) <span class="op">{</span> x <span class="op">+</span> y <span class="op">}</span> <span class="op">};</span>
<span class="kw">let</span> addTwo <span class="op">=</span> <span class="at">newAdder</span>(<span class="dv">2</span>)<span class="op">;</span></code></pre></div>
<p><code>newAdder</code> here is a higher-order function. Higher-order functions are functions that either return other functions or receive them as arguments. In this case <code>newAdder</code> returns another function. But not just any function: a closure. <code>addTwo</code> is bound to the closure that's returned when calling <code>newAdder</code> with <code>2</code> as the sole argument.</p>
<p>And what makes <code>addTwo</code> a closure? The bindings it has access to when called.</p>
<p>When <code>addTwo</code> is called it not only has access to the arguments of the call, the <code>y</code> parameter, but it can also reach the value <code>x</code> was bound to at the time of the <code>newAdder(2)</code> call, even though that binding is long out of scope and not existent in the current environment anymore:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let newAdder = fn(x) { fn(y) { x + y } };
&gt;&gt; let addTwo = newAdder(2);
&gt;&gt; x
ERROR: identifier not found: x</code></pre></div>
<p><code>x</code> is not bound to a value in our top-level environment. But <code>addTwo</code> still has access to it:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; addTwo(3);
5</code></pre></div>
<p>In other words: the closure <code>addTwo</code> still has access to the environment that was the current environment at the time of its definition. Which is when the last line of <code>newAdder</code>'s body was evaluated. This last line is a function literal. Remember: when function literals are evaluated we build an <code>object.Function</code> and keep a reference to the current environment in its <code>.Env</code> field.</p>
<p>When we later on evaluate the body of <code>addTwo</code>, we don't evaluate it in the current environment, but instead in the function's environment. And we do that by extending the function's environment and passing it to <code>Eval</code> instead of the current environment. Why? So it can still access it. Why? So we can use closures. Why? Because they're freaking amazing and I love them!</p>
<p>And since we're talking about amazing things, it's worth mentioning that we not only support returning functions from other functions but also accepting functions as arguments in a function call. Yes, functions are first-class citizens in Monkey and we can pass them around like any other value:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let add = fn(a, b) { a + b };
&gt;&gt; let sub = fn(a, b) { a - b };
&gt;&gt; let applyFunc = fn(a, b, func) { func(a, b) };
&gt;&gt; applyFunc(2, 2, add);
4
&gt;&gt; applyFunc(10, 2, sub);
8</code></pre></div>
<p>Here we pass the <code>add</code> and <code>sub</code> functions as arguments to <code>applyFunc</code>. <code>applyFunc</code> then calls this function without any problems: the <code>func</code> parameter resolves to the function object which then gets called with two arguments. There is not much more to it, everything works already in our interpreter.</p>
<p>I know what you're thinking right now and here is a template for the message you want to send:</p>
<p><strong>Dear NAME_OF_FRIEND, remember when I said that someday I'll be someone and do something great people will remember me for? Well, today's the day. My Monkey interpreter works and it supports functions, higher-order functions, closures and integers and arithmetic and long story short: I've never been happier in my life!</strong></p>
<p>We did it. We built a fully working Monkey interpreter that supports functions and function calls, higher-order functions and closures. Go on, celebrate! I'll be waiting here.</p>
<h2 id="whos-taking-the-trash-out">3.11 - Who's taking the trash out?</h2>
<p>At the beginning of this book I promised you that we wouldn't take any shortcuts and build a fully functional interpreter with our own hands, from scratch and without any third party tools. And we did! But now I have a small confession to make.</p>
<p>Consider what happens when we run this snippet of Monkey code in our interpreter:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> counter <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span>
  <span class="cf">if</span> (x <span class="op">&gt;</span> <span class="dv">100</span>) <span class="op">{</span>
    <span class="cf">return</span> <span class="kw">true</span><span class="op">;</span>
  <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
    <span class="kw">let</span> foobar <span class="op">=</span> <span class="dv">9999</span><span class="op">;</span>
    <span class="at">counter</span>(x <span class="op">+</span> <span class="dv">1</span>)<span class="op">;</span>
  <span class="op">}</span>
<span class="op">};</span>

<span class="at">counter</span>(<span class="dv">0</span>)<span class="op">;</span></code></pre></div>
<p>Obviously, it would return 'true' after evaluating the body of <code>counter</code> 101 times. But a lot is happening until the last of these recursive calls to <code>counter</code> returns.</p>
<p>The first thing is the evaluation if-else-expression condition: <code>x &gt; 100</code>. If the produced value is not truthy, the alternative of the if-else-expression gets evaluated. In the alternative the integer literal <code>9999</code> gets bound to the name <code>foobar</code>, which is never referenced again. Then <code>x + 1</code> is evaluated. The result of that call to <code>Eval</code> is then passed to another call to <code>counter</code>. And then it all starts again, until <code>x &gt; 100</code> evaluates to <code>TRUE</code>.</p>
<p>The point is this: in each call to <code>counter</code> a lot of objects are allocated. Or to put it in terms of our <code>Eval</code> function and our object system: each evaluation of <code>counter</code>'s body results in a lot of <code>object.Integer</code> being allocated and instantiated. The unused <code>9999</code> integer literal and the result of <code>x + 1</code> are obvious. But even the literals <code>100</code> and <code>1</code> produce new <code>object.Integer</code>s every time the body of <code>counter</code> is evaluated.</p>
<p>If we were to modify our <code>Eval</code> function to track every instance of <code>&amp;object.Integer{}</code>, we'd see that running this small snippet of code results in around 400 allocated <code>object.Integer</code>s.</p>
<p>What's the problem with that?</p>
<p>Our objects are stored in memory. The more objects we use the more memory we need. And even though the number of objects in the example is tiny compared to other programs memory is not infinite.</p>
<p>With each call to <code>counter</code> the memory usage of our interpreter process should rise until it eventually runs out of memory and the operating system kills it. But if we were to monitor memory usage while running the snippet above, we'd see that it doesn't steadily rise and never goes down. Instead it increases and decreases. Why?</p>
<p>The answer to that question is the heart of the confession I have to make: we're reusing Go's garbage collector as a garbage collector for our guest language. We do not need to write our own.</p>
<p>Go's garbage collector (GC) is the reason why we don't run out of memory. It manages memory for us. Even when we call the <code>counter</code> function from above many, many times and thus add a lot more unused integer literals and object allocations, we won't run out of memory. Because the GC keeps track of which <code>object.Integer</code> are still reachable by us and which are not. When it notices that an object is not reachable anymore it makes the object's memory available again.</p>
<p>The example above generates a lot of integer objects that are unreachable after a call to <code>counter</code>: the literals <code>1</code> and <code>100</code> and the nonsense <code>9999</code> bound to <code>foobar</code>. There is no way to access these objects after <code>counter</code> returns. In the case of <code>1</code> and <code>100</code> it's clear that they're unreachable, since they're not bound to a name. But even the <code>9999</code> bound to <code>foobar</code> is unreachable since <code>foobar</code> is out of scope when the function returns. The environment that was constructed for the evaluation of <code>counter</code>'s body gets destroyed (also by Go's GC, mind you!) and with it the <code>foobar</code> binding.</p>
<p>These unreachable objects are useless and take up memory. That's why the GC collects them and frees up the memory they used.</p>
<p>And that's super handy for us! That saves us a lot of work! If we were to write our interpreter in a language like C, where we don't have a GC, we'd need to implement one ourselves to manage memory for users of the interpreter.</p>
<p>What would such a hypothetical GC need to do? In short: keep track of object allocations and references to objects, make enough memory available for future object allocations and give memory back when it's not needed anymore. This last point is what garbage collection is all about. Without it the programs would &quot;leak&quot; and finally run out of memory.</p>
<p>There are a myriad ways to accomplish all of the above, involving different algorithms and implementations. For example, there's the basic &quot;mark and sweep&quot; algorithm. In order to implement it one has to decide whether the GC will be a generational GC or not, or whether it's a stop-the-world GC or a concurrent GC, or how it's organizing memory and handling memory fragmentation. Having decided all of that an efficient implementation is still a lot of hard work.</p>
<p>But maybe you're asking yourself: <em>Okay, so we have the GC of Go available. But can't we just write our own GC for the guest language and use that one instead?</em></p>
<p>Unfortunately, no. We'd have to disable Go's GC and find a way to take over all of its duties. That's easier said than done. It's a huge undertaking since we would also have to take care of allocating and freeing memory ourselves - in a language that per default prohibits exactly that.</p>
<p>That's why I decided to not add a &quot;Let's write our own GC next to Go's GC&quot; section to this book and to instead reuse Go's GC. Garbage collection itself is a huge topic and adding the dimension of working around an existing GC blows it out of the scope of this book. But still, I hope that this section gave you a rough idea of what a GC does and which problems it solves. Maybe you even know now what to do if you were to translate the interpreter we built here into another host language without garbage collection.</p>
<p>And with that... we're done! Our interpreter works. All that's left for us is to extend it and make it more useful by adding more data types and functions.</p>
<h1 id="extending-the-interpreter">Extending the Interpreter</h1>
<h2 id="data-types-functions">4.1 - Data Types &amp; Functions</h2>
<p>Even though our interpreter works amazingly well and has some mind-blowing features, like first-class functions and closures, the only data types we had available as users of Monkey were integers and booleans. That's not especially useful and a lot less than what we're used to from other programming languages. In this chapter we're going to change that. We're going to add new data types to our interpreter.</p>
<p>The great thing about this endeavor is that it takes us through the whole interpreter again. We will add new token types, modify the lexer, extend the parser and finally add support for the data types to our evaluator and the object system.</p>
<p>Even better is that the data types we're going to add are already present in Go. That means that we only need to make them available in Monkey. We don't need to implement them from scratch, which is pretty handy, since this book isn't called &quot;Implementing Common Data Structures In Go&quot; and we can concentrate on our interpreter.</p>
<p>In addition to that we're also going to make the interpreter much more powerful by adding some new functions. Of course, as users of our interpreter we could define functions ourselves just fine, but those were limited in what they could do. These new ones, called built-in functions, will be much more powerful, since they have access to the inner workings of the Monkey programming language.</p>
<p>The first thing we're going to do is add a data type we all know: the string. Nearly every programming language has it and Monkey shall have it too.</p>
<h2 id="strings">4.2 - Strings</h2>
<p>In Monkey strings are a sequence of characters. They are first-class values, can be bound to identifiers, used as arguments in functions calls and be returned by functions. They look just like the strings in many other programming languages: characters enclosed by double quotes.</p>
<p>Besides the data type itself, in this section we'll also add support for string concatenation by supporting the infix operator <code>+</code> for strings.</p>
<p>At the end, we'll be able to do this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is micro, your own programming language!
Feel free to type in commands
&gt;&gt; let firstName = &quot;Thorsten&quot;;
&gt;&gt; let lastName = &quot;Ball&quot;;
&gt;&gt; let fullName = fn(first, last) { first + &quot; &quot; + last };
&gt;&gt; fullName(firstName, lastName);
Thorsten Ball</code></pre></div>
<h3 id="supporting-strings-in-our-lexer">Supporting Strings in our Lexer</h3>
<p>The first thing we have to do is add support for string literals to our lexer. The basic structure of strings is this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&quot;&lt;sequence of characters&gt;&quot;</code></pre></div>
<p>That's not too hard, right? A sequence of characters enclosed by double quotes.</p>
<p>What we want from our lexer is a single token for each string literal. So in the case of <code>&quot;Hello World&quot;</code> we want a single token, instead of tokens for <code>&quot;</code>, <code>Hello</code>, <code>World</code> and <code>&quot;</code>. A single token for string literals makes handling them in our parser a lot easier and we move the bulk of the work to one small method in the lexer.</p>
<p>Of course, the approach using multiple tokens is also valid and maybe beneficial in some cases/parsers. We could use <code>&quot;</code> surrounding <code>token.IDENT</code> tokens. But in our case, we'll mirror the <code>token.INT</code> integer tokens we already have and carry the string literal itself around in the <code>.Literal</code> field of the token.</p>
<p>And with that being clear, it's time to work on our tokens and our lexer again. We haven't touched those since the first chapter, but I'm sure we'll do just fine.</p>
<p>The first thing we need to do is add a new <code>STRING</code> token type to our <code>token</code> package:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    STRING = <span class="st">&quot;STRING&quot;</span>
<span class="co">// [...]</span>
)</code></pre></div>
<p>With that in place we can add a test case for our lexer to see if strings are properly supported. To do that we just extend the <code>input</code> in our <code>TestNextToken</code> test function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>

<span class="st">if (5 &lt; 10) {</span>
<span class="st">    return true;</span>
<span class="st">} else {</span>
<span class="st">    return false;</span>
<span class="st">}</span>

<span class="st">10 == 10;</span>
<span class="st">10 != 9;</span>
<span class="st">&quot;foobar&quot;</span>
<span class="st">&quot;foo bar&quot;</span>
<span class="st">`</span>

    tests := []<span class="kw">struct</span> {
        expectedType    token.TokenType
        expectedLiteral <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {token.STRING, <span class="st">&quot;foobar&quot;</span>},
        {token.STRING, <span class="st">&quot;foo bar&quot;</span>},
        {token.EOF, <span class="st">&quot;&quot;</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>The <code>input</code> now has two more lines containing the string literals we want to turn into tokens. There's <code>&quot;foobar&quot;</code> to make sure that lexing of string literals works and <code>&quot;foo bar&quot;</code> to make sure that it still works even with whitespace inside a literal.</p>
<p>Of course, the tests fail, because we haven't changed anything in the <code>Lexer</code> yet:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
--- FAIL: TestNextToken (0.00s)
  lexer_test.go:122: tests[73] - tokentype wrong. expected=&quot;STRING&quot;,\
    got=&quot;ILLEGAL&quot;
FAIL
FAIL    monkey/lexer    0.006s</code></pre></div>
<p>Fixing the tests is easier than you might think. All we need to do is add a <code>case</code> branch for <code>&quot;</code> to the switch statement in our <code>Lexer</code> and add a small helper method:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
<span class="co">// [...]</span>

    <span class="kw">switch</span> l.ch {
<span class="co">// [...]</span>
    <span class="kw">case</span> &#39;<span class="st">&quot;&#39;:</span>
        tok.Type = token.STRING
        tok.Literal = l.readString()
<span class="co">// [...]</span>
    }

<span class="co">// [...]</span>
}

<span class="kw">func</span> (l *Lexer) readString() <span class="dt">string</span> {
    position := l.position + <span class="dv">1</span>
    <span class="kw">for</span> {
        l.readChar()
        <span class="kw">if</span> l.ch == &#39;<span class="st">&quot;&#39; || l.ch == 0 {</span>
            <span class="kw">break</span>
        }
    }
    <span class="kw">return</span> l.input[position:l.position]
}</code></pre></div>
<p>There's really nothing mysterious about these changes. A new <code>case</code> branch and a helper function called <code>readString</code> that calls <code>readChar</code> until it encounters either a closing double quote or the end of the input.</p>
<p>If you think that this is too easy, feel free to make <code>readString</code> report an error instead of simply returning when it reaches the end of the input. Or you can add support for character escaping so that string literals like <code>&quot;hello \&quot;world\&quot;&quot;</code>, <code>&quot;hello\n world&quot;</code> and <code>&quot;hello\t\t\tworld&quot;</code> work.</p>
<p>Meanwhile, our tests are passing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer    0.006s</code></pre></div>
<p>Great! Our lexer now knows how to handle string literals. It's time to teach the parser how to do the same.</p>
<h3 id="parsing-strings">Parsing Strings</h3>
<p>In order for our parser to turn <code>token.STRING</code> into a string literal AST node we need to define said node. Thankfully the definition couldn't be simpler. It looks really similar to <code>ast.IntegerLiteral</code>, except that the <code>Value</code> field now contains a <code>string</code> instead of an <code>int64</code>.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> StringLiteral <span class="kw">struct</span> {
    Token token.Token
    Value <span class="dt">string</span>
}

<span class="kw">func</span> (sl *StringLiteral) expressionNode()      {}
<span class="kw">func</span> (sl *StringLiteral) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> sl.Token.Literal }
<span class="kw">func</span> (sl *StringLiteral) String() <span class="dt">string</span>       { <span class="kw">return</span> sl.Token.Literal }</code></pre></div>
<p>Of course, string literals are expressions and not statements. They evaluate to the string.</p>
<p>With that definition we can write a small test case that makes sure the parser knows how to handle <code>token.STRING</code> tokens and outputs <code>*ast.StringLiteral</code>s:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestStringLiteralExpression(t *testing.T) {
    input := <span class="st">`&quot;hello world&quot;;`</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    literal, ok := stmt.Expression.(*ast.StringLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp not *ast.StringLiteral. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> literal.Value != <span class="st">&quot;hello world&quot;</span> {
        t.Errorf(<span class="st">&quot;literal.Value not %q. got=%q&quot;</span>, <span class="st">&quot;hello world&quot;</span>, literal.Value)
    }
}</code></pre></div>
<p>Running the tests results in a well known type of parser error:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestStringLiteralExpression (0.00s)
  parser_test.go:888: parser has 1 errors
  parser_test.go:890: parser error: &quot;no prefix parse function for STRING found&quot;
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>We've seen that many times before and we know how to fix it. All we have to do is register a new <code>prefixParseFn</code> for <code>token.STRING</code> tokens. This parse function then returns an <code>*ast.StringLiteral</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.STRING, p.parseStringLiteral)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseStringLiteral() ast.Expression {
    <span class="kw">return</span> &amp;ast.StringLiteral{Token: p.curToken, Value: p.curToken.Literal}
}</code></pre></div>
<p>Three new lines! That's all it takes to make the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>So now our lexer turns string literals into <code>token.STRING</code> tokens and the parser turns those into <code>*ast.StringLiteral</code> nodes. We're now ready to make changes to our object system and the evaluator.</p>
<h3 id="evaluating-strings">Evaluating Strings</h3>
<p>Representing a string in our object system is as easy as representing integers. And the biggest reason why it's so easy is that we reuse Go's <code>string</code> data type. Imagine adding a data type to the guest language that can't be represented with built-in data structures of the host language. E.g.: strings in C. That's a lot more work. But instead, all we have to do is define a new object that holds a string:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    STRING_OBJ = <span class="st">&quot;STRING&quot;</span>
)

<span class="kw">type</span> String <span class="kw">struct</span> {
    Value <span class="dt">string</span>
}

<span class="kw">func</span> (s *String) Type() ObjectType { <span class="kw">return</span> STRING_OBJ }
<span class="kw">func</span> (s *String) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> s.Value }</code></pre></div>
<p>Now we need to extend our evaluator so it turns <code>*ast.StringLiteral</code> in <code>object.String</code> objects. The test to make sure that this works is tiny:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestStringLiteral(t *testing.T) {
    input := <span class="st">`&quot;Hello World!&quot;`</span>

    evaluated := testEval(input)
    str, ok := evaluated.(*object.String)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;object is not String. got=%T (%+v)&quot;</span>, evaluated, evaluated)
    }

    <span class="kw">if</span> str.Value != <span class="st">&quot;Hello World!&quot;</span> {
        t.Errorf(<span class="st">&quot;String has wrong value. got=%q&quot;</span>, str.Value)
    }
}</code></pre></div>
<p>The call to <code>Eval</code> doesn't return an <code>*object.String</code> yet but <code>nil</code>:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestStringLiteral (0.00s)
  evaluator_test.go:317: object is not String. got=&lt;nil&gt; (&lt;nil&gt;)
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>Getting this test to pass needs even fewer lines than in the parser. Just two:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>

    <span class="kw">case</span> *ast.StringLiteral:
        <span class="kw">return</span> &amp;object.String{Value: node.Value}

<span class="co">// [...]</span>
}</code></pre></div>
<p>That makes the tests pass and we can now use strings in our REPL:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; &quot;Hello world!&quot;
Hello world!
&gt;&gt; let hello = &quot;Hello there, fellow Monkey users and fans!&quot;
&gt;&gt; hello
Hello there, fellow Monkey users and fans!
&gt;&gt; let giveMeHello = fn() { &quot;Hello!&quot; }
&gt;&gt; giveMeHello()
Hello!</code></pre></div>
<p>We now have full support for strings in our interpreter! Sweet! Or should I say...</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; &quot;This is amazing!&quot;
This is amazing!</code></pre></div>
<h3 id="string-concatenation">String Concatenation</h3>
<p>Having the string data type available is great. But we can't do much with strings yet, besides creating them. Let's change that! In this section we're going to add string concatenation to our interpreter. And we'll do that by adding support for the <code>+</code> infix operator with string operands.</p>
<p>What we want is perfectly described by this test:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestStringConcatenation(t *testing.T) {
    input := <span class="st">`&quot;Hello&quot; + &quot; &quot; + &quot;World!&quot;`</span>

    evaluated := testEval(input)
    str, ok := evaluated.(*object.String)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;object is not String. got=%T (%+v)&quot;</span>, evaluated, evaluated)
    }

    <span class="kw">if</span> str.Value != <span class="st">&quot;Hello World!&quot;</span> {
        t.Errorf(<span class="st">&quot;String has wrong value. got=%q&quot;</span>, str.Value)
    }
}</code></pre></div>
<p>We can also extend our <code>TestErrorHandling</code> function to make sure that we only add support for the <code>+</code> operator and nothing more:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestErrorHandling(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input           <span class="dt">string</span>
        expectedMessage <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">`&quot;Hello&quot; - &quot;World&quot;`</span>,
            <span class="st">&quot;unknown operator: STRING - STRING&quot;</span>,
        },
<span class="co">// [...]</span>
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>This test case is already green and acts more as specification and regression testing than as a guide for an implementation. But our concatenation test is failing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestStringConcatenation (0.00s)
  evaluator_test.go:336: object is not String. got=*object.Error\
    (&amp;{Message:unknown operator: STRING + STRING})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>The place where we need to make changes is <code>evalInfixExpression</code>. Here we need to add a new branch to the existing switch statement that's evaluated when both operands are strings:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    <span class="kw">switch</span> {
<span class="co">// [...]</span>
    <span class="kw">case</span> left.Type() == object.STRING_OBJ &amp;&amp; right.Type() == object.STRING_OBJ:
        <span class="kw">return</span> evalStringInfixExpression(operator, left, right)
<span class="co">// [...]</span>
    }
}</code></pre></div>
<p>The <code>evalStringInfixExpression</code> is the most minimal implementation possible:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalStringInfixExpression(
    operator <span class="dt">string</span>,
    left, right object.Object,
) object.Object {
    <span class="kw">if</span> operator != <span class="st">&quot;+&quot;</span> {
        <span class="kw">return</span> newError(<span class="st">&quot;unknown operator: %s %s %s&quot;</span>,
            left.Type(), operator, right.Type())
    }

    leftVal := left.(*object.String).Value
    rightVal := right.(*object.String).Value
    <span class="kw">return</span> &amp;object.String{Value: leftVal + rightVal}
}</code></pre></div>
<p>The first thing here is the check for the correct operator. If it's the supported <code>+</code> we unwrap the string objects and construct a new string that's a concatenation of both operands.</p>
<p>If we want to support more operators for strings this is the place where to add them. Also, if we want to support comparison of strings with the <code>==</code> and <code>!=</code> we'd need to add this here too. Pointer comparison doesn't work for strings, at least not in the way we want it to: with strings we want to compare values and not pointers.</p>
<p>And that's it! Our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>We can now use string literals, pass them around, bind them to names, return them from functions and also concatenate them:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let makeGreeter = fn(greeting) { fn(name) { greeting + &quot; &quot; + name + &quot;!&quot; } };
&gt;&gt; let hello = makeGreeter(&quot;Hello&quot;);
&gt;&gt; hello(&quot;Thorsten&quot;);
Hello Thorsten!
&gt;&gt; let heythere = makeGreeter(&quot;Hey there&quot;);
&gt;&gt; heythere(&quot;Thorsten&quot;);
Hey there Thorsten!</code></pre></div>
<p>Alright! I'd say strings are now working very well in our interpreter. But we can still add something else to work with them...</p>
<h2 id="built-in-functions">4.3 - Built-in Functions</h2>
<p>In this section we're going to add built-in functions to our interpreter. They're called &quot;built-in&quot;, because they're not defined by a user of the interpreter and they're not Monkey code - they are built right into the interpreter, into the language itself.</p>
<p>These built-in functions are defined by us, in Go, and bridge the world of Monkey with the world of our interpreter implementation. A lot of language implementations provide such functions to offer functionality to the language's user that's not provided &quot;inside&quot; the language.</p>
<p>Here's an example: a function that returns the current time. In order to get the current time one could ask the kernel (or another computer, etc.). Asking and talking to the kernel is normally done via something called system calls. But if the programming language doesn't offer users to make such system calls themselves, then the language implementation, be it the compiler or the interpreter, has to provide something to make these system calls on behalf of the users instead.</p>
<p>So, again, the built-in functions we're going to add are defined by us, the implementers of the interpreter. The user of the interpreter can call them, but we define them. What these functions can do, we leave open. The only restriction they have is that they need to accept zero or more <code>object.Object</code> as arguments and return an <code>object.Object</code>.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">type</span> BuiltinFunction <span class="kw">func</span>(args ...Object) Object</code></pre></div>
<p>That's the type definition of a callable Go function. But since we need to make these <code>BuiltinFunction</code>s available to our users we need to fit them into our object system. We do that by wrapping them:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    BUILTIN_OBJ = <span class="st">&quot;BUILTIN&quot;</span>
)

<span class="kw">type</span> Builtin <span class="kw">struct</span> {
    Fn BuiltinFunction
}

<span class="kw">func</span> (b *Builtin) Type() ObjectType { <span class="kw">return</span> BUILTIN_OBJ }
<span class="kw">func</span> (b *Builtin) Inspect() <span class="dt">string</span>  { <span class="kw">return</span> <span class="st">&quot;builtin function&quot;</span> }</code></pre></div>
<p>There's not much to <code>object.Builtin</code>, as you can see. It's clearly just a wrapper. But in combination with <code>object.BuiltinFunction</code> it's enough to get us started.</p>
<h3 id="len">len</h3>
<p>The first built-in function we're going to add to our interpreter is <code>len</code>. Its job is to return the number of characters in a string. It's impossible to define this function as a user of Monkey. That's why we need it to be built-in. What we want from <code>len</code> is this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; len(&quot;Hello World!&quot;)
12
&gt;&gt; len(&quot;&quot;)
0
&gt;&gt; len(&quot;Hey Bob, how ya doin?&quot;)
21</code></pre></div>
<p>I think that makes the idea behind <code>len</code> pretty clear. So clear in fact, that we can easily write a test for it:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestBuiltinFunctions(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="kw">interface</span>{}
    }{
        {<span class="st">`len(&quot;&quot;)`</span>, <span class="dv">0</span>},
        {<span class="st">`len(&quot;four&quot;)`</span>, <span class="dv">4</span>},
        {<span class="st">`len(&quot;hello world&quot;)`</span>, <span class="dv">11</span>},
        {<span class="st">`len(1)`</span>, <span class="st">&quot;argument to `len` not supported, got INTEGER&quot;</span>},
        {<span class="st">`len(&quot;one&quot;, &quot;two&quot;)`</span>, <span class="st">&quot;wrong number of arguments. got=2, want=1&quot;</span>},
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)

        <span class="kw">switch</span> expected := tt.expected.(<span class="kw">type</span>) {
        <span class="kw">case</span> <span class="dt">int</span>:
            testIntegerObject(t, evaluated, <span class="dt">int64</span>(expected))
        <span class="kw">case</span> <span class="dt">string</span>:
            errObj, ok := evaluated.(*object.Error)
            <span class="kw">if</span> !ok {
                t.Errorf(<span class="st">&quot;object is not Error. got=%T (%+v)&quot;</span>,
                    evaluated, evaluated)
                <span class="kw">continue</span>
            }
            <span class="kw">if</span> errObj.Message != expected {
                t.Errorf(<span class="st">&quot;wrong error message. expected=%q, got=%q&quot;</span>,
                    expected, errObj.Message)
            }
        }
    }
}</code></pre></div>
<p>So here we have a few test cases that run <code>len</code> through its paces: an empty string, a normal string and a string containing whitespace. It really shouldn't matter if there's whitespace in the string, but you'll never know, so I put the test case in. The last two test cases are more interesting: we want to make sure that <code>len</code> returns an <code>*object.Error</code> when called with an integer or with the wrong number of arguments.</p>
<p>If we run the tests we can see that calling <code>len</code> gives us an error, but not the one expected in our test case:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestBuiltinFunctions (0.00s)
  evaluator_test.go:389: object is not Integer. got=*object.Error\
    (&amp;{Message:identifier not found: len})
  evaluator_test.go:389: object is not Integer. got=*object.Error\
    (&amp;{Message:identifier not found: len})
  evaluator_test.go:389: object is not Integer. got=*object.Error\
    (&amp;{Message:identifier not found: len})
  evaluator_test.go:371: wrong error message.\
    expected=&quot;argument to `len` not supported, got INTEGER&quot;,\
    got=&quot;identifier not found: len&quot;
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p><code>len</code> can't be found, which isn't that baffling considering that we haven't defined it yet.</p>
<p>In order to do that, the first thing we have to do is provide a way for built-in functions to be found. One option is to add them to the top-level <code>object.Environment</code>, that gets passed into <code>Eval</code>. But instead we're going to keep a separate environment of built-in functions:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">package</span> evaluator

<span class="kw">import</span> <span class="st">&quot;monkey/object&quot;</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
    <span class="st">&quot;len&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">return</span> NULL
        },
    },
}</code></pre></div>
<p>In order to make use of that, we need to edit our <code>evalIdentifier</code> function to lookup built-in functions as a fallback when the given identifier is not bound to a value in the current environment:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalIdentifier(
    node *ast.Identifier,
    env *object.Environment,
) object.Object {
    <span class="kw">if</span> val, ok := env.Get(node.Value); ok {
        <span class="kw">return</span> val
    }

    <span class="kw">if</span> builtin, ok := builtins[node.Value]; ok {
        <span class="kw">return</span> builtin
    }

    <span class="kw">return</span> newError(<span class="st">&quot;identifier not found: &quot;</span> + node.Value)
}</code></pre></div>
<p>So now <code>len</code> is found when looking up the <code>len</code> identifier, calling it doesn't work yet:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; len()
ERROR: not a function: BUILTIN
&gt;&gt;</code></pre></div>
<p>Running the tests gives us the same error. We need to teach our <code>applyFunction</code> about <code>*object.Builtin</code> and <code>object.BuiltinFunction</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> applyFunction(fn object.Object, args []object.Object) object.Object {
    <span class="kw">switch</span> fn := fn.(<span class="kw">type</span>) {

    <span class="kw">case</span> *object.Function:
        extendedEnv := extendFunctionEnv(fn, args)
        evaluated := Eval(fn.Body, extendedEnv)
        <span class="kw">return</span> unwrapReturnValue(evaluated)

    <span class="kw">case</span> *object.Builtin:
        <span class="kw">return</span> fn.Fn(args...)

    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;not a function: %s&quot;</span>, fn.Type())
    }
}</code></pre></div>
<p>Besides moving the existing lines around, what changed here is the addition of the <code>case *object.Builtin</code> branch, in which we call the <code>object.BuiltinFunction</code>. Doing so is as easy as using the <code>args</code> slice as arguments and calling the function.</p>
<p>Of note is that we don't need to <code>unwrapReturnValue</code> when calling a built-in function. That's because we never return an <code>*object.ReturnValue</code> from these functions.</p>
<p>Now the tests are rightfully complaining about <code>NULL</code> being returned when calling <code>len</code>:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestBuiltinFunctions (0.00s)
  evaluator_test.go:389: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:389: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:389: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:366: object is not Error. got=*object.Null (&amp;{})
  evaluator_test.go:366: object is not Error. got=*object.Null (&amp;{})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>That means that calling <code>len</code> works though! It's just that it returns only <code>NULL</code>. But fixing this is as easy as writing any other Go function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">import</span> (
    <span class="st">&quot;monkey/object&quot;</span>
    <span class="st">&quot;unicode/utf8&quot;</span>
)

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
    <span class="st">&quot;len&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">1</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=1&quot;</span>,
                    <span class="bu">len</span>(args))
            }

            <span class="kw">switch</span> arg := args[<span class="dv">0</span>].(<span class="kw">type</span>) {
            <span class="kw">case</span> *object.String:
                <span class="kw">return</span> &amp;object.Integer{Value: <span class="dt">int64</span>(<span class="bu">len</span>(arg.Value))}
            <span class="kw">default</span>:
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `len` not supported, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }
        },
    },
}</code></pre></div>
<p>The most important part of this function is the call to Go's <code>len</code> and the returning of a newly allocated <code>object.Integer</code>. Besides that we have error checking that makes sure that we can't call this function with the wrong number of arguments or with an argument of an unsupported type. And alas, our tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>That means we can take <code>len</code> on a test drive in our REPL:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; len(&quot;1234&quot;)
4
&gt;&gt; len(&quot;Hello World!&quot;)
12
&gt;&gt; len(&quot;Woooooohooo!&quot;, &quot;len works!!&quot;)
ERROR: wrong number of arguments. got=2, want=1
&gt;&gt; len(12345)
ERROR: argument to `len` not supported, got INTEGER</code></pre></div>
<p>Perfect! Our first built-in function works and is ready to go.</p>
<h2 id="array">4.4 - Array</h2>
<p>The data type we're going to add to our Monkey interpreter in this section is the array. In Monkey an array is an ordered list of elements of possibly different types. Each element in the array can be accessed individually. Arrays are constructed by using their literal form: a comma separated list of elements, enclosed by brackets.</p>
<p>Initializing a new array, binding it to a name and accessing individual elements will look like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> myArray <span class="op">=</span> [<span class="st">&quot;Thorsten&quot;</span><span class="op">,</span> <span class="st">&quot;Ball&quot;</span><span class="op">,</span> <span class="dv">28</span><span class="op">,</span> <span class="at">fn</span>(x) <span class="op">{</span> x <span class="op">*</span> x <span class="op">}</span>]<span class="op">;</span>
<span class="op">&gt;&gt;</span> myArray[<span class="dv">0</span>]
Thorsten
<span class="op">&gt;&gt;</span> myArray[<span class="dv">2</span>]
<span class="dv">28</span>
<span class="op">&gt;&gt;</span> myArray[<span class="dv">3</span>](<span class="dv">2</span>)<span class="op">;</span>
<span class="dv">4</span></code></pre></div>
<p>As you can see, Monkey arrays really don't care about the types of their elements. Every possible value in Monkey can be an element in an array. In this example <code>myArray</code> holds two strings, an integer and a function.</p>
<p>Accessing individual elements by their index in the array, as seen in the last three lines, is done with a new operator, called the index operator: <code>array[index]</code>.</p>
<p>In this section we'll also add support for arrays to our newly added <code>len</code> function and also add a few more built-in functions that work with arrays:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> myArray <span class="op">=</span> [<span class="st">&quot;one&quot;</span><span class="op">,</span> <span class="st">&quot;two&quot;</span><span class="op">,</span> <span class="st">&quot;three&quot;</span>]<span class="op">;</span>
<span class="op">&gt;&gt;</span> <span class="at">len</span>(myArray)
<span class="dv">3</span>
<span class="op">&gt;&gt;</span> <span class="at">first</span>(myArray)
one
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(myArray)
[two<span class="op">,</span> three]
<span class="op">&gt;&gt;</span> <span class="at">last</span>(myArray)
three
<span class="op">&gt;&gt;</span> <span class="at">push</span>(myArray<span class="op">,</span> <span class="st">&quot;four&quot;</span>)
[one<span class="op">,</span> two<span class="op">,</span> three<span class="op">,</span> four]</code></pre></div>
<p>The basis for our implementation of the Monkey array in our interpreter will be a Go slice of type <code>[]object.Object</code>. That means that we don't have to implement a new data structure. We can just reuse Go's slice.</p>
<p>Sounds awesome? Good! The first thing we have to do is teach our lexer a few new tokens.</p>
<h3 id="supporting-arrays-in-our-lexer">Supporting Arrays in our Lexer</h3>
<p>In order to correctly parse array literals and the index operator, our lexer needs to be able to identify more tokens than it currently does. All the tokens we need in order to construct and use arrays in Monkey are <code>[</code>, <code>]</code> and <code>,</code>. The lexer already knows about <code>,</code> so we only need to add support for <code>[</code> and <code>]</code>.</p>
<p>The first step is to define these new token types in the <code>token</code> package:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>

    LBRACKET = <span class="st">&quot;[&quot;</span>
    RBRACKET = <span class="st">&quot;]&quot;</span>

<span class="co">// [...]</span>
)</code></pre></div>
<p>The second step is to extend the test suite of the lexer, which is easy, since we've done this many times before:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>

<span class="st">if (5 &lt; 10) {</span>
<span class="st">    return true;</span>
<span class="st">} else {</span>
<span class="st">    return false;</span>
<span class="st">}</span>

<span class="st">10 == 10;</span>
<span class="st">10 != 9;</span>
<span class="st">&quot;foobar&quot;</span>
<span class="st">&quot;foo bar&quot;</span>
<span class="st">[1, 2];</span>
<span class="st">`</span>

    tests := []<span class="kw">struct</span> {
        expectedType    token.TokenType
        expectedLiteral <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {token.LBRACKET, <span class="st">&quot;[&quot;</span>},
        {token.INT, <span class="st">&quot;1&quot;</span>},
        {token.COMMA, <span class="st">&quot;,&quot;</span>},
        {token.INT, <span class="st">&quot;2&quot;</span>},
        {token.RBRACKET, <span class="st">&quot;]&quot;</span>},
        {token.SEMICOLON, <span class="st">&quot;;&quot;</span>},
        {token.EOF, <span class="st">&quot;&quot;</span>},
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>Again the <code>input</code> is extended to include new tokens (<code>[1, 2]</code> in this case) and new <code>tests</code> have been added to make sure the lexer's <code>NextToken</code> method really returns <code>token.LBRACKET</code> and <code>token.RBRACKET</code>.</p>
<p>Making the test pass is as easy as adding these <em>four</em> lines to our <code>NextToken()</code> method. Yes, just four:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
<span class="co">// [...]</span>

    <span class="kw">case</span> &#39;[&#39;:
        tok = newToken(token.LBRACKET, l.ch)
    <span class="kw">case</span> &#39;]&#39;:
        tok = newToken(token.RBRACKET, l.ch)

<span class="co">// [...]</span>
}</code></pre></div>
<p>Alright! The tests are passing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer    0.006s</code></pre></div>
<p>In our parser we'll now use <code>token.LBRACKET</code> and <code>token.RBRACKET</code> to parse arrays.</p>
<h3 id="parsing-array-literals">Parsing Array Literals</h3>
<p>As we saw before, an array literal in Monkey is a comma-separated list of expressions enclosed by an opening and a closing bracket.</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">[<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span> <span class="op">+</span> <span class="dv">3</span><span class="op">,</span> <span class="at">fn</span>(x) <span class="op">{</span> x <span class="op">},</span> <span class="at">add</span>(<span class="dv">2</span><span class="op">,</span> <span class="dv">2</span>)]</code></pre></div>
<p>Yes, the elements in an array literal can be any type of expression. Integer literals, function literals, infix or prefix expressions.</p>
<p>If that sounds complicated, don't worry. We already know how to parse comma-separated lists of expressions - function call arguments are just that. And we also know how to parse something enclosed by matching tokens. In other words: let's get to it!</p>
<p>The first thing we have to do is define the AST node for array literals. Since we already have the essential pieces in place for this, the definition is rather self-explanatory:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> ArrayLiteral <span class="kw">struct</span> {
    Token    token.Token <span class="co">// the &#39;[&#39; token</span>
    Elements []Expression
}

<span class="kw">func</span> (al *ArrayLiteral) expressionNode()      {}
<span class="kw">func</span> (al *ArrayLiteral) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> al.Token.Literal }
<span class="kw">func</span> (al *ArrayLiteral) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    elements := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, el := <span class="kw">range</span> al.Elements {
        elements = <span class="bu">append</span>(elements, el.String())
    }

    out.WriteString(<span class="st">&quot;[&quot;</span>)
    out.WriteString(strings.Join(elements, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;]&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>The following test function makes sure that parsing array literals results in a <code>*ast.ArrayLiteral</code> being returned. (I also added a test function for empty array literals to make sure that we don't run into nasty edge-cases)</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingArrayLiterals(t *testing.T) {
    input := <span class="st">&quot;[1, 2 * 2, 3 + 3]&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    array, ok := stmt.Expression.(*ast.ArrayLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp not ast.ArrayLiteral. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> <span class="bu">len</span>(array.Elements) != <span class="dv">3</span> {
        t.Fatalf(<span class="st">&quot;len(array.Elements) not 3. got=%d&quot;</span>, <span class="bu">len</span>(array.Elements))
    }

    testIntegerLiteral(t, array.Elements[<span class="dv">0</span>], <span class="dv">1</span>)
    testInfixExpression(t, array.Elements[<span class="dv">1</span>], <span class="dv">2</span>, <span class="st">&quot;*&quot;</span>, <span class="dv">2</span>)
    testInfixExpression(t, array.Elements[<span class="dv">2</span>], <span class="dv">3</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">3</span>)
}</code></pre></div>
<p>Just to make sure that the parsing of expressions really works the test input contains two different infix operator expressions, even though integer or boolean literals would be enough. Other than that the test is pretty boring and asserts that the parser really returns an <code>*ast.ArrayLiteral</code> with the correct number of elements.</p>
<p>In order to get the tests to pass we need to register a new <code>prefixParseFn</code> in our parser, since the opening <code>token.LBRACKET</code> of an array literal is in prefix position.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>

    p.registerPrefix(token.LBRACKET, p.parseArrayLiteral)

<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseArrayLiteral() ast.Expression {
    array := &amp;ast.ArrayLiteral{Token: p.curToken}

    array.Elements = p.parseExpressionList(token.RBRACKET)

    <span class="kw">return</span> array
}</code></pre></div>
<p>We've added <code>prefixParseFn</code>s before, so that part's not really exciting. What's interesting here is the new method called <code>parseExpressionList</code>. This method is a modified and generalized version of <code>parseCallArguments</code>, which we used before in <code>parseCallExpression</code> to parse a list of comma separated arguments:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseExpressionList(end token.TokenType) []ast.Expression {
    list := []ast.Expression{}

    <span class="kw">if</span> p.peekTokenIs(end) {
        p.nextToken()
        <span class="kw">return</span> list
    }

    p.nextToken()
    list = <span class="bu">append</span>(list, p.parseExpression(LOWEST))

    <span class="kw">for</span> p.peekTokenIs(token.COMMA) {
        p.nextToken()
        p.nextToken()
        list = <span class="bu">append</span>(list, p.parseExpression(LOWEST))
    }

    <span class="kw">if</span> !p.expectPeek(end) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> list
}</code></pre></div>
<p>Again, we've seen this before under the name <code>parseCallArguments</code>. The only change is that this new version now accepts an <code>end</code> parameter that tells the method which token signifies the end of the list. The updated <code>parseCallExpression</code> method, in which we used <code>parseCallArguments</code> before, now looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> (p *Parser) parseCallExpression(function ast.Expression) ast.Expression {
    exp := &amp;ast.CallExpression{Token: p.curToken, Function: function}
    exp.Arguments = p.parseExpressionList(token.RPAREN)
    <span class="kw">return</span> exp
}</code></pre></div>
<p>The only change is the call to <code>parseExpressionList</code> with <code>token.RPAREN</code> (which signifies the end of the arguments list). We could reuse a relatively big method by changing a few lines. Great! And the best of all? The tests are passing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>We can mark &quot;parsing array literals&quot; as &quot;done&quot;.</p>
<h3 id="parsing-index-operator-expressions">Parsing Index Operator Expressions</h3>
<p>To fully support arrays in Monkey we not only need to be able to parse array literals but also index operator expressions. Maybe the name &quot;index operator&quot; doesn't ring a bell, but I bet you know what it is. Index operator expressions look like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">myArray[<span class="dv">0</span>]<span class="op">;</span>
myArray[<span class="dv">1</span>]<span class="op">;</span>
myArray[<span class="dv">2</span>]<span class="op">;</span></code></pre></div>
<p>That's the basic form at least, but there are many. Take a look at these examples to spot the structure underlying them all:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">[<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>][<span class="dv">2</span>]<span class="op">;</span>

<span class="kw">let</span> myArray <span class="op">=</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]<span class="op">;</span>
myArray[<span class="dv">2</span>]<span class="op">;</span>

myArray[<span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>]<span class="op">;</span>

<span class="at">returnsArray</span>()[<span class="dv">1</span>]<span class="op">;</span></code></pre></div>
<p>Yep, you're totally correct! The basic structure is this one:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&lt;expression&gt;[&lt;expression&gt;]</code></pre></div>
<p>That seems simple enough. We can define a new AST node, called <code>ast.IndexExpression</code>, that reflects this structure:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> IndexExpression <span class="kw">struct</span> {
    Token token.Token <span class="co">// The [ token</span>
    Left  Expression
    Index Expression
}

<span class="kw">func</span> (ie *IndexExpression) expressionNode()      {}
<span class="kw">func</span> (ie *IndexExpression) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> ie.Token.Literal }
<span class="kw">func</span> (ie *IndexExpression) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    out.WriteString(<span class="st">&quot;(&quot;</span>)
    out.WriteString(ie.Left.String())
    out.WriteString(<span class="st">&quot;[&quot;</span>)
    out.WriteString(ie.Index.String())
    out.WriteString(<span class="st">&quot;])&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>It's important to note that both <code>Left</code> and <code>Index</code> are just <code>Expression</code>s. <code>Left</code> is the object that's being accessed and we've seen that it can be of any type: an identifier, an array literal, a function call. The same goes for <code>Index</code>. It can be any expression. Syntactically it doesn't make a difference which one it is, but semantically it has to produce an integer.</p>
<p>The fact that both <code>Left</code> and <code>Index</code> are expressions makes the parsing process easier, because we can use our <code>parseExpression</code> method to parse them. But first things first! Here is the test case that makes sure our parser knows how to return an <code>*ast.IndexExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingIndexExpressions(t *testing.T) {
    input := <span class="st">&quot;myArray[1 + 1]&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt, ok := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    indexExp, ok := stmt.Expression.(*ast.IndexExpression)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp not *ast.IndexExpression. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> !testIdentifier(t, indexExp.Left, <span class="st">&quot;myArray&quot;</span>) {
        <span class="kw">return</span>
    }

    <span class="kw">if</span> !testInfixExpression(t, indexExp.Index, <span class="dv">1</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">1</span>) {
        <span class="kw">return</span>
    }
}</code></pre></div>
<p>Now, this test only asserts that the parser outputs the correct AST for a single expression statement containing an index expression. But equally important is that the parser handles the precedence of the index operator correctly. The index operator has to have the highest precedence of all operators yet. Making sure of that is as easy as extending our existing <code>TestOperatorPrecedenceParsing</code> test function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestOperatorPrecedenceParsing(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">&quot;a * [1, 2, 3, 4][b * c] * d&quot;</span>,
            <span class="st">&quot;((a * ([1, 2, 3, 4][(b * c)])) * d)&quot;</span>,
        },
        {
            <span class="st">&quot;add(a * b[2], b[1], 2 * [1, 2][1])&quot;</span>,
            <span class="st">&quot;add((a * (b[2])), (b[1]), (2 * ([1, 2][1])))&quot;</span>,
        },
    }
<span class="co">// [...]</span>
}</code></pre></div>
<p>The additional <code>(</code> and <code>)</code> in the <code>String()</code> output of <code>*ast.IndexExpression</code> help us when writing these tests, since they make the precedence of the index operator visible. In these added test cases we expect that the precedence of the index operator is higher than the precedence of call expressions or even the <code>*</code> operator in infix expressions.</p>
<p>The tests fail because the parser doesn't know anything about index expressions yet:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestOperatorPrecedenceParsing (0.00s)
  parser_test.go:393: expected=&quot;((a * ([1, 2, 3, 4][(b * c)])) * d)&quot;,\
    got=&quot;(a * [1, 2, 3, 4])([(b * c)] * d)&quot;
  parser_test.go:968: parser has 4 errors
  parser_test.go:970: parser error: &quot;expected next token to be ), got [ instead&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for ) found&quot;
--- FAIL: TestParsingIndexExpressions (0.00s)
  parser_test.go:835: exp not *ast.IndexExpression. got=*ast.Identifier
FAIL
FAIL    monkey/parser   0.007s</code></pre></div>
<p>Even though the tests complain about a missing <code>prefixParseFn</code> what we want is an <code>infixParseFn</code>. Yes, index operator expressions do not really have a single operator between operands on each side. But in order to parse them without a lot of trouble it's of advantage to act like they do, just like we did with call expressions. Specifically, that means treating the <code>[</code> in <code>myArray[0]</code> as the infix operator, <code>myArray</code> as the left operand and <code>0</code> as the right operand.</p>
<p>Doing this makes the implementation fit really nicely into our parser:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>

    p.registerInfix(token.LBRACKET, p.parseIndexExpression)

<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseIndexExpression(left ast.Expression) ast.Expression {
    exp := &amp;ast.IndexExpression{Token: p.curToken, Left: left}

    p.nextToken()
    exp.Index = p.parseExpression(LOWEST)

    <span class="kw">if</span> !p.expectPeek(token.RBRACKET) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> exp
}</code></pre></div>
<p>Neat! But that doesn't fix our tests:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestOperatorPrecedenceParsing (0.00s)
  parser_test.go:393: expected=&quot;((a * ([1, 2, 3, 4][(b * c)])) * d)&quot;,\
    got=&quot;(a * [1, 2, 3, 4])([(b * c)] * d)&quot;
  parser_test.go:968: parser has 4 errors
  parser_test.go:970: parser error: &quot;expected next token to be ), got [ instead&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for , found&quot;
  parser_test.go:970: parser error: &quot;no prefix parse function for ) found&quot;
--- FAIL: TestParsingIndexExpressions (0.00s)
  parser_test.go:835: exp not *ast.IndexExpression. got=*ast.Identifier
FAIL
FAIL    monkey/parser   0.008s</code></pre></div>
<p>That's because the whole idea behind our Pratt parser hinges on the idea of precedences and we haven't defined the precedence of our index operator yet:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>
<span class="kw">const</span> (
    _ <span class="dt">int</span> = <span class="ot">iota</span>
<span class="co">// [...]</span>
    INDEX       <span class="co">// array[index]</span>
)

<span class="kw">var</span> precedences = <span class="kw">map</span>[token.TokenType]<span class="dt">int</span>{
<span class="co">// [...]</span>
    token.LBRACKET: INDEX,
}</code></pre></div>
<p>It's important that the definition of <code>INDEX</code> is the last line in the <code>const</code> block. That gives <code>INDEX</code> the highest value of all defined precedence constants, thanks to the <code>iota</code>. The added entry in <code>precedences</code> gives <code>token.LBRACKET</code> this highest precedence of all, <code>INDEX</code>. And, well, it does wonders:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.007s</code></pre></div>
<p>Lexer done, parser done. See you in the evaluator!</p>
<h3 id="evaluating-array-literals">Evaluating Array Literals</h3>
<p>Evaluating array literals is not hard. Mapping Monkey arrays to Go's slices makes life pretty, pretty sweet. We don't have to implement a new data structure. We only need to define a new <code>object.Array</code> type, since that's what the evaluation of array literals produces. And the definition of <code>object.Array</code> is simple, since arrays in Monkey are simple: they are just a list of objects.</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    ARRAY_OBJ = <span class="st">&quot;ARRAY&quot;</span>
)

<span class="kw">type</span> Array <span class="kw">struct</span> {
    Elements []Object
}

<span class="kw">func</span> (ao *Array) Type() ObjectType { <span class="kw">return</span> ARRAY_OBJ }
<span class="kw">func</span> (ao *Array) Inspect() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    elements := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, e := <span class="kw">range</span> ao.Elements {
        elements = <span class="bu">append</span>(elements, e.Inspect())
    }

    out.WriteString(<span class="st">&quot;[&quot;</span>)
    out.WriteString(strings.Join(elements, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;]&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>I think you'll agree with me when I say that the most complicated thing about this definition is the <code>Inspect</code> method. And even that one is pretty easy to understand.</p>
<p>Here is the evaluator test for array literals:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestArrayLiterals(t *testing.T) {
    input := <span class="st">&quot;[1, 2 * 2, 3 + 3]&quot;</span>

    evaluated := testEval(input)
    result, ok := evaluated.(*object.Array)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;object is not Array. got=%T (%+v)&quot;</span>, evaluated, evaluated)
    }

    <span class="kw">if</span> <span class="bu">len</span>(result.Elements) != <span class="dv">3</span> {
        t.Fatalf(<span class="st">&quot;array has wrong num of elements. got=%d&quot;</span>,
            <span class="bu">len</span>(result.Elements))
    }

    testIntegerObject(t, result.Elements[<span class="dv">0</span>], <span class="dv">1</span>)
    testIntegerObject(t, result.Elements[<span class="dv">1</span>], <span class="dv">4</span>)
    testIntegerObject(t, result.Elements[<span class="dv">2</span>], <span class="dv">6</span>)
}</code></pre></div>
<p>We can reuse some existing code to get this test to pass, just like we did in our parser. And again the code we're reusing was originally written for call expressions. Here is the <code>case</code> branch that evaluates <code>*ast.ArrayLiteral</code>s and produces array objects:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>

    <span class="kw">case</span> *ast.ArrayLiteral:
        elements := evalExpressions(node.Elements, env)
        <span class="kw">if</span> <span class="bu">len</span>(elements) == <span class="dv">1</span> &amp;&amp; isError(elements[<span class="dv">0</span>]) {
            <span class="kw">return</span> elements[<span class="dv">0</span>]
        }
        <span class="kw">return</span> &amp;object.Array{Elements: elements}
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>Isn't that one of the great joys of programming? Reusing existing code without having to turn it into a super generic, over-engineered spaceship.</p>
<p>The tests are passing and we can use array literals in our REPL to produce arrays:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript">$ go run <span class="va">main</span>.<span class="at">go</span>
Hello mrnugget<span class="op">!</span> This is the Monkey programming language<span class="op">!</span>
Feel free to type <span class="kw">in</span> commands
<span class="op">&gt;&gt;</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]
[<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]
<span class="op">&gt;&gt;</span> <span class="kw">let</span> double <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span> x <span class="op">*</span> <span class="dv">2</span> <span class="op">};</span>
<span class="op">&gt;&gt;</span> [<span class="dv">1</span><span class="op">,</span> <span class="at">double</span>(<span class="dv">2</span>)<span class="op">,</span> <span class="dv">3</span> <span class="op">*</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span> <span class="op">-</span> <span class="dv">3</span>]
[<span class="dv">1</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">9</span><span class="op">,</span> <span class="dv">1</span>]
<span class="op">&gt;&gt;</span></code></pre></div>
<p>Amazing, isn't it? But what we can't do yet is accessing single elements of the array by using the index operator.</p>
<h3 id="evaluating-index-operator-expressions">Evaluating Index Operator Expressions</h3>
<p>Great news: much harder than evaluating index expressions is parsing them. And we already did that. The only problem left is the possibility of off-by-one errors when accessing and retrieving the elements in an array. But for that we'll just add a few tests to our test suite:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestArrayIndexExpressions(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="kw">interface</span>{}
    }{
        {
            <span class="st">&quot;[1, 2, 3][0]&quot;</span>,
            <span class="dv">1</span>,
        },
        {
            <span class="st">&quot;[1, 2, 3][1]&quot;</span>,
            <span class="dv">2</span>,
        },
        {
            <span class="st">&quot;[1, 2, 3][2]&quot;</span>,
            <span class="dv">3</span>,
        },
        {
            <span class="st">&quot;let i = 0; [1][i];&quot;</span>,
            <span class="dv">1</span>,
        },
        {
            <span class="st">&quot;[1, 2, 3][1 + 1];&quot;</span>,
            <span class="dv">3</span>,
        },
        {
            <span class="st">&quot;let myArray = [1, 2, 3]; myArray[2];&quot;</span>,
            <span class="dv">3</span>,
        },
        {
            <span class="st">&quot;let myArray = [1, 2, 3]; myArray[0] + myArray[1] + myArray[2];&quot;</span>,
            <span class="dv">6</span>,
        },
        {
            <span class="st">&quot;let myArray = [1, 2, 3]; let i = myArray[0]; myArray[i]&quot;</span>,
            <span class="dv">2</span>,
        },
        {
            <span class="st">&quot;[1, 2, 3][3]&quot;</span>,
            <span class="ot">nil</span>,
        },
        {
            <span class="st">&quot;[1, 2, 3][-1]&quot;</span>,
            <span class="ot">nil</span>,
        },
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        integer, ok := tt.expected.(<span class="dt">int</span>)
        <span class="kw">if</span> ok {
            testIntegerObject(t, evaluated, <span class="dt">int64</span>(integer))
        } <span class="kw">else</span> {
            testNullObject(t, evaluated)
        }
    }
}</code></pre></div>
<p>Okay, I'll admit, these tests might seem excessive. A lot of the things we're testing implicitly here have already been tested elsewhere. But the test cases are so easy to write! And they are so readable! I love these tests.</p>
<p>Take note of the desired behaviour these tests specify. They contain something we haven't talked about yet: when we use an index that's out of the arrays bounds, we'll return <code>NULL</code>. Some languages produce an error in such a case and some return a null value. I choose to return <code>NULL</code>.</p>
<p>As expected the tests are failing. And not only that, they're blowing up:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestArrayIndexExpressions (0.00s)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
  evaluator_test.go:492: object is not Integer. got=&lt;nil&gt; (&lt;nil&gt;)
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x70057]
[redacted: backtrace here]
FAIL    monkey/evaluator        0.011s</code></pre></div>
<p>So how do we fix this and evaluate index expressions? As we've seen, the left operand of the index operator can be any expression and the index itself can be any expression. That means we need to evaluate both before we can evaluate the &quot;indexing&quot; itself. Otherwise we'd try to access elements of an identifier or a function call, which doesn't work.</p>
<p>Here is the <code>case</code> branch for <code>*ast.IndexExpression</code> that makes these desired calls to <code>Eval</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>

    <span class="kw">case</span> *ast.IndexExpression:
        left := Eval(node.Left, env)
        <span class="kw">if</span> isError(left) {
            <span class="kw">return</span> left
        }
        index := Eval(node.Index, env)
        <span class="kw">if</span> isError(index) {
            <span class="kw">return</span> index
        }
        <span class="kw">return</span> evalIndexExpression(left, index)

<span class="co">// [...]</span>
}</code></pre></div>
<p>And here is the <code>evalIndexExpression</code> function it uses:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalIndexExpression(left, index object.Object) object.Object {
    <span class="kw">switch</span> {
    <span class="kw">case</span> left.Type() == object.ARRAY_OBJ &amp;&amp; index.Type() == object.INTEGER_OBJ:
        <span class="kw">return</span> evalArrayIndexExpression(left, index)
    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;index operator not supported: %s&quot;</span>, left.Type())
    }
}</code></pre></div>
<p>An if-conditional would do the job of the switch statement here just fine, but we're going to add another <code>case</code> branch later in this chapter. Besides the error handling (for which I also added a test) nothing really interesting happens in this function. The meat of the operation is in <code>evalArrayIndexExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalArrayIndexExpression(array, index object.Object) object.Object {
    arrayObject := array.(*object.Array)
    idx := index.(*object.Integer).Value
    max := <span class="dt">int64</span>(<span class="bu">len</span>(arrayObject.Elements) - <span class="dv">1</span>)

    <span class="kw">if</span> idx &lt; <span class="dv">0</span> || idx &gt; max {
        <span class="kw">return</span> NULL
    }

    <span class="kw">return</span> arrayObject.Elements[idx]
}</code></pre></div>
<p>Here we actually retrieve the element with the specified index from the array. Besides the little type assertion and conversion dances this function is pretty straightforward: it checks if the given index is out of range and if that's the case it returns <code>NULL</code>, otherwise the desired element. Just like we specified in our tests, which are now passing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>Okay, now take a deep breath, relax and take a look at this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let a = [1, 2 * 2, 10 - 5, 8 / 2];
&gt;&gt; a[0]
1
&gt;&gt; a[1]
4
&gt;&gt; a[5 - 3]
5
&gt;&gt; a[99]
null</code></pre></div>
<p>Retrieving elements from an array works! Sweet! I can only repeat myself here: it's amazing how easy it was to implement this language feature, isn't it?</p>
<h3 id="adding-built-in-functions-for-arrays">Adding Built-in Functions for Arrays</h3>
<p>We are now able to construct arrays by using array literals. And we can access single elements by using index expressions. Just those two things alone make arrays quite useful to have. But in order to make them even more useful, we need to add a few built-in functions that make working with them more convenient. In this sub-section we're going to do exactly that.</p>
<p>I won't be showing any test code and test cases in this section. The reason is that these particular tests take up space without adding anything new. Our &quot;framework&quot; for testing built-in functions is already in place with <code>TestBuiltinFunctions</code> and the added tests follow the existing scheme. You can find them in the accompanying code.</p>
<p>Our goal is to add new built-in functions. But the first thing we actually have to do is not adding a new one but changing an existing function. We need to add support for arrays to <code>len</code>, which only supported strings until now:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
    <span class="st">&quot;len&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">1</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=1&quot;</span>,
                    <span class="bu">len</span>(args))
            }

            <span class="kw">switch</span> arg := args[<span class="dv">0</span>].(<span class="kw">type</span>) {
            <span class="kw">case</span> *object.Array:
                <span class="kw">return</span> &amp;object.Integer{Value: <span class="dt">int64</span>(<span class="bu">len</span>(arg.Elements))}
            <span class="kw">case</span> *object.String:
                <span class="kw">return</span> &amp;object.Integer{Value: <span class="dt">int64</span>(<span class="bu">len</span>(arg.Value))}
            <span class="kw">default</span>:
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `len` not supported, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }
        },
    },
<span class="co">// [...]</span>
}</code></pre></div>
<p>The only change is the added <code>case</code> branch for <code>*object.Array</code>. And with that out of the way, we're ready to start adding new functions. Yay!</p>
<p>The first of these new built-in functions is <code>first</code>. <code>first</code> returns the first element of the given array. Yes, calling <code>myArray[0]</code> does the same thing. But <code>first</code> is arguably prettier. Here is its implementation:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
<span class="co">// [...]</span>

    <span class="st">&quot;first&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">1</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=1&quot;</span>,
                    <span class="bu">len</span>(args))
            }
            <span class="kw">if</span> args[<span class="dv">0</span>].Type() != object.ARRAY_OBJ {
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `first` must be ARRAY, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }

            arr := args[<span class="dv">0</span>].(*object.Array)
            <span class="kw">if</span> <span class="bu">len</span>(arr.Elements) &gt; <span class="dv">0</span> {
                <span class="kw">return</span> arr.Elements[<span class="dv">0</span>]
            }

            <span class="kw">return</span> NULL
        },
    },
}</code></pre></div>
<p>Great! That works! And what comes after <code>first</code>? You're correct, the next function we're going to add is called <code>last</code>.</p>
<p>The purpose of <code>last</code> is to return the last element of the given array. In index operator terms it returns <code>myArray[len(myArray)-1]</code>. And as it turns out, implementing <code>last</code> is not much harder than implementing <code>first</code> - who would have thought that? Here it is:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
<span class="co">// [...]</span>

    <span class="st">&quot;last&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">1</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=1&quot;</span>,
                    <span class="bu">len</span>(args))
            }
            <span class="kw">if</span> args[<span class="dv">0</span>].Type() != object.ARRAY_OBJ {
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `last` must be ARRAY, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }

            arr := args[<span class="dv">0</span>].(*object.Array)
            length := <span class="bu">len</span>(arr.Elements)
            <span class="kw">if</span> length &gt; <span class="dv">0</span> {
                <span class="kw">return</span> arr.Elements[length<span class="dv">-1</span>]
            }

            <span class="kw">return</span> NULL
        },
    },
}</code></pre></div>
<p>The next function we're going to add would be called <code>cdr</code> in Scheme. In some other languages it's sometimes called <code>tail</code>. We're going to call it <code>rest</code>. <code>rest</code> returns a new array containing all elements of the array passed as argument, <em>except the first one</em>. Here's what using it looks like:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> a <span class="op">=</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]<span class="op">;</span>
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(a)
[<span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(<span class="at">rest</span>(a))
[<span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(a)))
[<span class="dv">4</span>]
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(a))))
[]
<span class="op">&gt;&gt;</span> <span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(<span class="at">rest</span>(a)))))
<span class="kw">null</span></code></pre></div>
<p>Its implementation is simple, but keep in mind that we're returning a <em>newly allocated</em> array. We're not modifying the array passed to <code>rest</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
<span class="co">// [...]</span>

    <span class="st">&quot;rest&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">1</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=1&quot;</span>,
                    <span class="bu">len</span>(args))
            }
            <span class="kw">if</span> args[<span class="dv">0</span>].Type() != object.ARRAY_OBJ {
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `rest` must be ARRAY, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }

            arr := args[<span class="dv">0</span>].(*object.Array)
            length := <span class="bu">len</span>(arr.Elements)
            <span class="kw">if</span> length &gt; <span class="dv">0</span> {
                newElements := <span class="bu">make</span>([]object.Object, length<span class="dv">-1</span>, length<span class="dv">-1</span>)
                <span class="bu">copy</span>(newElements, arr.Elements[<span class="dv">1</span>:length])
                <span class="kw">return</span> &amp;object.Array{Elements: newElements}
            }

            <span class="kw">return</span> NULL
        },
    },
}</code></pre></div>
<p>The last array function we're going to build into our interpreter is called <code>push</code>. It adds a new element to the end of the array. But, and here's the kicker, it doesn't modify the given array. Instead it allocates a new array with the same elements as the old one plus the new, pushed element. Arrays are immutable in Monkey. Here is <code>push</code> in action:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> a <span class="op">=</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]<span class="op">;</span>
<span class="op">&gt;&gt;</span> <span class="kw">let</span> b <span class="op">=</span> <span class="at">push</span>(a<span class="op">,</span> <span class="dv">5</span>)<span class="op">;</span>
<span class="op">&gt;&gt;</span> a
[<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]
<span class="op">&gt;&gt;</span> b
[<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">5</span>]</code></pre></div>
<p>And here is its implementation:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
<span class="co">// [...]</span>

    <span class="st">&quot;push&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">if</span> <span class="bu">len</span>(args) != <span class="dv">2</span> {
                <span class="kw">return</span> newError(<span class="st">&quot;wrong number of arguments. got=%d, want=2&quot;</span>,
                    <span class="bu">len</span>(args))
            }
            <span class="kw">if</span> args[<span class="dv">0</span>].Type() != object.ARRAY_OBJ {
                <span class="kw">return</span> newError(<span class="st">&quot;argument to `push` must be ARRAY, got %s&quot;</span>,
                    args[<span class="dv">0</span>].Type())
            }

            arr := args[<span class="dv">0</span>].(*object.Array)
            length := <span class="bu">len</span>(arr.Elements)

            newElements := <span class="bu">make</span>([]object.Object, length<span class="dv">+1</span>, length<span class="dv">+1</span>)
            <span class="bu">copy</span>(newElements, arr.Elements)
            newElements[length] = args[<span class="dv">1</span>]

            <span class="kw">return</span> &amp;object.Array{Elements: newElements}
        },
    },
}</code></pre></div>
<h3 id="test-driving-arrays">Test-Driving Arrays</h3>
<p>We now have array literals, the index operator and a few built-in functions to work with arrays. It's time to take them for a spin. Let's see what they can do.</p>
<p>With <code>first</code>, <code>rest</code> and <code>push</code> we can build a <code>map</code> function:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> map <span class="op">=</span> <span class="at">fn</span>(arr<span class="op">,</span> f) <span class="op">{</span>
  <span class="kw">let</span> iter <span class="op">=</span> <span class="at">fn</span>(arr<span class="op">,</span> accumulated) <span class="op">{</span>
    <span class="cf">if</span> (<span class="at">len</span>(arr) <span class="op">==</span> <span class="dv">0</span>) <span class="op">{</span>
      accumulated
    <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
      <span class="at">iter</span>(<span class="at">rest</span>(arr)<span class="op">,</span> <span class="at">push</span>(accumulated<span class="op">,</span> <span class="at">f</span>(<span class="at">first</span>(arr))))<span class="op">;</span>
    <span class="op">}</span>
  <span class="op">};</span>

  <span class="at">iter</span>(arr<span class="op">,</span> [])<span class="op">;</span>
<span class="op">};</span></code></pre></div>
<p>And with <code>map</code> we can do things like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> a <span class="op">=</span> [<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span>]<span class="op">;</span>
<span class="op">&gt;&gt;</span> <span class="kw">let</span> double <span class="op">=</span> <span class="at">fn</span>(x) <span class="op">{</span> x <span class="op">*</span> <span class="dv">2</span> <span class="op">};</span>
<span class="op">&gt;&gt;</span> <span class="at">map</span>(a<span class="op">,</span> double)<span class="op">;</span>
[<span class="dv">2</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">6</span><span class="op">,</span> <span class="dv">8</span>]</code></pre></div>
<p>Isn't this amazing? There's more! Based on the same built-in functions we can also define a <code>reduce</code> function:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> reduce <span class="op">=</span> <span class="at">fn</span>(arr<span class="op">,</span> initial<span class="op">,</span> f) <span class="op">{</span>
  <span class="kw">let</span> iter <span class="op">=</span> <span class="at">fn</span>(arr<span class="op">,</span> result) <span class="op">{</span>
    <span class="cf">if</span> (<span class="at">len</span>(arr) <span class="op">==</span> <span class="dv">0</span>) <span class="op">{</span>
      result
    <span class="op">}</span> <span class="cf">else</span> <span class="op">{</span>
      <span class="at">iter</span>(<span class="at">rest</span>(arr)<span class="op">,</span> <span class="at">f</span>(result<span class="op">,</span> <span class="at">first</span>(arr)))<span class="op">;</span>
    <span class="op">}</span>
  <span class="op">};</span>

  <span class="at">iter</span>(arr<span class="op">,</span> initial)<span class="op">;</span>
<span class="op">};</span></code></pre></div>
<p>And <code>reduce</code>, in turn, can be used to define a <code>sum</code> function:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> sum <span class="op">=</span> <span class="at">fn</span>(arr) <span class="op">{</span>
  <span class="at">reduce</span>(arr<span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="at">fn</span>(initial<span class="op">,</span> el) <span class="op">{</span> initial <span class="op">+</span> el <span class="op">}</span>)<span class="op">;</span>
<span class="op">};</span></code></pre></div>
<p>And it works like a charm:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="at">sum</span>([<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">5</span>])<span class="op">;</span>
<span class="dv">15</span></code></pre></div>
<p>As you probably know, I'm not a fan of patting oneself on the back, but let me just say this: holy monkey! Look at what our interpreter can do! A <code>map</code> function?! <code>reduce</code>?! We've come a long, long way!</p>
<p>And that's not even all of it! There's a lot more we can do now and I urge you to explore the possibilities the array data type and the few built-in functions give us. But you know what you should do first? Take some time off, brag about this to your friends and family, enjoy the praise and compliments. And when you come back, we'll add another data type.</p>
<h2 id="hashes">4.5 - Hashes</h2>
<p>The next data type we're going to add is called &quot;hash&quot;. A hash in Monkey is what's sometimes called hash, map, hash map or dictionary in other programming languages. It maps keys to values.</p>
<p>In order to construct a hash in Monkey one uses the hash literal: a comma-separated list of key-value pairs that's enclosed by curly braces. Each key-value pair uses a colon to differentiate between the key and the value. Here is what using a hash literal looks like:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> myHash <span class="op">=</span> <span class="op">{</span><span class="st">&quot;name&quot;</span><span class="op">:</span> <span class="st">&quot;Jimmy&quot;</span><span class="op">,</span> <span class="st">&quot;age&quot;</span><span class="op">:</span> <span class="dv">72</span><span class="op">,</span> <span class="st">&quot;band&quot;</span><span class="op">:</span> <span class="st">&quot;Led Zeppelin&quot;</span><span class="op">};</span>
<span class="op">&gt;&gt;</span> myHash[<span class="st">&quot;name&quot;</span>]
Jimmy
<span class="op">&gt;&gt;</span> myHash[<span class="st">&quot;age&quot;</span>]
<span class="dv">72</span>
<span class="op">&gt;&gt;</span> myHash[<span class="st">&quot;band&quot;</span>]
Led Zeppelin</code></pre></div>
<p>In this example <code>myHash</code> contains three key-value pairs. The keys are all strings. And, as you can see, we can use index operator expressions to get values out of the hash again, just like we can with arrays. Except that in this example the index values are strings, which don't work with arrays. And that's not even the only data type that's usable as a hash key:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> myHash <span class="op">=</span> <span class="op">{</span><span class="dt">true</span><span class="op">:</span> <span class="st">&quot;yes, a boolean&quot;</span><span class="op">,</span> <span class="dv">99</span><span class="op">:</span> <span class="st">&quot;correct, an integer&quot;</span><span class="op">};</span>
<span class="op">&gt;&gt;</span> myHash[<span class="kw">true</span>]
yes<span class="op">,</span> a boolean
<span class="op">&gt;&gt;</span> myHash[<span class="dv">99</span>]
correct<span class="op">,</span> an integer</code></pre></div>
<p>That's also valid. In fact, besides string, integer and boolean literals we can use any expression as index in index operator expressions:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> myHash[<span class="dv">5</span> <span class="op">&gt;</span> <span class="dv">1</span>]
yes<span class="op">,</span> a boolean
<span class="op">&gt;&gt;</span> myHash[<span class="dv">100</span> <span class="op">-</span> <span class="dv">1</span>]
correct<span class="op">,</span> an integer</code></pre></div>
<p>As long as these expressions evaluate to either strings, integers or booleans they are usable as hash keys. Here <code>5 &gt; 1</code> evaluates to <code>true</code> and <code>100 - 1</code> evaluates to <code>99</code>, both of which are valid and mapped to values in <code>myHash</code>.</p>
<p>Rather unsurprisingly our implementation will use Go's <code>map</code> as the underlying data structure for Monkey hashes. But since we want to use strings, integers and booleans interchangeably as keys, we need to build something on top of plain old <code>map</code> to make it work. We'll come to that when we extend our object system. But first we have to turn hash literals into tokens.</p>
<h3 id="lexing-hash-literals">Lexing Hash Literals</h3>
<p>How do we turn hash literals into tokens? Which tokens do we need to recognize and output in our lexer so that we can later work with them in the parser? Here is the hash literal from above again:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">{</span><span class="st">&quot;name&quot;</span><span class="op">:</span> <span class="st">&quot;Jimmy&quot;</span><span class="op">,</span> <span class="st">&quot;age&quot;</span><span class="op">:</span> <span class="dv">72</span><span class="op">,</span> <span class="st">&quot;band&quot;</span><span class="op">:</span> <span class="st">&quot;Led Zeppelin&quot;</span><span class="op">}</span></code></pre></div>
<p>Besides the string literals there are four characters in use here that are important: <code>{</code>, <code>}</code>, <code>,</code> and <code>:</code>. We already know how to lex the first three. Our lexer turns these into <code>token.LBRACE</code>, <code>token.RBRACE</code> and <code>token.COMMA</code> respectively. That means, all that's left for us to do in this section is to turn <code>:</code> into a token.</p>
<p>And for that we first need to define the necessary token type in the <code>token</code> package:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// token/token.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    COLON = <span class="st">&quot;:&quot;</span>
<span class="co">// [...]</span>
)</code></pre></div>
<p>Next we're going to add a new test for the <code>NextToken</code> method of <code>Lexer</code> that expects a <code>token.COLON</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer_test.go</span>

<span class="kw">func</span> TestNextToken(t *testing.T) {
    input := <span class="st">`let five = 5;</span>
<span class="st">let ten = 10;</span>

<span class="st">let add = fn(x, y) {</span>
<span class="st">  x + y;</span>
<span class="st">};</span>

<span class="st">let result = add(five, ten);</span>
<span class="st">!-/*5;</span>
<span class="st">5 &lt; 10 &gt; 5;</span>

<span class="st">if (5 &lt; 10) {</span>
<span class="st">    return true;</span>
<span class="st">} else {</span>
<span class="st">    return false;</span>
<span class="st">}</span>

<span class="st">10 == 10;</span>
<span class="st">10 != 9;</span>
<span class="st">&quot;foobar&quot;</span>
<span class="st">&quot;foo bar&quot;</span>
<span class="st">[1, 2];</span>
<span class="st">{&quot;foo&quot;: &quot;bar&quot;}</span>
<span class="st">`</span>

    tests := []<span class="kw">struct</span> {
        expectedType    token.TokenType
        expectedLiteral <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {token.LBRACE, <span class="st">&quot;{&quot;</span>},
        {token.STRING, <span class="st">&quot;foo&quot;</span>},
        {token.COLON, <span class="st">&quot;:&quot;</span>},
        {token.STRING, <span class="st">&quot;bar&quot;</span>},
        {token.RBRACE, <span class="st">&quot;}&quot;</span>},
        {token.EOF, <span class="st">&quot;&quot;</span>},
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>We could get away with adding a single <code>:</code> to the test input, but using a hash literal as we did here provides a little more context when later reading and eventually debugging the test.</p>
<p>Turning <code>:</code> into <code>token.COLON</code> is as easy as it gets:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// lexer/lexer.go</span>

<span class="kw">func</span> (l *Lexer) NextToken() token.Token {
<span class="co">// [...]</span>
    <span class="kw">case</span> &#39;:&#39;:
        tok = newToken(token.COLON, l.ch)
<span class="co">// [...]</span>
}</code></pre></div>
<p>Only two new lines and the lexer now spits out <code>token.COLON</code>:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./lexer
ok      monkey/lexer    0.006s</code></pre></div>
<p>Boom! The lexer now returns <code>token.LBRACE</code>, <code>token.RBRACE</code>, <code>token.COMMA</code> and the new <code>token.COLON</code>. That's all we need in order to parse to hash literals.</p>
<h3 id="parsing-hash-literals">Parsing Hash Literals</h3>
<p>Before we start working on our parser or even writing a test, let's look at the basic syntactic structure of a hash literal:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">{&lt;expression&gt; : &lt;expression&gt;, &lt;expression&gt; : &lt;expression&gt;, ... }</code></pre></div>
<p>It's a comma-separated list of pairs. Each pair consists of two expressions. One produces the hash key and one produces the value. The key is separated from the value with a colon. The list is enclosed by a pair of curly braces.</p>
<p>When we turn this into an AST node, we have to keep track of the key-value pairs. Now how would we do that? We'll use a <code>map</code>, yes, but of what type are the keys and the values in this <code>map</code>?</p>
<p>We said earlier that the only admissible data types for hash keys are strings, integers and booleans. But we can't enforce that in the parser. Instead we'll have to validate hash key types in the evaluation stage and generate possible errors there.</p>
<p>That's because a lot of different expressions can produce strings, integers or booleans. Not just their literal forms. Enforcing the data type of hash keys in the parsing stage would prevent us from doing something like this:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> key <span class="op">=</span> <span class="st">&quot;name&quot;</span><span class="op">;</span>
<span class="kw">let</span> hash <span class="op">=</span> <span class="op">{</span><span class="dt">key</span><span class="op">:</span> <span class="st">&quot;Monkey&quot;</span><span class="op">};</span></code></pre></div>
<p>Here <code>key</code> evaluates to <code>&quot;name&quot;</code> and is thus totally valid as a hash key, even though it's an identifier. In order to allow this, we need to allow any expression as a key and any expression as a value in a hash literal. At least in the parsing stage. Following that our <code>ast.HashLiteral</code> definition looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// ast/ast.go</span>

<span class="kw">type</span> HashLiteral <span class="kw">struct</span> {
    Token token.Token <span class="co">// the &#39;{&#39; token</span>
    Pairs <span class="kw">map</span>[Expression]Expression
}

<span class="kw">func</span> (hl *HashLiteral) expressionNode()      {}
<span class="kw">func</span> (hl *HashLiteral) TokenLiteral() <span class="dt">string</span> { <span class="kw">return</span> hl.Token.Literal }
<span class="kw">func</span> (hl *HashLiteral) String() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    pairs := []<span class="dt">string</span>{}
    <span class="kw">for</span> key, value := <span class="kw">range</span> hl.Pairs {
        pairs = <span class="bu">append</span>(pairs, key.String()+<span class="st">&quot;:&quot;</span>+value.String())
    }

    out.WriteString(<span class="st">&quot;{&quot;</span>)
    out.WriteString(strings.Join(pairs, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;}&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>Now that we're clear about the structure of hash literals and have <code>ast.HashLiteral</code> defined, we can write tests for our parser:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingHashLiteralsStringKeys(t *testing.T) {
    input := <span class="st">`{&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 3}`</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    hash, ok := stmt.Expression.(*ast.HashLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp is not ast.HashLiteral. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> <span class="bu">len</span>(hash.Pairs) != <span class="dv">3</span> {
        t.Errorf(<span class="st">&quot;hash.Pairs has wrong length. got=%d&quot;</span>, <span class="bu">len</span>(hash.Pairs))
    }

    expected := <span class="kw">map</span>[<span class="dt">string</span>]<span class="dt">int64</span>{
        <span class="st">&quot;one&quot;</span>:   <span class="dv">1</span>,
        <span class="st">&quot;two&quot;</span>:   <span class="dv">2</span>,
        <span class="st">&quot;three&quot;</span>: <span class="dv">3</span>,
    }

    <span class="kw">for</span> key, value := <span class="kw">range</span> hash.Pairs {
        literal, ok := key.(*ast.StringLiteral)
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;key is not ast.StringLiteral. got=%T&quot;</span>, key)
        }

        expectedValue := expected[literal.String()]

        testIntegerLiteral(t, value, expectedValue)
    }
}</code></pre></div>
<p>And of course, we also have to be sure that we parse an empty hash literal correctly, because such edge-cases are the root of all hair loss in programming:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingEmptyHashLiteral(t *testing.T) {
    input := <span class="st">&quot;{}&quot;</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    hash, ok := stmt.Expression.(*ast.HashLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp is not ast.HashLiteral. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> <span class="bu">len</span>(hash.Pairs) != <span class="dv">0</span> {
        t.Errorf(<span class="st">&quot;hash.Pairs has wrong length. got=%d&quot;</span>, <span class="bu">len</span>(hash.Pairs))
    }
}</code></pre></div>
<p>I also added two more tests that are similar to <code>TestHashLiteralStringKeys</code> but use integers and booleans as hash keys and make sure the parser turns those into <code>*ast.IntegerLiteral</code> and <code>*ast.Boolean</code> respectively. And then there is a fifth test function that makes sure the values in a hash literal can be any expression, even operator expressions. It looks like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser_test.go</span>

<span class="kw">func</span> TestParsingHashLiteralsWithExpressions(t *testing.T) {
    input := <span class="st">`{&quot;one&quot;: 0 + 1, &quot;two&quot;: 10 - 8, &quot;three&quot;: 15 / 5}`</span>

    l := lexer.New(input)
    p := New(l)
    program := p.ParseProgram()
    checkParserErrors(t, p)

    stmt := program.Statements[<span class="dv">0</span>].(*ast.ExpressionStatement)
    hash, ok := stmt.Expression.(*ast.HashLiteral)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;exp is not ast.HashLiteral. got=%T&quot;</span>, stmt.Expression)
    }

    <span class="kw">if</span> <span class="bu">len</span>(hash.Pairs) != <span class="dv">3</span> {
        t.Errorf(<span class="st">&quot;hash.Pairs has wrong length. got=%d&quot;</span>, <span class="bu">len</span>(hash.Pairs))
    }

    tests := <span class="kw">map</span>[<span class="dt">string</span>]<span class="kw">func</span>(ast.Expression){
        <span class="st">&quot;one&quot;</span>: <span class="kw">func</span>(e ast.Expression) {
            testInfixExpression(t, e, <span class="dv">0</span>, <span class="st">&quot;+&quot;</span>, <span class="dv">1</span>)
        },
        <span class="st">&quot;two&quot;</span>: <span class="kw">func</span>(e ast.Expression) {
            testInfixExpression(t, e, <span class="dv">10</span>, <span class="st">&quot;-&quot;</span>, <span class="dv">8</span>)
        },
        <span class="st">&quot;three&quot;</span>: <span class="kw">func</span>(e ast.Expression) {
            testInfixExpression(t, e, <span class="dv">15</span>, <span class="st">&quot;/&quot;</span>, <span class="dv">5</span>)
        },
    }

    <span class="kw">for</span> key, value := <span class="kw">range</span> hash.Pairs {
        literal, ok := key.(*ast.StringLiteral)
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;key is not ast.StringLiteral. got=%T&quot;</span>, key)
            <span class="kw">continue</span>
        }

        testFunc, ok := tests[literal.String()]
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;No test function for key %q found&quot;</span>, literal.String())
            <span class="kw">continue</span>
        }

        testFunc(value)
    }
}</code></pre></div>
<p>So how are all of these test functions doing? Not so well, to be honest. We get a lot of failures and parser errors:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
--- FAIL: TestParsingEmptyHashLiteral (0.00s)
  parser_test.go:1173: parser has 2 errors
  parser_test.go:1175: parser error: &quot;no prefix parse function for { found&quot;
  parser_test.go:1175: parser error: &quot;no prefix parse function for } found&quot;
--- FAIL: TestParsingHashLiteralsStringKeys (0.00s)
  parser_test.go:1173: parser has 7 errors
  parser_test.go:1175: parser error: &quot;no prefix parse function for { found&quot;
[... more errors ...]
--- FAIL: TestParsingHashLiteralsBooleanKeys (0.00s)
  parser_test.go:1173: parser has 5 errors
  parser_test.go:1175: parser error: &quot;no prefix parse function for { found&quot;
[... more errors ...]
--- FAIL: TestParsingHashLiteralsIntegerKeys (0.00s)
  parser_test.go:967: parser has 7 errors
  parser_test.go:969: parser error: &quot;no prefix parse function for { found&quot;
[... more errors ...]
--- FAIL: TestParsingHashLiteralsWithExpressions (0.00s)
  parser_test.go:1173: parser has 7 errors
  parser_test.go:1175: parser error: &quot;no prefix parse function for { found&quot;
[... more errors ...]
FAIL
FAIL    monkey/parser   0.008s</code></pre></div>
<p>It might sound unbelievable but there's good news: it only takes one function to make all of these tests pass. One <code>prefixParseFn</code>, to be exact. Since the <code>token.LBRACE</code> of a hash literal is in prefix position, just like the <code>token.LBRACKET</code> of an array literal, we can define a <code>parseHashLiteral</code> method as a <code>prefixParseFn</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// parser/parser.go</span>

<span class="kw">func</span> New(l *lexer.Lexer) *Parser {
<span class="co">// [...]</span>
    p.registerPrefix(token.LBRACE, p.parseHashLiteral)
<span class="co">// [...]</span>
}

<span class="kw">func</span> (p *Parser) parseHashLiteral() ast.Expression {
    hash := &amp;ast.HashLiteral{Token: p.curToken}
    hash.Pairs = <span class="bu">make</span>(<span class="kw">map</span>[ast.Expression]ast.Expression)

    <span class="kw">for</span> !p.peekTokenIs(token.RBRACE) {
        p.nextToken()
        key := p.parseExpression(LOWEST)

        <span class="kw">if</span> !p.expectPeek(token.COLON) {
            <span class="kw">return</span> <span class="ot">nil</span>
        }

        p.nextToken()
        value := p.parseExpression(LOWEST)

        hash.Pairs[key] = value

        <span class="kw">if</span> !p.peekTokenIs(token.RBRACE) &amp;&amp; !p.expectPeek(token.COMMA) {
            <span class="kw">return</span> <span class="ot">nil</span>
        }
    }

    <span class="kw">if</span> !p.expectPeek(token.RBRACE) {
        <span class="kw">return</span> <span class="ot">nil</span>
    }

    <span class="kw">return</span> hash
}</code></pre></div>
<p>It may look intimidating, but there is nothing in <code>parseHashLiteral</code> we haven't seen before. It only loops over key-value expression pairs by checking for a closing <code>token.RBRACE</code> and calling <code>parseExpression</code> two times. That and the filling of <code>hash.Pairs</code> are the most important parts of this method. It does its job well:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./parser
ok      monkey/parser   0.006s</code></pre></div>
<p>All of our parser tests pass! And judging by the numbers of tests we added, we can be reasonably sure that our parser now knows how to parse hash literals. That means we're now coming to the most interesting part of adding hashes to our interpreter: representing them in the object system and evaluating hash literals.</p>
<h3 id="hashing-objects">Hashing Objects</h3>
<p>Besides extending the lexer and parser, adding a new data type also means representing it in the object system. We successfully did that for integers, strings and arrays. But whereas implementing these other data types just meant defining a struct that has a <code>.Value</code> field with the correct type, hashes require a little bit more effort. Let me explain why.</p>
<p>Let's say we defined a new <code>object.Hash</code> type like this:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">type</span> Hash <span class="kw">struct</span> {
  Pairs <span class="kw">map</span>[Object]Object
}</code></pre></div>
<p>That's the most obvious choice for implementing a <code>Hash</code> data type based on Go's <code>map</code>. But with this definition, how would we fill the <code>Pairs</code> map? And more importantly, how would we get values back out of it?</p>
<p>Consider this piece of Monkey code:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="kw">let</span> hash <span class="op">=</span> <span class="op">{</span><span class="st">&quot;name&quot;</span><span class="op">:</span> <span class="st">&quot;Monkey&quot;</span><span class="op">};</span>
hash[<span class="st">&quot;name&quot;</span>]</code></pre></div>
<p>Let's say we are evaluating these two lines and are using the <code>object.Hash</code> definition from above. When evaluating the hash literal in the first line we take every key-value pair and put it in the <code>map[Object]Object</code> map, resulting in <code>.Pairs</code> having the following mapping: an <code>*object.String</code> with <code>.Value</code> being <code>&quot;name&quot;</code> mapped to an <code>*object.String</code> with <code>.Value</code> being <code>&quot;Monkey&quot;</code>.</p>
<p>So far, so good. But the problem arises in the second line where we use an index expression to try to access the <code>&quot;Monkey&quot;</code> string.</p>
<p>In this second line the <code>&quot;name&quot;</code> string literal of the index expression evaluates to a new, freshly allocated <code>*object.String</code>. And even though this new <code>*object.String</code> also contains <code>&quot;name&quot;</code> in its <code>.Value</code> field, just like the other <code>*object.String</code> in <code>Pairs</code>, we can't use the new one to retrieve <code>&quot;Monkey&quot;</code>.</p>
<p>The reason for this is that they're pointers pointing to different memory locations. The fact that the content of the memory locations they point to is the same (<code>&quot;name&quot;</code>) doesn't matter. Comparing these pointers would tell us that they're not equal. That means using the newly created <code>*object.String</code> as a key doesn't get us <code>&quot;Monkey&quot;</code>. That's how pointers and comparison between them works in Go.</p>
<p>Here is an example that demonstrates the problem we'd face with the <code>object.Hash</code> implementation from above:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">name1 := &amp;object.String{Value: <span class="st">&quot;name&quot;</span>}
monkey := &amp;object.String{Value: <span class="st">&quot;Monkey&quot;</span>}

pairs := <span class="kw">map</span>[object.Object]object.Object{}
pairs[name1] = monkey

fmt.Printf(<span class="st">&quot;pairs[name1]=%+v</span><span class="ch">\n</span><span class="st">&quot;</span>, pairs[name1])
<span class="co">// =&gt; pairs[name1]=&amp;{Value:Monkey}</span>

name2 := &amp;object.String{Value: <span class="st">&quot;name&quot;</span>}

fmt.Printf(<span class="st">&quot;pairs[name2]=%+v</span><span class="ch">\n</span><span class="st">&quot;</span>, pairs[name2])
<span class="co">// =&gt; pairs[name2]=&lt;nil&gt;</span>

fmt.Printf(<span class="st">&quot;(name1 == name2)=%t</span><span class="ch">\n</span><span class="st">&quot;</span>, name1 == name2)
<span class="co">// =&gt; (name1 == name2)=false</span></code></pre></div>
<p>As a solution to this problem we could iterate over every key in <code>.Pairs</code>, check if it's an <code>*object.String</code> and compare its <code>.Value</code> to the <code>.Value</code> of the key in the index expression. We'd find the matching value this way, but this method turns the lookup time for a given key from O(1) into O(n), defeating the entire purpose of using hashes in the first place.</p>
<p>Another option is to define <code>Pairs</code> as a <code>map[string]Object</code> and then use the <code>.Value</code> of <code>*object.String</code> as the keys. That works, but not for integers and booleans.</p>
<p>No, what we need is a way to generate hashes for objects that we can easily compare and use as hash keys in our <code>object.Hash</code>. We need to be able to generate a hash key for an <code>*object.String</code> that's comparable and equal to the hash key of another <code>*object.String</code> with the same <code>.Value</code>. The same goes for <code>*object.Integer</code> and <code>*object.Boolean</code>. But the hash keys for an <code>*object.String</code> must never be equal to the hash key for an <code>*object.Integer</code> or an <code>*object.Boolean</code>. Between types the hash keys always have to differ.</p>
<p>We can express the desired behaviour in a set of test functions in our object system:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object_test.go</span>

<span class="kw">package</span> object

<span class="kw">import</span> <span class="st">&quot;testing&quot;</span>

<span class="kw">func</span> TestStringHashKey(t *testing.T) {
    hello1 := &amp;String{Value: <span class="st">&quot;Hello World&quot;</span>}
    hello2 := &amp;String{Value: <span class="st">&quot;Hello World&quot;</span>}
    diff1 := &amp;String{Value: <span class="st">&quot;My name is johnny&quot;</span>}
    diff2 := &amp;String{Value: <span class="st">&quot;My name is johnny&quot;</span>}

    <span class="kw">if</span> hello1.HashKey() != hello2.HashKey() {
        t.Errorf(<span class="st">&quot;strings with same content have different hash keys&quot;</span>)
    }

    <span class="kw">if</span> diff1.HashKey() != diff2.HashKey() {
        t.Errorf(<span class="st">&quot;strings with same content have different hash keys&quot;</span>)
    }

    <span class="kw">if</span> hello1.HashKey() == diff1.HashKey() {
        t.Errorf(<span class="st">&quot;strings with different content have same hash keys&quot;</span>)
    }
}</code></pre></div>
<p>That's exactly what we want from a <code>HashKey()</code> method. And not just for <code>*object.String</code> but for <code>*object.Boolean</code> and <code>*object.Integer</code>, which is why the same test function exists for both of them too.</p>
<p>To stop the tests from blowing up we need to implement the <code>HashKey()</code> method on each of the three types:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">import</span> (
<span class="co">// [...]</span>
    <span class="st">&quot;hash/fnv&quot;</span>
)

<span class="kw">type</span> HashKey <span class="kw">struct</span> {
    Type  ObjectType
    Value <span class="dt">uint64</span>
}

<span class="kw">func</span> (b *Boolean) HashKey() HashKey {
    <span class="kw">var</span> value <span class="dt">uint64</span>

    <span class="kw">if</span> b.Value {
        value = <span class="dv">1</span>
    } <span class="kw">else</span> {
        value = <span class="dv">0</span>
    }

    <span class="kw">return</span> HashKey{Type: b.Type(), Value: value}
}

<span class="kw">func</span> (i *Integer) HashKey() HashKey {
    <span class="kw">return</span> HashKey{Type: i.Type(), Value: <span class="dt">uint64</span>(i.Value)}
}

<span class="kw">func</span> (s *String) HashKey() HashKey {
    h := fnv.New64a()
    h.Write([]<span class="dt">byte</span>(s.Value))

    <span class="kw">return</span> HashKey{Type: s.Type(), Value: h.Sum64()}
}</code></pre></div>
<p>Every <code>HashKey()</code> method returns a <code>HashKey</code>. As you can see in its definition, <code>HashKey</code> is nothing fancy. The <code>Type</code> field contains an <code>ObjectType</code> and thus effectively &quot;scopes&quot; <code>HashKey</code>s to different object types. The <code>Value</code> field holds the actual hash, which is just an integer. Since it's just two integers we can easily compare a <code>HashKey</code> to another <code>HashKey</code> by using the <code>==</code> operator. And that also makes <code>HashKey</code> usable as a key in a Go <code>map</code>.</p>
<p>The problem we demonstrated earlier is solved by using this newly defined <code>HashKey</code> and the <code>HashKey()</code> methods:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go">name1 := &amp;object.String{Value: <span class="st">&quot;name&quot;</span>}
monkey := &amp;object.String{Value: <span class="st">&quot;Monkey&quot;</span>}

pairs := <span class="kw">map</span>[object.HashKey]object.Object{}
pairs[name1.HashKey()] = monkey

fmt.Printf(<span class="st">&quot;pairs[name1.HashKey()]=%+v</span><span class="ch">\n</span><span class="st">&quot;</span>, pairs[name1.HashKey()])
<span class="co">// =&gt; pairs[name1.HashKey()]=&amp;{Value:Monkey}</span>

name2 := &amp;object.String{Value: <span class="st">&quot;name&quot;</span>}

fmt.Printf(<span class="st">&quot;pairs[name2.HashKey()]=%+v</span><span class="ch">\n</span><span class="st">&quot;</span>, pairs[name2.HashKey()])
<span class="co">// =&gt; pairs[name2.HashKey()]=&amp;{Value:Monkey}</span>

fmt.Printf(<span class="st">&quot;(name1 == name2)=%t</span><span class="ch">\n</span><span class="st">&quot;</span>, name1 == name2)
<span class="co">// =&gt; (name1 == name2)=false</span>

fmt.Printf(<span class="st">&quot;(name1.HashKey() == name2.HashKey())=%t</span><span class="ch">\n</span><span class="st">&quot;</span>,
  name1.HashKey() == name2.HashKey())
<span class="co">// =&gt; (name1.HashKey() == name2.HashKey())=true</span></code></pre></div>
<p>That's <em>exactly</em> what we want! The <code>HashKey</code> definition and the <code>HashKey()</code> method implementations solve the problems we had with our naive <code>Hash</code> definition. They also make the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./object
ok      monkey/object   0.008s</code></pre></div>
<p>Now we can define <code>object.Hash</code> and use this new <code>HashKey</code> type:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">const</span> (
<span class="co">// [...]</span>
    HASH_OBJ = <span class="st">&quot;HASH&quot;</span>
)

<span class="kw">type</span> HashPair <span class="kw">struct</span> {
    Key   Object
    Value Object
}

<span class="kw">type</span> Hash <span class="kw">struct</span> {
    Pairs <span class="kw">map</span>[HashKey]HashPair
}

<span class="kw">func</span> (h *Hash) Type() ObjectType { <span class="kw">return</span> HASH_OBJ }</code></pre></div>
<p>This adds both the definition of <code>Hash</code> and <code>HashPair</code>. <code>HashPair</code> is the type of the values in <code>Hash.Pairs</code>. You might be wondering why we use that and not just define <code>Pairs</code> as a <code>map[HashKey]Object</code>.</p>
<p>The reason is the <code>Inspect()</code> method of <code>Hash</code>. When we later print a Monkey hash in our REPL, we want to print the values contained in the hash as well as its keys. And just printing the <code>HashKey</code>s is not really useful. So we keep track of the objects that generated the <code>HashKeys</code> by using <code>HashPair</code>s as values, where we save the original key object and the value object its mapped to. That way we can call the <code>Inspect()</code> methods of the key objects to generate the <code>Inspect()</code> output for <code>*object.Hash</code>. Here is said <code>Inspect()</code> method:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">func</span> (h *Hash) Inspect() <span class="dt">string</span> {
    <span class="kw">var</span> out bytes.Buffer

    pairs := []<span class="dt">string</span>{}
    <span class="kw">for</span> _, pair := <span class="kw">range</span> h.Pairs {
        pairs = <span class="bu">append</span>(pairs, fmt.Sprintf(<span class="st">&quot;%s: %s&quot;</span>,
            pair.Key.Inspect(), pair.Value.Inspect()))
    }

    out.WriteString(<span class="st">&quot;{&quot;</span>)
    out.WriteString(strings.Join(pairs, <span class="st">&quot;, &quot;</span>))
    out.WriteString(<span class="st">&quot;}&quot;</span>)

    <span class="kw">return</span> out.String()
}</code></pre></div>
<p>The <code>Inspect()</code> method is not the only reason why it's good to keep track of the objects that generated the <code>HashKey</code>. That would also be necessary if we were to implement something like a <code>range</code> function for Monkey hashes, which iterates over keys and values in the hash. Or if we want to add a <code>firstPair</code> function that returns the first key and value of a given hash as an array. Or if we want... You get the drift. Keeping track of keys is highly useful, even though for now only the <code>Inspect()</code> method benefits.</p>
<p>And that's it! That's the whole implementation of <code>object.Hash</code>. But there's a small thing we ought to do while we still have the <code>object</code> package open:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// object/object.go</span>

<span class="kw">type</span> Hashable <span class="kw">interface</span> {
    HashKey() HashKey
}</code></pre></div>
<p>We can use this interface in our evaluator to check if the given object is usable as a hash key when we evaluate hash literals or index expressions for hashes.</p>
<p>At the moment it's only implemented by <code>*object.String</code>, <code>*object.Boolean</code> and <code>*object.Integer</code>.</p>
<p>Granted, there's one more thing we could do before moving on: we could optimize the performance of the <code>HashKey()</code> methods by caching their return values, but that sounds like a nice exercise for the performance-minded reader.</p>
<h3 id="evaluating-hash-literals">Evaluating Hash Literals</h3>
<p>We're about to start evaluating hash literals and I'll be completely honest with you: the hardest part about adding hashes to our interpreter is over. It's smooth sailing from here on out. So, let's enjoy the ride, relax and write a test:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestHashLiterals(t *testing.T) {
    input := <span class="st">`let two = &quot;two&quot;;</span>
<span class="st">    {</span>
<span class="st">        &quot;one&quot;: 10 - 9,</span>
<span class="st">        two: 1 + 1,</span>
<span class="st">        &quot;thr&quot; + &quot;ee&quot;: 6 / 2,</span>
<span class="st">        4: 4,</span>
<span class="st">        true: 5,</span>
<span class="st">        false: 6</span>
<span class="st">    }`</span>

    evaluated := testEval(input)
    result, ok := evaluated.(*object.Hash)
    <span class="kw">if</span> !ok {
        t.Fatalf(<span class="st">&quot;Eval didn&#39;t return Hash. got=%T (%+v)&quot;</span>, evaluated, evaluated)
    }

    expected := <span class="kw">map</span>[object.HashKey]<span class="dt">int64</span>{
        (&amp;object.String{Value: <span class="st">&quot;one&quot;</span>}).HashKey():   <span class="dv">1</span>,
        (&amp;object.String{Value: <span class="st">&quot;two&quot;</span>}).HashKey():   <span class="dv">2</span>,
        (&amp;object.String{Value: <span class="st">&quot;three&quot;</span>}).HashKey(): <span class="dv">3</span>,
        (&amp;object.Integer{Value: <span class="dv">4</span>}).HashKey():      <span class="dv">4</span>,
        TRUE.HashKey():                             <span class="dv">5</span>,
        FALSE.HashKey():                            <span class="dv">6</span>,
    }

    <span class="kw">if</span> <span class="bu">len</span>(result.Pairs) != <span class="bu">len</span>(expected) {
        t.Fatalf(<span class="st">&quot;Hash has wrong num of pairs. got=%d&quot;</span>, <span class="bu">len</span>(result.Pairs))
    }

    <span class="kw">for</span> expectedKey, expectedValue := <span class="kw">range</span> expected {
        pair, ok := result.Pairs[expectedKey]
        <span class="kw">if</span> !ok {
            t.Errorf(<span class="st">&quot;no pair for given key in Pairs&quot;</span>)
        }

        testIntegerObject(t, pair.Value, expectedValue)
    }
}</code></pre></div>
<p>This test function shows what we want from <code>Eval</code> when it encounters a <code>*ast.HashLiteral</code>: a fresh <code>*object.Hash</code> with the correct number of <code>HashPair</code>s mapped to the matching <code>HashKey</code>s in its <code>Pairs</code> attribute.</p>
<p>And it also shows another requirement we have: strings, identifiers, infix operator expressions, booleans and integers - they should all be usable as keys. Any expression really. As long as it produces an <code>object</code> that implements the <code>Hashable</code> interface it should usable as a hash key.</p>
<p>Then there are the values. They can be produced by any expression, too. We test for this here by asserting that <code>10 - 9</code> evaluates to <code>1</code>, <code>6 / 2</code> to <code>3</code> and so on.</p>
<p>As expected the test fails:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestHashLiterals (0.00s)
  evaluator_test.go:522: Eval didn&#39;t return Hash. got=&lt;nil&gt; (&lt;nil&gt;)
FAIL
FAIL    monkey/evaluator        0.008s</code></pre></div>
<p>We know how to get it to pass, though. We need to extend our <code>Eval</code> function with another <code>case</code> branch for <code>*ast.HashLiteral</code>s:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> Eval(node ast.Node, env *object.Environment) object.Object {
<span class="co">// [...]</span>

    <span class="kw">case</span> *ast.HashLiteral:
        <span class="kw">return</span> evalHashLiteral(node, env)

<span class="co">// [...]</span>
}</code></pre></div>
<p>The <code>evalHashLiteral</code> function here may look intimidating, but trust me, it doesn't bite:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalHashLiteral(
    node *ast.HashLiteral,
    env *object.Environment,
) object.Object {
    pairs := <span class="bu">make</span>(<span class="kw">map</span>[object.HashKey]object.HashPair)

    <span class="kw">for</span> keyNode, valueNode := <span class="kw">range</span> node.Pairs {
        key := Eval(keyNode, env)
        <span class="kw">if</span> isError(key) {
            <span class="kw">return</span> key
        }

        hashKey, ok := key.(object.Hashable)
        <span class="kw">if</span> !ok {
            <span class="kw">return</span> newError(<span class="st">&quot;unusable as hash key: %s&quot;</span>, key.Type())
        }

        value := Eval(valueNode, env)
        <span class="kw">if</span> isError(value) {
            <span class="kw">return</span> value
        }

        hashed := hashKey.HashKey()
        pairs[hashed] = object.HashPair{Key: key, Value: value}
    }

    <span class="kw">return</span> &amp;object.Hash{Pairs: pairs}
}</code></pre></div>
<p>When iterating over the <code>node.Pairs</code> the <code>keyNode</code> is the first to be evaluated. Besides checking if the call to <code>Eval</code> produced an error we also make a type assertion about the evaluation result: it needs to implement the <code>object.Hashable</code> interface, otherwise it's unusable as a hash key. That's exactly why we added the <code>Hashable</code> definition.</p>
<p>Then we call <code>Eval</code> again, to evaluate <code>valueNode</code>. If that call to <code>Eval</code> also doesn't produce an error, we can add the newly produced key-value pair to our <code>pairs</code> map. We do this by generating a <code>HashKey</code> for the aptly-named <code>hashKey</code> object with a call to <code>HashKey()</code>. Then we initialize a new <code>HashPair</code>, pointing to both <code>key</code> and <code>value</code> and add it to <code>pairs</code>.</p>
<p>And that's all it takes. The tests are now passing:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>That means we can already start using hash literals in our REPL:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; {&quot;name&quot;: &quot;Monkey&quot;, &quot;age&quot;: 0, &quot;type&quot;: &quot;Language&quot;, &quot;status&quot;: &quot;awesome&quot;}
{age: 0, type: Language, status: awesome, name: Monkey}</code></pre></div>
<p>That's awesome! But we can't get elements out of the hash yet, which kinda diminishes their usefulness:</p>
<div class="sourceCode"><pre class="sourceCode javascript"><code class="sourceCode javascript"><span class="op">&gt;&gt;</span> <span class="kw">let</span> bob <span class="op">=</span> <span class="op">{</span><span class="st">&quot;name&quot;</span><span class="op">:</span> <span class="st">&quot;Bob&quot;</span><span class="op">,</span> <span class="st">&quot;age&quot;</span><span class="op">:</span> <span class="dv">99</span><span class="op">};</span>
<span class="op">&gt;&gt;</span> bob[<span class="st">&quot;name&quot;</span>]
ERROR<span class="op">:</span> index operator not supported<span class="op">:</span> HASH</code></pre></div>
<p>That's what we're going to fix now.</p>
<h3 id="evaluating-index-expressions-with-hashes">Evaluating Index Expressions With Hashes</h3>
<p>Remember that switch statement we added to <code>evalIndexExpression</code> in our evaluator? And do you also remember when I told you that we're going to add another <code>case</code> branch? Well, here we are!</p>
<p>But first of all we need to add a test function that makes sure accessing values in a hash via an index expression works:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestHashIndexExpressions(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input    <span class="dt">string</span>
        expected <span class="kw">interface</span>{}
    }{
        {
            <span class="st">`{&quot;foo&quot;: 5}[&quot;foo&quot;]`</span>,
            <span class="dv">5</span>,
        },
        {
            <span class="st">`{&quot;foo&quot;: 5}[&quot;bar&quot;]`</span>,
            <span class="ot">nil</span>,
        },
        {
            <span class="st">`let key = &quot;foo&quot;; {&quot;foo&quot;: 5}[key]`</span>,
            <span class="dv">5</span>,
        },
        {
            <span class="st">`{}[&quot;foo&quot;]`</span>,
            <span class="ot">nil</span>,
        },
        {
            <span class="st">`{5: 5}[5]`</span>,
            <span class="dv">5</span>,
        },
        {
            <span class="st">`{true: 5}[true]`</span>,
            <span class="dv">5</span>,
        },
        {
            <span class="st">`{false: 5}[false]`</span>,
            <span class="dv">5</span>,
        },
    }

    <span class="kw">for</span> _, tt := <span class="kw">range</span> tests {
        evaluated := testEval(tt.input)
        integer, ok := tt.expected.(<span class="dt">int</span>)
        <span class="kw">if</span> ok {
            testIntegerObject(t, evaluated, <span class="dt">int64</span>(integer))
        } <span class="kw">else</span> {
            testNullObject(t, evaluated)
        }
    }
}</code></pre></div>
<p>Just like in <code>TestArrayIndexExpressions</code> we're making sure using index operator expressions produces the correct value - only this time with hashes. The different test cases here use string, integer or boolean hash keys when retrieving values out of a hash. So, in essence, what the test really asserts is that the <code>HashKey</code> methods implemented by various data types are called correctly.</p>
<p>And to make sure that using an object as hash key that does not implement <code>object.Hashable</code> produces an error, we can add another test to our <code>TestErrorHandling</code> test function:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator_test.go</span>

<span class="kw">func</span> TestErrorHandling(t *testing.T) {
    tests := []<span class="kw">struct</span> {
        input           <span class="dt">string</span>
        expectedMessage <span class="dt">string</span>
    }{
<span class="co">// [...]</span>
        {
            <span class="st">`{&quot;name&quot;: &quot;Monkey&quot;}[fn(x) { x }];`</span>,
            <span class="st">&quot;unusable as hash key: FUNCTION&quot;</span>,
        },
    }

<span class="co">// [...]</span>
}</code></pre></div>
<p>Running <code>go test</code> now results in the expected failures:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
--- FAIL: TestErrorHandling (0.00s)
  evaluator_test.go:228: no error object returned. got=*object.Null(&amp;{})
--- FAIL: TestHashIndexExpressions (0.00s)
  evaluator_test.go:611: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:611: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:611: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:611: object is not Integer. got=*object.Null (&amp;{})
  evaluator_test.go:611: object is not Integer. got=*object.Null (&amp;{})
FAIL
FAIL    monkey/evaluator        0.007s</code></pre></div>
<p>That means we're ready to add another <code>case</code> branch to the switch statement in <code>evalIndexExpression</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalIndexExpression(left, index object.Object) object.Object {
    <span class="kw">switch</span> {
    <span class="kw">case</span> left.Type() == object.ARRAY_OBJ &amp;&amp; index.Type() == object.INTEGER_OBJ:
        <span class="kw">return</span> evalArrayIndexExpression(left, index)
    <span class="kw">case</span> left.Type() == object.HASH_OBJ:
        <span class="kw">return</span> evalHashIndexExpression(left, index)
    <span class="kw">default</span>:
        <span class="kw">return</span> newError(<span class="st">&quot;index operator not supported: %s&quot;</span>, left.Type())
    }
}</code></pre></div>
<p>The new <code>case</code> branch calls a new function: <code>evalHashIndexExpression</code>. And we already know how <code>evalHashIndexExpression</code> has to work, since we successfully tested the usage of the <code>object.Hashable</code> interface before - in our tests and when evaluating hash literals. So no surprises here:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/evaluator.go</span>

<span class="kw">func</span> evalHashIndexExpression(hash, index object.Object) object.Object {
    hashObject := hash.(*object.Hash)

    key, ok := index.(object.Hashable)
    <span class="kw">if</span> !ok {
        <span class="kw">return</span> newError(<span class="st">&quot;unusable as hash key: %s&quot;</span>, index.Type())
    }

    pair, ok := hashObject.Pairs[key.HashKey()]
    <span class="kw">if</span> !ok {
        <span class="kw">return</span> NULL
    }

    <span class="kw">return</span> pair.Value
}</code></pre></div>
<p>Adding <code>evalHashIndexExpression</code> to the switch statement made the tests pass:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go test ./evaluator
ok      monkey/evaluator        0.007s</code></pre></div>
<p>We can now successfully retrieve values from our hashes! Don't believe me? Think the tests are lying to us? I faked the test output? It can't be? The whole book is full of li.. what? No, watch this.</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; let people = [{&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 24}, {&quot;name&quot;: &quot;Anna&quot;, &quot;age&quot;: 28}];
&gt;&gt; people[0][&quot;name&quot;];
Alice
&gt;&gt; people[1][&quot;age&quot;];
28
&gt;&gt; people[1][&quot;age&quot;] + people[0][&quot;age&quot;];
52
&gt;&gt; let getName = fn(person) { person[&quot;name&quot;]; };
&gt;&gt; getName(people[0]);
Alice
&gt;&gt; getName(people[1]);
Anna</code></pre></div>
<h2 id="the-grand-finale">4.6 - The Grand Finale</h2>
<p>Our Monkey interpreter is now fully functional. It supports mathematical expressions, variable bindings, functions and the application of those functions, conditionals, return statements and even advanced concepts like higher-order functions and closures. And then there are the different data types: integers, booleans, strings, arrays and hashes. We can be proud of ourselves.</p>
<p>But... and here comes the but... our interpreter still does not pass the most basic of all programming language tests: printing something. Yes, our Monkey interpreter can't communicate with the outside world. Even programming language scoundrel like Bash and Brainfuck manage to do that. It's clear what we have to do. We have to add one last built-in function: <code>puts</code>.</p>
<p><code>puts</code> prints the given arguments on new lines to STDOUT. It calls the <code>Inspect()</code> method on the objects passed in as arguments and prints the return value of these calls. The <code>Inspect()</code> method is part of the <code>Object</code> interface, so every entity in our object system supports it. Using <code>puts</code> should look kinda like this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; puts(&quot;Hello!&quot;)
Hello!
&gt;&gt; puts(1234)
1234
&gt;&gt; puts(fn(x) { x * x })
fn(x) {
(x * x)
}</code></pre></div>
<p>And <code>puts</code> is a variadic function. It takes an unlimited number of arguments and prints each on a separate line:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; puts(&quot;hello&quot;, &quot;world&quot;, &quot;how&quot;, &quot;are&quot;, &quot;you&quot;)
hello
world
how
are
you</code></pre></div>
<p>Of course, <code>puts</code> is all about printing things and not producing a value, so we need to make sure that it returns <code>NULL</code>:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; let putsReturnValue = puts(&quot;foobar&quot;);
foobar
&gt;&gt; putsReturnValue
null</code></pre></div>
<p>That also means that our REPL will print the <code>null</code> in addition to the output we expect from <code>puts</code>. So it will look like this:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">&gt;&gt; puts(&quot;Hello!&quot;)
Hello!
null</code></pre></div>
<p>Now that's more than enough information and specification to complete this last quest of ours. Are you ready?</p>
<p>Here it is, here's what this section has been building up to, here is the complete, working implementation of <code>puts</code>:</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// evaluator/builtins.go</span>

<span class="kw">import</span> (
    <span class="st">&quot;fmt&quot;</span>
    <span class="st">&quot;monkey/object&quot;</span>
    <span class="st">&quot;unicode/utf8&quot;</span>
)

<span class="kw">var</span> builtins = <span class="kw">map</span>[<span class="dt">string</span>]*object.Builtin{
<span class="co">// [...]</span>
    <span class="st">&quot;puts&quot;</span>: &amp;object.Builtin{
        Fn: <span class="kw">func</span>(args ...object.Object) object.Object {
            <span class="kw">for</span> _, arg := <span class="kw">range</span> args {
                fmt.Println(arg.Inspect())
            }

            <span class="kw">return</span> NULL
        },
    },
}</code></pre></div>
<p>And with that, we did it. We're done. Even if you were wary of our little celebrations and shrugged them off before, now's the time to go looking for a funny party hat and put it on.</p>
<p>In chapter three we brought the Monkey programming language to life. It started to breathe. With our last change, we made it talk. Now, Monkey is finally a real programming language:</p>
<div class="sourceCode"><pre class="sourceCode changelog"><code class="sourceCode changelog">$ go run main.go
Hello mrnugget! This is the Monkey programming language!
Feel free to type in commands
&gt;&gt; puts(&quot;Hello World!&quot;)
Hello World!
null
&gt;&gt;</code></pre></div>
<h1 id="resources" class="unnumbered">Resources</h1>
<h4 id="books">Books</h4>
<ul>
<li>Abelson, Harold and Sussman, Gerald Jay with Sussman, Julie. 1996. <strong>Structure and Interpretation of Computer Programs, Second Edition</strong>. MIT Press.</li>
<li>Appel, Andrew W.. 2004. <strong>Modern Compiler Implementation in C</strong>. Cambridge University Press.</li>
<li>Cooper, Keith D. and Torczon Linda. 2011. <strong>Engineering a Compiler, Second Edition</strong>. Morgan Kaufmann.</li>
<li>Grune, Dick and Jacobs, Ceriel. 1990. <strong>Parsing Techniques. A Practical Guide.</strong>. Ellis Horwood Limited.</li>
<li>Grune, Dick and van Reeuwijk, Kees and Bal Henri E. and Jacobs, Ceriel J.H. Jacobs and Langendoen, Koen. 2012. <strong>Modern Compiler Design, Second Edition</strong>. Springer</li>
<li>Nisan, Noam and Schocken, Shimon. 2008. <strong>The Elements Of Computing Systems</strong>. MIT Press.</li>
</ul>
<h4 id="papers">Papers</h4>
<ul>
<li>Ayock, John. 2003. <strong>A Brief History of Just-In-Time</strong>. In <strong>ACM Computing Surveys, Vol. 35, No. 2, June 2003</strong></li>
<li>Ertl, M. Anton and Gregg, David. 2003. <strong>The Structure and Performance of Efficient Interpreters</strong>. In <strong>Journal Of Instruction-Level Parallelism 5 (2003)</strong></li>
<li>Ghuloum, Abdulaziz. 2006. <strong>An Incremental Approach To Compiler Construction</strong>. In <strong>Proceedings of the 2006 Scheme and Functional Programming Workshop</strong>.</li>
<li>Ierusalimschy, Robert and de Figueiredo, Luiz Henrique and Celes Waldemar. <strong>The Implementation of Lua 5.0</strong>. <a href="https://www.lua.org/doc/jucs05.pdf" class="uri">https://www.lua.org/doc/jucs05.pdf</a></li>
<li>Pratt, Vaughan R. 1973. <strong>Top Down Operator Precedence</strong>. Massachusetts Institute of Technology.</li>
<li>Romer, Theodore H. and Lee, Dennis and Voelker, Geoffrey M. and Wolman, Alec and Wong, Wayne A. and Baer, Jean-Loup and Bershad, Brian N. and Levy, Henry M.. 1996. <strong>The Structure and Performance of Interpreters</strong>. In <strong>ASPLOS VII Proceedings of the seventh international conference on Architectural support for programming languages and operating systems</strong>.</li>
<li>Dybvig, R. Kent. 2006. <strong>The Development of Chez Scheme</strong>. In <strong>ACM ICFP '06</strong></li>
</ul>
<h4 id="web">Web</h4>
<ul>
<li>Jack W. Crenshaw - Let's Build a Compiler! - <a href="http://compilers.iecc.com/crenshaw/tutorfinal.pdf" class="uri">http://compilers.iecc.com/crenshaw/tutorfinal.pdf</a></li>
<li>Douglas Crockford - Top Down Operator Precedence - <a href="http://javascript.crockford.com/tdop/tdop.html" class="uri">http://javascript.crockford.com/tdop/tdop.html</a></li>
<li>Bob Nystrom - Pratt Parsers: Expression Parsing Made Easy - <a href="http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/" class="uri">http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/</a></li>
<li>Shriram Krishnamurthi and Joe Gibbs Politz - Programming Languages: Application and Interpretation - <a href="http://papl.cs.brown.edu/2015/" class="uri">http://papl.cs.brown.edu/2015/</a></li>
<li>A Python Interpreter Written In Python - <a href="http://aosabook.org/en/500L/a-python-interpreter-written-in-python.html" class="uri">http://aosabook.org/en/500L/a-python-interpreter-written-in-python.html</a></li>
<li>Dr. Dobbs - Bob: A Tiny Object-Oriented Language - <a href="http://www.drdobbs.com/open-source/bob-a-tiny-object-oriented-language/184409401" class="uri">http://www.drdobbs.com/open-source/bob-a-tiny-object-oriented-language/184409401</a></li>
<li>Nick Desaulniers - Interpreter, Compiler, JIT - <a href="https://nickdesaulniers.github.io/blog/2015/05/25/interpreter-compiler-jit/" class="uri">https://nickdesaulniers.github.io/blog/2015/05/25/interpreter-compiler-jit/</a></li>
<li>Peter Norvig - (How to Write a (Lisp) Interpreter (in Python)) - <a href="http://norvig.com/lispy.html" class="uri">http://norvig.com/lispy.html</a></li>
<li>Fredrik Lundh - Simple Town-Down Parsing In Python - <a href="http://effbot.org/zone/simple-top-down-parsing.htm" class="uri">http://effbot.org/zone/simple-top-down-parsing.htm</a></li>
<li>Mihai Bazon - How to implement a programming language in JavaScript - <a href="http://lisperator.net/pltut/" class="uri">http://lisperator.net/pltut/</a></li>
<li>Mary Rose Cook - Little Lisp interpreter - <a href="https://www.recurse.com/blog/21-little-lisp-interpreter" class="uri">https://www.recurse.com/blog/21-little-lisp-interpreter</a></li>
<li>Peter Michaux - Scheme From Scratch - <a href="http://peter.michaux.ca/articles/scheme-from-scratch-introduction" class="uri">http://peter.michaux.ca/articles/scheme-from-scratch-introduction</a></li>
<li>Make a Lisp - <a href="https://github.com/kanaka/mal" class="uri">https://github.com/kanaka/mal</a></li>
<li>Matt Might - Compiling Scheme to C with closure conversion - <a href="http://matt.might.net/articles/compiling-scheme-to-c/" class="uri">http://matt.might.net/articles/compiling-scheme-to-c/</a></li>
<li>Rob Pike - Implementing a bignum calculator - <a href="https://www.youtube.com/watch?v=PXoG0WX0r_E" class="uri">https://www.youtube.com/watch?v=PXoG0WX0r_E</a></li>
<li>Rob Pike - Lexical Scanning in Go - <a href="https://www.youtube.com/watch?v=HxaD_trXwRE" class="uri">https://www.youtube.com/watch?v=HxaD_trXwRE</a></li>
</ul>
<h4 id="source-code">Source Code</h4>
<ul>
<li>The Wren Programming Language - <a href="https://github.com/munificent/wren" class="uri">https://github.com/munificent/wren</a></li>
<li>Otto - A JavaScript Interpreter In Go - <a href="https://github.com/robertkrimen/otto" class="uri">https://github.com/robertkrimen/otto</a></li>
<li>The Go Programming Language - <a href="https://github.com/golang/go" class="uri">https://github.com/golang/go</a></li>
<li>The Lua Programming Language (1.1, 3.1, 5.3.2) - <a href="https://www.lua.org/versions.html" class="uri">https://www.lua.org/versions.html</a></li>
<li>The Ruby Programming Language - <a href="https://github.com/ruby/ruby" class="uri">https://github.com/ruby/ruby</a></li>
<li>c4 - C in four functions - <a href="https://github.com/rswier/c4" class="uri">https://github.com/rswier/c4</a></li>
<li>tcc - Tiny C Compiler - <a href="https://github.com/LuaDist/tcc" class="uri">https://github.com/LuaDist/tcc</a></li>
<li>8cc - A Small C Compiler - <a href="https://github.com/rui314/8cc" class="uri">https://github.com/rui314/8cc</a></li>
<li>Fedjmike/mini-c - <a href="https://github.com/Fedjmike/mini-c" class="uri">https://github.com/Fedjmike/mini-c</a></li>
<li>thejameskyle/the-super-tiny-compiler - <a href="https://github.com/thejameskyle/the-super-tiny-compiler" class="uri">https://github.com/thejameskyle/the-super-tiny-compiler</a></li>
<li>lisp.c - <a href="https://gist.github.com/sanxiyn/523967" class="uri">https://gist.github.com/sanxiyn/523967</a></li>
</ul>
<h1 id="feedback" class="unnumbered">Feedback</h1>
<p>If you spot a typo, find something wrong with the code, have a suggestion to make or just a question, feel free to send me an email:</p>
<p><a href="mailto:me@thorstenball.com">me@thorstenball.com</a></p>
<h1 id="changelog" class="unnumbered">Changelog</h1>
<h4 id="january-2017---1.3">26 January 2017 - 1.3</h4>
<ul>
<li>License of the code:
<ul>
<li>The <code>code</code> folder and its content are now licensed under the MIT license. See the <code>LICENSE</code> file and/or the <code>README.md</code> file.</li>
</ul></li>
<li>Section 1.1:
<ul>
<li>Make clear that whitespace is only significant in the sense that it separates tokens, but not its length.</li>
</ul></li>
<li>Section 1.3:
<ul>
<li>Small wording change</li>
<li>Fix wrong reference to <code>NextToken</code> when <code>readChar</code> was meant</li>
</ul></li>
<li>Section 2.8:
<ul>
<li>Fix the <code>parseBlockStatement</code> method so it doesn't run into an endless loop when parsing incomplete input</li>
</ul></li>
<li>Section 4.2:
<ul>
<li>Fix the <code>readString</code> method so it doesn't run into an endless loop when a string in the input is not terminated with a closing double quote</li>
</ul></li>
<li>Section 4.4:
<ul>
<li>Fix a typo in the error message of the builtin <code>push</code> function</li>
</ul></li>
</ul>
<h4 id="december-2016---1.2">20 December 2016 - 1.2</h4>
<ul>
<li>Section 2.8:
<ul>
<li>Add a missing semicolon to the test input in <code>TestLetStatements</code></li>
</ul></li>
<li>Section 4.4:
<ul>
<li>Fix the failing test for the builtin <code>push</code> function. Error was introduced with the last update. This change only occurrs in the code accompanying the book and only in subfolder <code>04</code>.</li>
</ul></li>
</ul>
<h4 id="december-2016---1.1">8 December 2016 - 1.1</h4>
<p>Besides fixed typos and spelling errors:</p>
<ul>
<li>Introduction
<ul>
<li>Change the &quot;How To Use This Book&quot; subsection to include a link to the downloadable archive of the accompanying code</li>
</ul></li>
<li>Section 1.4:
<ul>
<li>Add hint about accompanying code</li>
<li>Show the last, fully extended version of the test <code>input</code> for <code>TestNextToken</code></li>
</ul></li>
<li>Section 2.6:
<ul>
<li>The failing test output for <code>TestParsingPrefixExpressions</code> in the book text was wrong. It's corrected to match the actual output one gets when building the parser from scratch</li>
<li>Fix wording that didn't match the described test output</li>
<li>Remove <code>token.LPAREN</code> from the <code>precedences</code> table here. It somehow slipped in at this point, but should only be added later on in section 2.8, where tests are supposed to fail because it's missing</li>
</ul></li>
<li>Section 2.8:
<ul>
<li>Fix wrong test expectation (<code>&quot;x&quot;</code> changed to <code>&quot;y&quot;</code>) in <code>TestLetStatement</code></li>
<li>Change <code>parser_parser_test.go</code> to <code>parser_test.go</code></li>
<li>Better show how to use <code>testLiteralExpression</code> in <code>TestParsingInfixExpressions</code></li>
<li>Fix outdated test output for failing <code>TestOperatorPrecedenceParsing</code>, <code>TestIfExpression</code>, <code>TestIfElseExpression</code>, <code>TestFunctionLiteralParsing</code></li>
</ul></li>
<li>Section 3.10:
<ul>
<li>Change the <code>Inspect()</code> method of <code>*object.Function</code> to use <code>fn</code> instead of <code>function</code> and newlines in output</li>
<li>Remove needless semicolons in example</li>
</ul></li>
<li>Section 3.5:
<ul>
<li>Change from if/else to &quot;if and return&quot; in <code>nativeBoolToBooleanObject</code></li>
</ul></li>
<li>Section 3.6:
<ul>
<li>Update the version of <code>testNullObject</code> to be the one in the accompanying code, with a correct call to <code>t.Errorf</code></li>
</ul></li>
<li>Section 4.4:
<ul>
<li>Name the <code>token.Token</code> field of <code>ast.ArrayLiteral</code></li>
<li>Fix possible panic through nil error in &quot;first&quot;, &quot;last&quot;, &quot;rest&quot;, and &quot;push&quot; functions by adding separate check</li>
</ul></li>
<li>Section 4.5:
<ul>
<li>Name the <code>token.Token</code> field of <code>ast.HashLiteral</code></li>
<li>Replace <code>null</code> in output with missing error message when trying to access hash via index expression before it's implemented</li>
</ul></li>
<li>Section 4.6:
<ul>
<li>Change the expected output using <code>puts</code> with a function literal to match the updated <code>Inspect()</code> of <code>*object.Function</code></li>
<li>Explain the <code>null</code>s in the expected output of <code>put</code> better</li>
</ul></li>
</ul>
<h4 id="november-2016---1.0">23 November 2016 - 1.0</h4>
<ul>
<li>Initial Release</li>
</ul>

      </body>
</html>
